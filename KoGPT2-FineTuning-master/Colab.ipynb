{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95R4RqiOuA7A",
        "outputId": "1f154736-1fdb-4493-e27f-83665efc0d35"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baLi1Gj_aOZ6"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import logging\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "my_drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPruP1vbulVa"
      },
      "source": [
        "# 필요한 필수 새팅 작업"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHALfG-nWlRV",
        "outputId": "1f37d342-3b41-454c-d374-ea9289750cae"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adc.json  drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS8xS6APuuB6",
        "outputId": "0038fbd8-d0ba-42b5-9274-a2edeaea5587"
      },
      "source": [
        "%cd /content/drive/MyDrive/KoGPT2-FineTuning-master/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/KoGPT2-FineTuning-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m6L6j_nYTTl",
        "outputId": "575fa734-b0ec-4517-d8b2-3c625c64df5c"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mxnet==1.6.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.62.3)\n",
            "Requirement already satisfied: gluonnlp==0.9.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.9.1)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.1.91)\n",
            "Requirement already satisfied: torch==1.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.5.0)\n",
            "Requirement already satisfied: transformers==2.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (2.11.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2.4.1)\n",
            "Requirement already satisfied: dropbox in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (11.24.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.6.0->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.6.0->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.6.0->-r requirements.txt (line 1)) (0.8.4)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp==0.9.1->-r requirements.txt (line 3)) (0.29.24)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp==0.9.1->-r requirements.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0->-r requirements.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0->-r requirements.txt (line 6)) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0->-r requirements.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0->-r requirements.txt (line 6)) (2019.12.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0->-r requirements.txt (line 1)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r requirements.txt (line 7)) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: stone>=2.* in /usr/local/lib/python3.7/dist-packages (from dropbox->-r requirements.txt (line 8)) (3.2.1)\n",
            "Requirement already satisfied: ply>=3.4 in /usr/local/lib/python3.7/dist-packages (from stone>=2.*->dropbox->-r requirements.txt (line 8)) (3.11)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp==0.9.1->-r requirements.txt (line 3)) (3.0.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.11.0->-r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.11.0->-r requirements.txt (line 6)) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8M3DCwcYlMv"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "# sys.path.append('drive/My Drive/KoGPT2-FineTuning_pre')\n",
        "logs_base_dir = \"runs\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-qz4OLnYlSY",
        "scrolled": true
      },
      "source": [
        "from jupyter_main import main"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_Jjj58pd1Rq"
      },
      "source": [
        "ctx= 'cuda'\n",
        "cachedir='~/kogpt2/'\n",
        "load_path = '/content/drive/MyDrive/KoGPT2-FineTuning-master/checkpoint' # 이어서 학습시킬 모델 경로\n",
        "save_path = '/content/drive/MyDrive/KoGPT2-FineTuning-master/checkpoint' # 학습한 모델을 저장시킬 경로\n",
        "data_file_path = '/content/drive/MyDrive/KoGPT2-FineTuning-master/dataset/weighted_lyrics_1970_80.csv' # 학습할 데이터셋 경로\n",
        "summary_url = '/content/drive/MyDrive/KoGPT2-FineTuning-master/summary_url'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umcGNCCYktXo"
      },
      "source": [
        "# 모델 학습 시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMsOOmvhiU7D",
        "outputId": "07e448fb-5317-4873-85e0-64c30d7f5e48"
      },
      "source": [
        "main(epoch=100, load_path = load_path, data_file_path = data_file_path, save_path = save_path, summary_url = summary_url, text_size = 700, new = 1, batch_size = 16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count 0 :  /content/drive/MyDrive/KoGPT2-FineTuning-master/checkpoint\n",
            "tokenizer ending\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13379, 3)\n",
            "KoGPT-2 Transfer Learning Start\n",
            "epoch no.0 train no.0  loss = 4392.47119 avg_loss = 10.98118\n",
            "epoch no.0 train no.10  loss = 3826.37280 avg_loss = 9.97113\n",
            "epoch no.0 train no.20  loss = 5461.39160 avg_loss = 9.62063\n",
            "epoch no.0 train no.30  loss = 3441.78760 avg_loss = 9.31489\n",
            "epoch no.0 train no.40  loss = 3237.37842 avg_loss = 9.03904\n",
            "epoch no.0 train no.50  loss = 7806.07910 avg_loss = 8.77119\n",
            "epoch no.0 train no.60  loss = 7312.94971 avg_loss = 8.51269\n",
            "epoch no.0 train no.70  loss = 4306.47656 avg_loss = 8.27346\n",
            "epoch no.0 train no.80  loss = 2783.86792 avg_loss = 8.05108\n",
            "epoch no.0 train no.90  loss = 2670.20166 avg_loss = 7.85328\n",
            "epoch no.0 train no.100  loss = 2686.67920 avg_loss = 7.68110\n",
            "epoch no.0 train no.110  loss = 3884.31812 avg_loss = 7.52453\n",
            "epoch no.0 train no.120  loss = 2594.31885 avg_loss = 7.38585\n",
            "epoch no.0 train no.130  loss = 2532.02124 avg_loss = 7.26589\n",
            "epoch no.0 train no.140  loss = 2567.16431 avg_loss = 7.15730\n",
            "epoch no.0 train no.150  loss = 2516.01929 avg_loss = 7.05769\n",
            "epoch no.0 train no.160  loss = 2529.14844 avg_loss = 6.96888\n",
            "epoch no.0 train no.170  loss = 2484.52026 avg_loss = 6.88434\n",
            "epoch no.0 train no.180  loss = 2442.81665 avg_loss = 6.80597\n",
            "epoch no.0 train no.190  loss = 3712.92749 avg_loss = 6.73584\n",
            "epoch no.0 train no.200  loss = 2413.74341 avg_loss = 6.67590\n",
            "epoch no.0 train no.210  loss = 2423.17065 avg_loss = 6.61848\n",
            "epoch no.0 train no.220  loss = 2464.92261 avg_loss = 6.56300\n",
            "epoch no.0 train no.230  loss = 2425.06323 avg_loss = 6.51328\n",
            "epoch no.0 train no.240  loss = 2444.59351 avg_loss = 6.46193\n",
            "epoch no.0 train no.250  loss = 2404.24854 avg_loss = 6.41693\n",
            "epoch no.0 train no.260  loss = 2385.90820 avg_loss = 6.36755\n",
            "epoch no.0 train no.270  loss = 2386.99316 avg_loss = 6.32140\n",
            "epoch no.0 train no.280  loss = 2346.92969 avg_loss = 6.27202\n",
            "epoch no.0 train no.290  loss = 2300.37769 avg_loss = 6.22430\n",
            "epoch no.0 train no.300  loss = 3394.50391 avg_loss = 6.17532\n",
            "epoch no.0 train no.310  loss = 2234.81470 avg_loss = 6.12777\n",
            "epoch no.0 train no.320  loss = 2241.20605 avg_loss = 6.08410\n",
            "epoch no.0 train no.330  loss = 2278.30908 avg_loss = 6.03446\n",
            "epoch no.0 train no.340  loss = 2204.70435 avg_loss = 5.98253\n",
            "epoch no.0 train no.350  loss = 2239.57520 avg_loss = 5.93753\n",
            "epoch no.0 train no.360  loss = 2185.75830 avg_loss = 5.89695\n",
            "epoch no.0 train no.370  loss = 2184.32373 avg_loss = 5.84975\n",
            "epoch no.0 train no.380  loss = 3196.23218 avg_loss = 5.81075\n",
            "epoch no.0 train no.390  loss = 2125.73755 avg_loss = 5.77106\n",
            "epoch no.0 train no.400  loss = 3320.65771 avg_loss = 5.73424\n",
            "epoch no.0 train no.410  loss = 2145.03979 avg_loss = 5.69669\n",
            "epoch no.0 train no.420  loss = 2183.73633 avg_loss = 5.66718\n",
            "epoch no.0 train no.430  loss = 2142.10376 avg_loss = 5.63269\n",
            "epoch no.0 train no.440  loss = 3110.98804 avg_loss = 5.60436\n",
            "epoch no.0 train no.450  loss = 3262.57812 avg_loss = 5.57439\n",
            "epoch no.0 train no.460  loss = 2131.80518 avg_loss = 5.54626\n",
            "epoch no.0 train no.470  loss = 2121.54224 avg_loss = 5.52152\n",
            "epoch no.0 train no.480  loss = 2166.09204 avg_loss = 5.49058\n",
            "epoch no.0 train no.490  loss = 2116.54614 avg_loss = 5.46494\n",
            "epoch no.0 train no.500  loss = 3193.57593 avg_loss = 5.44047\n",
            "701\n",
            "to_tokens: ['▁[', '▁너', '▁너', '젠', '▁', '젠', '▁', '를', '▁너', '젠', '이', '▁', '해', '▁', '게', '이', '▁', '▁', '를', '▁', '▁', '▁', '를', '▁', '해', '▁너', '를', '▁', '워', '▁너', '▁너', '를', '▁', '를', '▁너', '를', '▁', '를', '▁', '해', '▁너', '▁너', '해', '▁너', '게', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '해', '▁너', '를', '▁너', '에', '게', '▁너', '를', '▁너', '해', '▁너', '를', '▁너', '고', '▁너', '해', '▁너', '를', '▁너', '▁너', '널', '▁너', '를', '▁너', '를', '▁사랑', '게', '▁너', '를', '▁너', '해', '▁너', '를', '▁사랑', '를', '▁너', '해', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '에', '▁너', '게', '▁너', '를', '▁너', '를', '▁너', '해', '▁너', '를', '▁너', '를', '▁너', '해', '▁너', '를', '▁너', '를', '▁너', '해', '▁너', '를', '▁너', '해', '▁너', '를', '▁너', '의', '▁너', '를', '▁너', '를', '▁너', '보', '를', '▁사랑', '를', '▁너', '를', '▁너', '을', '▁너', '를', '▁사랑', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '해', '▁너', '젠', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '해', '▁너', '를', '▁너', '▁너', '를', '을', '를', '▁너', '해', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '해', '▁너', '를', '▁너', '해', '▁너', '를', '▁너', '해', '▁수', '를', '▁너', '를', '▁너', '를', '▁너', '▁너', '를', '▁너', '해', '▁수', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '▁너', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '해', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '▁너', '▁너', '▁너', '를', '▁너', '를', '▁너', '▁너', '를', '▁너', '해', '▁너', '를', '▁너', '해', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '해', '를', '를', '▁너', '해', '▁너', '를', '▁너', '를', '▁너', '▁너', '▁너', '▁너', '를', '▁너', '를', '▁너', '해', '▁너', '를', '▁너', '게', '▁너', '를', '▁너', '를', '▁너', '▁너', '를', '▁너', '를', '▁너', '를', '를', '▁너', '해', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '▁너', '▁너', '를', '▁너', '를', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '▁너', '를', '를', '▁너', '를', '▁너', '를', '▁너', '▁너', '를', '▁너', '를', '▁너', '를', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '게', '▁너', '를', '▁너', '를', '▁너', '를', '▁', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '▁너', '를', '▁너', '를', '▁너', '를', '와', '▁너', '를', '▁너', '를', '▁너', '▁너', '▁너', '를', '▁너', '▁너', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '▁너', '를', '를', '▁너', '▁너', '▁너', '를', '▁너', '▁너', '▁너', '를', '▁너', '를', '▁너', '▁너', '▁너', '를', '▁너', '▁너', '▁너', '를', '▁너', '해', '를', '▁너', '를', '▁너', '▁너', '▁너', '를', '▁너', '▁너', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '널', '▁너', '를', '▁너', '를', '▁너', '를', '를', '▁너', '를', '▁너', '▁너', '를', '를', '▁너', '를', '▁너', '를', '를', '를', '▁너', '를', '▁너', '를', '▁너', '▁너', '▁너', '▁너', '를', '를', '▁너', '▁너', '▁너', '를', '▁너', '를', '를', '▁너', '를', '▁너', '▁너', '▁너', '▁너', '를', '▁너', '▁너', '▁너', '▁너', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '▁너', '▁너', '를', '▁너', '를', '를', '를', '▁너', '▁너', '니', '▁너', '▁너', '▁너', '를', '▁너', '와', '를', '▁너', '를', '▁너', '를', '▁너', '▁너', '▁너', '를', '▁너', '▁너', '를', '▁너', '를', '▁너', '를', '▁너', '해', '▁너', '▁너', '를', '▁너', '▁너', '▁너', '를', '를', '▁너', '▁너', '▁너', '를', '▁너', '▁너', '▁너', '▁너', '▁너', '▁너', '를', '▁너', '를', '를', '▁너', '▁너', '▁너', '▁너', '▁너', '를', '▁너', '▁너', '▁너', '를', '▁너', '▁너', '▁너', '▁너', '▁너', '▁너', '널', '▁너', '해', '를', '▁너', '를', '를', '▁너', '▁너', '▁너', '▁너', '▁너', '를', '를', '▁너', '를', '▁너', '▁너', '▁너', '▁너', '▁너', '를', '▁너', '▁너', '▁너', '를', '▁너', '▁너', '▁너', '▁너', '▁너', '▁너', '▁너', '▁너', '▁너', '▁너', '해', '▁너', '▁없어', '▁너', '▁너', '를', '▁너']\n",
            "너라면 이게\n",
            "\n",
            "이젠너와 이별을\n",
            "\n",
            "기억을 내 가슴이고 너를만을 나를 사랑한 너의 지쳐도너의 너의 너를 너를\n",
            "\n",
            "사랑해 날 사랑해 내 게 너를 너와 너의 사랑해너의가슴 내게 나의사랑해 너를 울을 사랑해 너의 사람 도 너는 너를 내게너의사랑해 너를너는 말지 너의너는나의 가슴을 내게 너의 너를 사랑해 너를 나를 사랑해 나의 너를 사랑해 너를 사랑해 너와 너도 나를 너를 바라 나를 너를 너의 눈지 너를 나를너와 너의 너를 사랑이 이젠 너의 너의 너를 너를 사랑해 너만 하는 너만 너를 사랑해 너의 너와너와 나의 사랑해 너를 사랑해 너를 사랑할 너를 너의 너를 다시 너만 사랑할 너와 너의 너를 너만 너를 너를 너도너를 너의 기억해 너는 너와 너를사랑하는 나를 너를 너를 너의 너란거야해 너의 너만한 나를 사랑해너를 사랑해 너를너를 너와 너를 나 너를 너를 너의 너의 너의 너만 너의 사랑 너 너만 사랑해너의 너에게인거게 너를 너를 사랑해 너와 내게 너가 너와서 너만 너의 너 나를사랑해 너를너를 너를 너의 너를\n",
            "\n",
            "지워 너를 너 너의 너를너만 너의너를 너를 너와 너의 너를 너를만너 너를 너의 너와 나 너를 너를 너 너를 너가 너만 너만 너를 내 게 너는 너는 너 내게 너의 너 더 너를 너와 너를 너를 너를 너 너와 너를 너를 너지 너를 너 없는줄 너와 너와 너 너를 너를 너를 너를 너와 너와 너란 너는 너를 너의 너를 너와 없어 너 너만 너를너를너를 너와 너와 나에게 너 너 사랑해 너를 사랑 너의 너는 너를 너와 너와 너를 너만 너와너와 너도 너를 너만 너니 너 에게 너를 너지 너 너가 너서게 너 너와 너를 너 너 너없는 너에게 너를 내 너 내 너 너를너 너 너만 너 너는 너니 나 너 더 너 너에게 너만한 너에게 너를 나를 너를 너의 너에게 너 너 너를 너 가 나도 너를 너 너만 너와 너만 너진 너를한 너인 너의 나를 사랑해 너 너를 너는 너 너와 너는 너 너는 너 없 너는 너를 너 너만 너와 너를 너를 더 너 너 너 나를 너의 나 를 사랑 너 너 너 너는 너와 너를 너 너를 나 또 너 너에게 너 너로 너 수 너의 너는 너는 너 너를 너를 사랑할 수지 너 너 내 \n",
            "epoch no.0 train no.510  loss = 2085.82642 avg_loss = 5.41490\n",
            "epoch no.0 train no.520  loss = 2003.97607 avg_loss = 5.38984\n",
            "epoch no.0 train no.530  loss = 2013.77454 avg_loss = 5.36498\n",
            "epoch no.0 train no.540  loss = 3087.40503 avg_loss = 5.34292\n",
            "epoch no.0 train no.550  loss = 2086.35962 avg_loss = 5.31487\n",
            "epoch no.0 train no.560  loss = 1956.87317 avg_loss = 5.28296\n",
            "epoch no.0 train no.570  loss = 1998.02393 avg_loss = 5.26012\n",
            "epoch no.0 train no.580  loss = 2836.46875 avg_loss = 5.23524\n",
            "epoch no.0 train no.590  loss = 1965.84583 avg_loss = 5.21573\n",
            "epoch no.0 train no.600  loss = 1940.58081 avg_loss = 5.19618\n",
            "epoch no.0 train no.610  loss = 2001.53223 avg_loss = 5.17922\n",
            "epoch no.0 train no.620  loss = 2024.18652 avg_loss = 5.16827\n",
            "epoch no.0 train no.630  loss = 2005.88892 avg_loss = 5.14827\n",
            "epoch no.0 train no.640  loss = 1907.93591 avg_loss = 5.12969\n",
            "epoch no.0 train no.650  loss = 1928.43420 avg_loss = 5.11042\n",
            "epoch no.0 train no.660  loss = 1860.71167 avg_loss = 5.08542\n",
            "epoch no.0 train no.670  loss = 5153.52588 avg_loss = 5.06790\n",
            "epoch no.0 train no.680  loss = 1980.42639 avg_loss = 5.05551\n",
            "epoch no.0 train no.690  loss = 1935.29395 avg_loss = 5.03653\n",
            "epoch no.0 train no.700  loss = 1858.53552 avg_loss = 5.01614\n",
            "epoch no.0 train no.710  loss = 2988.62769 avg_loss = 4.99736\n",
            "epoch no.0 train no.720  loss = 2931.73291 avg_loss = 4.98382\n",
            "epoch no.0 train no.730  loss = 1838.72607 avg_loss = 4.96711\n",
            "epoch no.0 train no.740  loss = 2904.97827 avg_loss = 4.94934\n",
            "epoch no.0 train no.750  loss = 2753.40723 avg_loss = 4.93201\n",
            "epoch no.0 train no.760  loss = 4772.68262 avg_loss = 4.91376\n",
            "epoch no.0 train no.770  loss = 1874.64062 avg_loss = 4.90174\n",
            "epoch no.0 train no.780  loss = 4752.16455 avg_loss = 4.89831\n",
            "epoch no.0 train no.790  loss = 1970.27051 avg_loss = 4.88389\n",
            "epoch no.0 train no.800  loss = 1993.08301 avg_loss = 4.86493\n",
            "epoch no.0 train no.810  loss = 1871.02393 avg_loss = 4.85230\n",
            "epoch no.0 train no.820  loss = 1884.76636 avg_loss = 4.84747\n",
            "epoch no.0 train no.830  loss = 1896.21558 avg_loss = 4.84013\n",
            "epoch no.1 train no.840  loss = 1869.42517 avg_loss = 4.82438\n",
            "epoch no.1 train no.850  loss = 2718.71631 avg_loss = 4.80936\n",
            "epoch no.1 train no.860  loss = 1932.31372 avg_loss = 4.79335\n",
            "epoch no.1 train no.870  loss = 4570.01807 avg_loss = 4.77986\n",
            "epoch no.1 train no.880  loss = 1908.15027 avg_loss = 4.77137\n",
            "epoch no.1 train no.890  loss = 1892.59473 avg_loss = 4.76348\n",
            "epoch no.1 train no.900  loss = 4505.24756 avg_loss = 4.74766\n",
            "epoch no.1 train no.910  loss = 1794.47595 avg_loss = 4.74136\n",
            "epoch no.1 train no.920  loss = 2752.17725 avg_loss = 4.73233\n",
            "epoch no.1 train no.930  loss = 1891.41040 avg_loss = 4.72704\n",
            "epoch no.1 train no.940  loss = 2774.61011 avg_loss = 4.71490\n",
            "epoch no.1 train no.950  loss = 1885.62817 avg_loss = 4.70846\n",
            "epoch no.1 train no.960  loss = 1831.39246 avg_loss = 4.70140\n",
            "epoch no.1 train no.970  loss = 2848.40723 avg_loss = 4.69286\n",
            "epoch no.1 train no.980  loss = 1857.06714 avg_loss = 4.68644\n",
            "epoch no.1 train no.990  loss = 1800.19287 avg_loss = 4.67709\n",
            "epoch no.1 train no.1000  loss = 1910.28979 avg_loss = 4.67153\n",
            "701\n",
            "to_tokens: ['▁[', '▁너', '▁너', '픈', '도', '가', '▁', '를', '▁너', '한', '▁', '▁사랑', '보', '▁더', '지', '▁말', '도', '▁', '지', '▁', '해', '▁너', '▁사랑', '널', '▁수', '▁없는', '지', '▁', '를', '▁너', '도', '도', '▁너', '를', '▁', '▁', '▁', '▁너', '해', '도', '▁', '를', '▁사랑', '았', '▁너', '대', '▁', '를', '▁사랑', '았', '▁', '워', '도', '고', '▁너', '을', '도', '를', '▁사랑', '워', '도', '▁', '이', '▁', '를', '▁사랑', '▁사람', '널', '▁사랑', '해', '도', '▁', '게', '▁', '젠', '이', '▁', '파', '도', '▁수', '▁없는', '도', '▁', '이', '▁', '대', '▁', '는', '도', '▁', '해', '도', '▁', '해', '▁수', '▁', '▁사랑', '이', '▁', '해', '▁', '를', '▁사랑', '야', '▁사랑', '▁', '를', '▁사랑', '해', '도', '▁', '게', '▁', '를', '▁', '파', '게', '▁', '줘', '대', '▁사랑', '해', '▁', '파', '▁사람', '▁', '▁사랑', '게', '▁', '▁', '나', '봐', '를', '▁', '도', '도', '▁사랑', '를', '▁사랑', '를', '▁사랑', '해', '도', '▁사랑', '파', '는', '해', '▁', '▁', '를', '▁사랑', '이', '도', '잊', '▁', '해', '▁', '를', '▁사랑', '며', '지', '▁사랑', '는', '게', '이', '▁', '▁', '파', '해', '도', '잊', '▁', '해', '도', '▁', '를', '▁사랑', '고', '▁', '게', '해', '▁', '파', '▁사람', '도', '게', '▁', '를', '▁사랑', '해', '▁수', '▁', '줄', '게', '▁', '와', '▁수', '해', '▁', '대', '만', '▁사랑', '한', '▁사랑', '게', '에', '해', '▁', '파', '▁사랑', '해', '▁', '해', '▁', '게', '이', '▁', '▁사랑', '해', '도', '▁사랑', '대', '▁사랑', '대', '▁사랑', '해', '도', '잊', '▁사랑', '게', '이', '▁나', '나', '봐', '파', '▁사랑', '▁사랑', '줘', '게', '▁', '게', '이', '도', '▁사랑', '별', '이', '▁', '▁사랑', '▁사랑', '이', '▁사랑', '게', '에', '▁', '이', '▁', '▁사랑', '해', '도', '▁사랑', '를', '▁사랑', '이', '▁사랑', '이', '▁', '나', '봐', '해', '▁수', '▁없는', '거', '▁없는', '거', '야', '▁사랑', '게', '도', '를', '▁', '해', '▁', '▁사랑', '를', '▁사랑', '해', '도', '▁사랑', '해', '▁', '이', '▁사랑', '게', '▁사랑', '▁사랑', '맘', '요', '이', '야', '이', '리', '▁사랑', '해', '▁사랑', '를', '▁', '파', '도', '▁사랑', '해', '▁사랑', '▁사랑', '▁사랑', '해', '야', '▁사랑', '해', '야', '▁사랑', '게', '▁사랑', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '이', '걸', '▁사랑', '대', '▁사랑', '워', '해', '도', '도', '해', '어', '봐', '도', '▁사랑', '이', '도', '를', '▁사랑', '해', '야', '를', '▁사랑', '이', '▁사랑', '이', '▁', '게', '▁사랑', '를', '▁사랑', '대', '▁사랑', '이', '▁사랑', '▁사랑', '해', '▁사랑', '이', '▁', '를', '걸', '해', '▁사랑', '▁사랑', '▁사랑', '해', '도', '를', '▁사랑', '파', '게', '▁', '게', '이', '▁사랑', '▁사랑', '대', '▁사랑', '이', '▁사랑', '▁사랑', '이', '▁', '나', '이', '야', '▁사랑', '이', '▁', '해', '▁', '해', '야', '를', '▁사랑', '이', '▁', '별', '이', '▁사랑', '▁사랑', '이', '▁사랑', '해', '도', '를', '▁사랑', '이', '겠', '지', '마', '▁사랑', '해', '도', '▁사랑', '이', '▁사랑', '해', '야', '해', '도', '이', '도', '▁사랑', '잊', '에', '▁사랑', '이', '▁사랑', '대', '▁사랑', '▁사랑', '이', '▁사랑', '별', '▁사랑', '이', '▁사랑', '해', '▁', '대', '▁사랑', '이', '▁사랑', '해', '▁사랑', '이', '▁사랑', '▁사랑', '해', '▁사랑', '를', '▁사랑', '이', '▁', '▁사랑', '▁사랑', '해', '도', '해', '▁', '를', '▁사랑', '이', '▁', '▁사랑', '이', '에', '▁사랑', '해', '▁사랑', '▁사랑', '▁사랑', '이', '이', '▁', '이', '▁사랑', '를', '▁사랑', '이', '도', '▁사랑', '이', '해', '▁내', '▁사랑', '이', '▁', '를', '▁사랑', '해', '야', '▁사랑', '해', '▁', '▁사랑', '를', '▁사랑', '널', '▁사랑', '해', '▁사랑', '▁사랑', '이', '▁사랑', '▁사랑', '해', '▁', '▁사랑', '이', '▁사랑', '▁사랑', '대', '▁사랑', '▁사랑', '대', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '대', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '▁사랑', '대', '▁사랑', '해', '야', '를', '이', '▁사랑', '해', '▁사랑', '해', '▁', '를', '▁사랑', '이', '▁', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '이', '거', '▁없는', '▁사랑', '해', '도', '이', '▁', '▁사랑', '이', '도', '잊', '▁사랑', '이', '▁사랑', '▁사랑', '해', '▁사랑', '이', '▁사랑', '이', '겠', '▁사랑', '▁사랑', '이', '▁사랑', '▁사랑', '이', '▁수', '야', '▁사랑', '해', '▁사랑', '이', '▁사랑', '잊', '▁사랑', '해', '야', '파', '도', '도', '해', '▁사랑', '잊', '▁사랑', '를', '▁사랑', '이', '▁사랑', '▁사랑', '해', '▁수', '▁사랑', '대', '▁사랑', '▁사랑', '이', '▁사랑', '가', '▁사랑', '이', '도', '대', '▁사랑', '이', '▁사랑', '해', '▁', '▁사랑', '이', '▁', '를', '▁사랑', '대', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '이', '▁사랑', '해', '▁사랑', '해']\n",
            "너라면 아파인 걸 나에게 사랑이 날 바라보다 울지 말도울고 사랑한 사람 을 수 있는게 너는 말아줘너와도 더이상사랑해도 너를 보면서 그땐 나를 보며 지워주던 사람아 나를 지워서 눈물이 나의 그 댈사랑해도 모르고 이별을아파할 수가는 눈물이 그저다려도 사랑해도 사랑할래도 눈물만사랑은\n",
            "\n",
            "나를 보내줘도 너를 사랑해도 내겐 너도 아프게해그댈 사랑이 아픈 걸도 내게해서 너무나 나에게 말아줘 나도 나를 사랑해요 아냐 사랑이야 너를 사랑해 도 사랑이 나를 보았니가 내 마음이도아파해 도사랑해도너를 울고 내 사랑하고 아픈가내게 나를 사랑할게 해줄게\n",
            "\n",
            "돌아올라리 그대는 행복한 내 모습 사랑이 아는 사랑에\n",
            "\n",
            "사랑이\n",
            "\n",
            "내 가슴이 날사랑해도 그날 그대를 사랑해 도 내 마음이었나 아픈 사람아 내게 내 사랑해도 이별이면한 사랑에 내 가슴에사랑이야 사랑해도 나를 사랑한사랑이 너무나 사랑할 수 없을 수 없을거라고 내 모습 너만 사랑이야 나를 사랑해도 사랑이 사랑에내게해 줘 사랑이야라서 사랑한 너만 아파도 사랑했던걸 왜 사랑이야행복이야\n",
            "\n",
            "내게만 사랑해지는 사랑에 사랑인걸 그대 그리워해줘 사랑했나봐도 사랑해 나를 사랑이 너도 사랑은 사랑이\n",
            "\n",
            "내겐 너를\n",
            "\n",
            "그대의 마음에 난 사랑이 사랑이 나란 사랑한 걸로 사랑해 나를아프게 내 사랑하는 걸 그댄 사랑한 사람 사랑이 너무 사랑이 난 사랑이 사랑이 사랑이 나를 사랑이 이별이 날 사랑은 사랑해 나를 사랑하겠지 못해 사랑해도 사랑이 사랑이 사랑해 사랑해 내 곁에서 사랑해서 그대는 사랑은 이젠 사랑해 사랑이 그댈 사랑한 사랑하는 사랑해도 사랑이 나를 사랑이 내게 사랑해 사랑이 나 날 사랑이 내 가슴속에 사랑해도도 사랑 사랑이 사랑은 너를 사랑해줄 사랑 사랑이 내 사랑이 나를 사랑이 날 사랑이야 너만 히 사랑해도 사랑해도 사랑이 너무 사랑이야 그대여 그대 사랑이 사랑한 사랑해도그대의 사랑해도 사랑이야그대를 사랑이 나 사랑에 사랑해 사랑이 나를 사랑이 내\n",
            "\n",
            "사랑해 너를 사랑해 나를 사랑할 수 없어사랑해 사랑이도 사랑해 도 사랑이면 사랑한 사랑인 사랑하네요 내 가슴이야 사랑할거야 사랑해 사랑해도 사랑이 아파해 사랑해 도 나를 사랑이야사랑할께 그대만사랑이\n",
            "\n",
            "죠 사랑해 그댈 사랑은 사랑이야 사랑이 나도 그저 사랑한 사랑인 날 사랑해 사랑한 사랑해 사랑한\n",
            "epoch no.1 train no.1010  loss = 1778.53149 avg_loss = 4.66172\n",
            "epoch no.1 train no.1020  loss = 1815.66431 avg_loss = 4.65759\n",
            "epoch no.1 train no.1030  loss = 4491.31250 avg_loss = 4.64819\n",
            "epoch no.1 train no.1040  loss = 1787.43005 avg_loss = 4.63740\n",
            "epoch no.1 train no.1050  loss = 4255.93750 avg_loss = 4.62846\n",
            "epoch no.1 train no.1060  loss = 1762.39661 avg_loss = 4.61832\n",
            "epoch no.1 train no.1070  loss = 1729.23047 avg_loss = 4.60891\n",
            "epoch no.1 train no.1080  loss = 1813.50232 avg_loss = 4.60477\n",
            "epoch no.1 train no.1090  loss = 1821.25647 avg_loss = 4.59833\n",
            "epoch no.1 train no.1100  loss = 4719.48828 avg_loss = 4.59483\n",
            "epoch no.1 train no.1110  loss = 4555.22754 avg_loss = 4.59007\n",
            "epoch no.1 train no.1120  loss = 1729.98901 avg_loss = 4.57851\n",
            "epoch no.1 train no.1130  loss = 1785.25061 avg_loss = 4.58011\n",
            "epoch no.1 train no.1140  loss = 1764.94556 avg_loss = 4.57352\n",
            "epoch no.1 train no.1150  loss = 1814.02209 avg_loss = 4.57265\n",
            "epoch no.1 train no.1160  loss = 2695.26050 avg_loss = 4.56458\n",
            "epoch no.1 train no.1170  loss = 2636.70703 avg_loss = 4.55890\n",
            "epoch no.1 train no.1180  loss = 1756.15088 avg_loss = 4.55467\n",
            "epoch no.1 train no.1190  loss = 1799.80298 avg_loss = 4.56254\n",
            "epoch no.1 train no.1200  loss = 1789.21875 avg_loss = 4.55486\n",
            "epoch no.1 train no.1210  loss = 1780.14197 avg_loss = 4.54457\n",
            "epoch no.1 train no.1220  loss = 1759.95947 avg_loss = 4.54237\n",
            "epoch no.1 train no.1230  loss = 1830.83691 avg_loss = 4.53223\n",
            "epoch no.1 train no.1240  loss = 1777.23999 avg_loss = 4.52762\n",
            "epoch no.1 train no.1250  loss = 1792.52148 avg_loss = 4.52269\n",
            "epoch no.1 train no.1260  loss = 2767.65186 avg_loss = 4.51984\n",
            "epoch no.1 train no.1270  loss = 1894.00427 avg_loss = 4.51484\n",
            "epoch no.1 train no.1280  loss = 1774.79187 avg_loss = 4.50680\n",
            "epoch no.1 train no.1290  loss = 1858.76355 avg_loss = 4.50268\n",
            "epoch no.1 train no.1300  loss = 1821.11780 avg_loss = 4.49933\n",
            "epoch no.1 train no.1310  loss = 1770.81665 avg_loss = 4.48610\n",
            "epoch no.1 train no.1320  loss = 2698.91504 avg_loss = 4.48398\n",
            "epoch no.1 train no.1330  loss = 1901.24280 avg_loss = 4.48304\n",
            "epoch no.1 train no.1340  loss = 1804.46399 avg_loss = 4.47580\n",
            "epoch no.1 train no.1350  loss = 1832.26172 avg_loss = 4.47322\n",
            "epoch no.1 train no.1360  loss = 2698.25513 avg_loss = 4.47193\n",
            "epoch no.1 train no.1370  loss = 1743.43433 avg_loss = 4.46719\n",
            "epoch no.1 train no.1380  loss = 1708.69922 avg_loss = 4.46063\n",
            "epoch no.1 train no.1390  loss = 1787.59631 avg_loss = 4.45942\n",
            "epoch no.1 train no.1400  loss = 1787.58142 avg_loss = 4.46051\n",
            "epoch no.1 train no.1410  loss = 1664.69666 avg_loss = 4.45262\n",
            "epoch no.1 train no.1420  loss = 4316.97461 avg_loss = 4.44962\n",
            "epoch no.1 train no.1430  loss = 1689.64734 avg_loss = 4.44271\n",
            "epoch no.1 train no.1440  loss = 4319.27295 avg_loss = 4.43757\n",
            "epoch no.1 train no.1450  loss = 1668.64221 avg_loss = 4.43500\n",
            "epoch no.1 train no.1460  loss = 1749.43750 avg_loss = 4.42887\n",
            "epoch no.1 train no.1470  loss = 1709.61780 avg_loss = 4.42561\n",
            "epoch no.1 train no.1480  loss = 1748.07764 avg_loss = 4.42663\n",
            "epoch no.1 train no.1490  loss = 1718.50854 avg_loss = 4.42329\n",
            "epoch no.1 train no.1500  loss = 2634.09546 avg_loss = 4.42171\n",
            "701\n",
            "to_tokens: ['▁[', '▁너', '▁너', '▁', '▁', '▁', '를', '▁', '야', '▁너', '를', '▁', '지', '▁너', '▁너', '게', '이', '▁', '▁', '▁', '를', '▁', '해', '어', '▁너', '거', '▁너', '를', '▁', '에', '어', '▁너', '를', '▁', '게', '▁없어', '▁너', '를', '▁사랑', '를', '▁사랑', '▁너', '▁너', '를', '▁사랑', '워', '▁너', '▁사랑', '해', '▁너', '를', '▁사랑', '▁너', '게', '▁너', '를', '▁사랑', '▁너', '▁사랑', '해', '▁너', '게', '▁너', '별', '은', '▁수', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '을', '에', '▁너', '를', '▁사랑', '는', '▁너', '를', '▁사랑', '는', '워', '이', '▁', '해', '▁너', '를', '▁사랑', '는', '게', '▁없는', '겠', '아', '▁너', '▁너', '를', '▁사랑', '줄', '▁너', '를', '▁사랑', '를', '▁사랑', '에', '▁너', '를', '▁사랑', '▁너', '▁너', '▁너', '▁너', '를', '▁사랑', '망', '▁너', '별', '▁너', '를', '▁사랑', '기', '▁전에', '을', '보', '게', '▁너', '아', '▁너', '를', '▁사랑', '가', '▁너', '를', '▁사랑', '는', '▁너', '를', '▁사랑', '▁수', '▁너', '를', '▁사랑', '야', '▁너', '를', '▁사랑', '는', '▁너', '▁너', '를', '▁사랑', '에', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '려', '워', '▁너', '▁너', '해', '▁너', '▁너', '를', '▁사랑', '는', '▁너', '를', '▁사랑', '속', '▁너', '면', '▁너', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '이', '▁너', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '▁너', '해', '▁너', '▁너', '를', '▁사랑', '는', '▁너', '를', '▁사랑', '날', '▁너', '해', '▁너', '별', '▁너', '는', '▁수', '▁너', '를', '▁사랑', '해', '▁너', '해', '▁너', '별', '▁너', '게', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '지', '▁수', '야', '▁너', '를', '▁사랑', '별', '▁너', '를', '▁사랑', '을', '야', '를', '▁사랑', '이', '야', '아', '보', '면', '▁너', '를', '▁사랑', '해', '▁너', '해', '▁너', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '해', '▁너', '를', '▁사랑', '해', '▁너', '해', '▁너', '별', '▁너', '별', '▁너', '면', '해', '▁너', '해', '▁너', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '젠', '을', '에', '▁너', '별', '▁너', '를', '▁사랑', '해', '▁너', '해', '▁수', '야', '▁너', '해', '▁너', '해', '▁너', '를', '▁사랑', '해', '▁너', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁너', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '해', '▁너', '해', '▁너', '를', '▁사랑', '고', '▁너', '를', '▁사랑', '해', '▁너', '를', '을', '의', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '는', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁너', '별', '▁너', '별', '이', '야', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '게', '해', '야', '해', '거', '▁너', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁너', '별', '이', '면', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '를', '이', '▁사랑', '해', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '야', '▁너', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '별', '해', '▁사랑', '해', '▁너', '를', '▁사랑', '파', '해', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '별', '이', '▁너', '해', '▁사랑', '를', '▁사랑', '해', '▁너', '해', '▁사랑', '▁사랑', '에', '▁너', '를', '▁사랑', '가', '▁너', '▁너', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '별', '를', '▁사랑', '해', '▁사랑', '별', '▁사랑', '해', '▁사랑', '별', '이', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '가', '해', '▁사랑', '▁사랑', '아', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '별', '새', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '별', '해', '▁사랑', '를', '▁사랑', '▁사랑', '아', '▁사랑', '▁너', '▁너', '를', '▁사랑', '별', '이', '▁사랑', '를', '▁사랑', '별', '를', '▁사랑', '해', '▁사랑', '해', '야', '해', '▁사랑', '별', '▁사랑', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '별', '이', '야', '▁사랑', '를', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '별', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '별']\n",
            "너라면 또 또또 너를\n",
            "\n",
            "보내지 너를보내는지 내 가슴이 내모습이 너를 사랑했지 않을께 나를 생각했어 너의 내 게면\n",
            "\n",
            "너의너를 생각해봐 너를 그리운 날 사랑해 너의 모습을 내게 너를 또 다른 사랑해 내게 이별을 나를 사랑해 너의 아픔속에 너를 보내는 너를 보내려움을 원해 너를\n",
            "\n",
            "보내줄 수 없잖아도 너를지켜줘 나를 너를 생각에 너를 만나게 해줘 너를 원해 이젠 너의 향기만 바라볼게 말로 너를 떠나는 나를 보내야너를 볼께 너를 보내는 너를 기다리는걸 너의 가슴에 너를 사랑해 너의 두려워해 사랑해 그 너를 보내는 나의마음에 서서면 너를 사랑해 너의 눈물이면 너를 사랑해 너를 사랑해너를 나를 사랑해 너의 사랑해줘 사랑해줘 나를 보내야 너를 그건 사랑해 이대로 다시 볼께 너를 사랑한 사랑해 이대로 내게 너를 사랑해 나를 보낼거야 나의 이젠 너의 추억이 나의 눈물이\n",
            "\n",
            "날 바라보던 너의 사랑해 사랑해 그 너를 사랑해 나를 사랑해 사랑해 너를 사랑해 사랑이 이젠 이젠가서해 사랑해 사랑해 너를 사랑은 너를 사랑해 이별속에 이대로 너를 사랑해 사랑할거야 사랑해 사랑해너를 사랑해 그 너를 사랑해 사랑해 사랑해 너를 사랑해나를 사랑해 너를 사랑아 너를 사랑해 나를 사랑해 사랑해 사랑해 너를 울어 너를 사랑했던 너만 너의 사랑해 너를사랑해 너를 보내야 너를 사랑해 너를 사랑해 사랑해 너를 사랑해 너의 사랑한다고 너를 보내줘 이젠 이 별이서해 너를 사랑해 너를 사랑해 사랑해 내 사랑이야할께 너를 사랑해 너를 사랑해 사랑해 너를 사랑해 너의 사랑해 사랑했던다면 이별이 너를 사랑한 너를 너만을 사랑해 사랑해 너를 사랑해 너를 사랑해 너의 사랑해 나를 사랑해 사랑해 너의 사랑한 사랑이야 너를 사랑해 사랑해 이별해 사랑해 너를아파 너를 사랑해사랑해 너를 사랑해 너를 사랑해 사랑해 이 세상에 사랑해 너를 사랑해 사랑해 그 추억에 너를 떠나가 있어 너를 사랑해 사랑한 이 너의 사랑해 이대로 사랑해 이 밤아 너를 사랑해 너의 사랑해 너를 떠나 사랑해 그 말들 사랑한 사랑해 사랑해 너의 사랑해 이 밤로 사랑해 너의 사랑해 너의 사랑해 사랑해 이 순간아 너를 그 말아가네 너의 이별해 너를 이 나의 사랑해 사랑이 사랑해 이럴께 너를 사랑해 너를사랑해 이별이 날 너를 나를 사랑해 너를 사랑해 사랑해 너를 사랑해 너를 사랑해 사랑해 사랑해 사랑해 사랑해 이 사랑해 사랑해 나를 사랑해 사랑해 사랑해 사랑해 이별\n",
            "epoch no.1 train no.1510  loss = 2732.91675 avg_loss = 4.42215\n",
            "epoch no.1 train no.1520  loss = 4419.12793 avg_loss = 4.42269\n",
            "epoch no.1 train no.1530  loss = 4256.52197 avg_loss = 4.41518\n",
            "epoch no.1 train no.1540  loss = 1773.08252 avg_loss = 4.40887\n",
            "epoch no.1 train no.1550  loss = 1701.79443 avg_loss = 4.40315\n",
            "epoch no.1 train no.1560  loss = 4368.11670 avg_loss = 4.40296\n",
            "epoch no.1 train no.1570  loss = 1800.97144 avg_loss = 4.39860\n",
            "epoch no.1 train no.1580  loss = 2657.16309 avg_loss = 4.39644\n",
            "epoch no.1 train no.1590  loss = 2488.05640 avg_loss = 4.39197\n",
            "epoch no.1 train no.1600  loss = 1712.27747 avg_loss = 4.39013\n",
            "epoch no.1 train no.1610  loss = 1706.26257 avg_loss = 4.38564\n",
            "epoch no.1 train no.1620  loss = 1755.00720 avg_loss = 4.38045\n",
            "epoch no.1 train no.1630  loss = 1792.45801 avg_loss = 4.37945\n",
            "epoch no.1 train no.1640  loss = 2587.61426 avg_loss = 4.37400\n",
            "epoch no.1 train no.1650  loss = 1742.52148 avg_loss = 4.37250\n",
            "epoch no.1 train no.1660  loss = 1682.49438 avg_loss = 4.36768\n",
            "epoch no.1 train no.1670  loss = 2524.32568 avg_loss = 4.36336\n",
            "epoch no.2 train no.1680  loss = 1676.34509 avg_loss = 4.35135\n",
            "epoch no.2 train no.1690  loss = 1764.91602 avg_loss = 4.35415\n",
            "epoch no.2 train no.1700  loss = 1736.79224 avg_loss = 4.34834\n",
            "epoch no.2 train no.1710  loss = 1675.61914 avg_loss = 4.34112\n",
            "epoch no.2 train no.1720  loss = 2610.65894 avg_loss = 4.33823\n",
            "epoch no.2 train no.1730  loss = 1765.28125 avg_loss = 4.33173\n",
            "epoch no.2 train no.1740  loss = 4211.72412 avg_loss = 4.32513\n",
            "epoch no.2 train no.1750  loss = 1719.65369 avg_loss = 4.31875\n",
            "epoch no.2 train no.1760  loss = 2607.14111 avg_loss = 4.31804\n",
            "epoch no.2 train no.1770  loss = 1653.12695 avg_loss = 4.31444\n",
            "epoch no.2 train no.1780  loss = 1683.11536 avg_loss = 4.30608\n",
            "epoch no.2 train no.1790  loss = 1728.86694 avg_loss = 4.29752\n",
            "epoch no.2 train no.1800  loss = 1718.50000 avg_loss = 4.29198\n",
            "epoch no.2 train no.1810  loss = 1739.23096 avg_loss = 4.28865\n",
            "epoch no.2 train no.1820  loss = 1703.74585 avg_loss = 4.28511\n",
            "epoch no.2 train no.1830  loss = 1714.25610 avg_loss = 4.28213\n",
            "epoch no.2 train no.1840  loss = 1682.44128 avg_loss = 4.28192\n",
            "epoch no.2 train no.1850  loss = 1673.09070 avg_loss = 4.27508\n",
            "epoch no.2 train no.1860  loss = 1656.47754 avg_loss = 4.26858\n",
            "epoch no.2 train no.1870  loss = 1684.23047 avg_loss = 4.26075\n",
            "epoch no.2 train no.1880  loss = 1665.89868 avg_loss = 4.25614\n",
            "epoch no.2 train no.1890  loss = 2509.84546 avg_loss = 4.25061\n",
            "epoch no.2 train no.1900  loss = 1742.55029 avg_loss = 4.24707\n",
            "epoch no.2 train no.1910  loss = 1575.00708 avg_loss = 4.24582\n",
            "epoch no.2 train no.1920  loss = 1670.21350 avg_loss = 4.24245\n",
            "epoch no.2 train no.1930  loss = 2455.56030 avg_loss = 4.24360\n",
            "epoch no.2 train no.1940  loss = 1648.80835 avg_loss = 4.24367\n",
            "epoch no.2 train no.1950  loss = 1660.06946 avg_loss = 4.24562\n",
            "epoch no.2 train no.1960  loss = 1664.55359 avg_loss = 4.24381\n",
            "epoch no.2 train no.1970  loss = 1734.90503 avg_loss = 4.24622\n",
            "epoch no.2 train no.1980  loss = 4413.22461 avg_loss = 4.24010\n",
            "epoch no.2 train no.1990  loss = 1652.23010 avg_loss = 4.23536\n",
            "epoch no.2 train no.2000  loss = 1669.89001 avg_loss = 4.23060\n",
            "592\n",
            "to_tokens: ['▁[', '▁', '▁', '▁너', '를', '▁', '이', '▁', '가', '▁', '▁', '의', '▁사랑', '해', '▁너', '야', '▁너', '를', '▁사랑', '해', '거', '를', '▁사랑', '해', '어', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '어', '아', '▁너', '를', '▁사랑', '해', '▁너', '해', '▁너', '를', '▁너', '를', '▁사랑', '를', '▁사랑', '해', '▁너', '별', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '는', '▁너', '를', '▁사랑', '를', '▁사랑', '를', '▁사랑', '해', '▁너', '▁세상', '에', '야', '해', '▁사랑', '해', '▁너', '를', '▁너', '를', '▁너', '해', '▁너', '해', '▁너', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '거', '▁사랑', '▁너', '별', '해', '야', '면', '▁너', '를', '▁사랑', '▁사랑', '해', '▁너', '▁세상', '▁사랑', '▁너', '를', '▁사랑', '해', '▁너', '해', '▁사랑', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '▁세상', '해', '거', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '해', '▁사랑', '▁너', '를', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁너', '해', '▁사랑', '를', '▁사랑', '해', '▁너', '▁너', '를', '▁사랑', '▁사랑', '해', '▁너', '▁사랑', '해', '▁너', '▁사랑', '해', '▁사랑', '별', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '해', '▁너', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁너', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁세상', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁세상', '▁사랑', '널', '▁사랑', '▁너', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁세상', '이', '▁사랑', '를', '해', '▁사랑', '해', '▁너', '해', '▁너', '를', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '▁사랑', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '해', '▁사랑', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁너', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁밤', '해', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '를', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '▁사랑', '▁사랑', '▁사랑', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '▁사랑', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑']\n",
            "너라면\n",
            "\n",
            "난\n",
            "\n",
            "너의 사랑이니 내가 싫어 너를 사랑했던거야 너를 사랑한 너를 사랑했었던 너를 사랑해 너를 사랑해 사랑해 너를\n",
            "\n",
            "사랑해 너는너를 사랑해 너를 사랑했잖아 너를\n",
            "\n",
            "사랑한 사랑해 너는 너는나를사랑해 이대로 너를 사랑해 너를 떠나는 나를 너를 너를사랑해 이 세상이야날 사랑해 너는 너는 사랑한 사랑해 사랑하고 나를 사랑해너를 사랑할 그도 이별이 지나면 너를 다시사랑해 이리 난 너를 사랑해 사랑해 너를 사랑해 너를 사랑하고 너를 사랑해 너를 사랑할걸 너를 사랑해 너를 사랑해 사랑해 너를사랑해 이별할 너를 사랑해 너를 사랑해 사랑해 너를사랑해 그 사랑해 너를 사랑해 사랑해줘 너는 너를 사랑하고 사랑해 사랑해 너를 사랑해도 너는 날 사랑해 내 사랑해 이 세상해 이 사랑해 사랑해 너를 사랑해 너를 사랑해 사랑해 사랑해 사랑해 너를 사랑해 사랑해 사랑해 너를 너를 사랑해 사랑해 이 날너를 사랑해 너를 사랑해 내게사랑해 사랑해 이대로 가면 너를 사랑해 사랑해 사랑해사랑해 사랑해 이 세상해 나 사랑해 사랑해 사랑해 나 사랑해 이 사랑해 사랑해 그 사랑해 사랑해 내 사랑해 사랑해 사랑해 너는 사랑해 사랑해 내 사랑해 사랑해도 너를 사랑해 사랑해 너를 사랑해 사랑해 나만해 너를 사랑해 사랑해 사랑해 사랑해해 이 사랑해 사랑해 너를 사랑 사랑해이 사랑해 너를 사랑해 사랑해줘 너를 사랑해 사랑해 사랑해 내 사랑해 사랑해 너를 사랑해 이 사랑해 사랑해 사랑해 사랑해 사랑해 이 사랑해 사랑해 이 사랑해 사랑해 너를 사랑해 사랑해 너를 사랑해 사랑해 사랑해 너는 사랑해 너를 사랑해 사랑해 우리 사랑해 사랑해 사랑해 사랑해 사랑해 너를 사랑해 사랑해 너를 사랑해 사랑해 사랑해 사랑해 사랑이 사랑해 사랑해 사랑해 사랑해 사랑해 나 사랑해 사랑해 사랑해 사랑해 나 너를 너를 사랑해 사랑해도 사랑해 사랑해 사랑해 너를 사랑해 사랑해사랑해 사랑해 사랑해 이 사랑해 사랑해이 밤 이대로 이 밤 사랑해 사랑해 너를 사랑해 너를 사랑해 사랑해 사랑해너를 사랑해 너만 사랑해 너를 사랑해 사랑해 사랑해 사랑해 사랑해 사랑해 사랑해 너만 사랑해 내 사랑을 사랑해 그 사랑해</s>\n",
            "epoch no.2 train no.2010  loss = 1586.46399 avg_loss = 4.23478\n",
            "epoch no.2 train no.2020  loss = 2659.23145 avg_loss = 4.22754\n",
            "epoch no.2 train no.2030  loss = 1662.50854 avg_loss = 4.22387\n",
            "epoch no.2 train no.2040  loss = 1637.35376 avg_loss = 4.22485\n",
            "epoch no.2 train no.2050  loss = 2539.58276 avg_loss = 4.21973\n",
            "epoch no.2 train no.2060  loss = 1660.61255 avg_loss = 4.21756\n",
            "epoch no.2 train no.2070  loss = 2499.68311 avg_loss = 4.21083\n",
            "epoch no.2 train no.2080  loss = 1622.18799 avg_loss = 4.20273\n",
            "epoch no.2 train no.2090  loss = 1722.11194 avg_loss = 4.20495\n",
            "epoch no.2 train no.2100  loss = 1633.30750 avg_loss = 4.19688\n",
            "epoch no.2 train no.2110  loss = 1661.27051 avg_loss = 4.19716\n",
            "epoch no.2 train no.2120  loss = 1671.49634 avg_loss = 4.19396\n",
            "epoch no.2 train no.2130  loss = 1681.65210 avg_loss = 4.18906\n",
            "epoch no.2 train no.2140  loss = 1656.56506 avg_loss = 4.18686\n",
            "epoch no.2 train no.2150  loss = 1686.08154 avg_loss = 4.18615\n",
            "epoch no.2 train no.2160  loss = 1657.08276 avg_loss = 4.17789\n",
            "epoch no.2 train no.2170  loss = 2537.72485 avg_loss = 4.17752\n",
            "epoch no.2 train no.2180  loss = 1638.53552 avg_loss = 4.17834\n",
            "epoch no.2 train no.2190  loss = 1628.34741 avg_loss = 4.18066\n",
            "epoch no.2 train no.2200  loss = 1686.53601 avg_loss = 4.17535\n",
            "epoch no.2 train no.2210  loss = 1663.72302 avg_loss = 4.17680\n",
            "epoch no.2 train no.2220  loss = 1707.26526 avg_loss = 4.17432\n",
            "epoch no.2 train no.2230  loss = 1581.45630 avg_loss = 4.17015\n",
            "epoch no.2 train no.2240  loss = 4040.89502 avg_loss = 4.16168\n",
            "epoch no.2 train no.2250  loss = 1784.25940 avg_loss = 4.16240\n",
            "epoch no.2 train no.2260  loss = 1667.73877 avg_loss = 4.15987\n",
            "epoch no.2 train no.2270  loss = 1612.86108 avg_loss = 4.16009\n",
            "epoch no.2 train no.2280  loss = 1693.42383 avg_loss = 4.16286\n",
            "epoch no.2 train no.2290  loss = 1679.04517 avg_loss = 4.17164\n",
            "epoch no.2 train no.2300  loss = 1745.27783 avg_loss = 4.17343\n",
            "epoch no.2 train no.2310  loss = 1685.53467 avg_loss = 4.16734\n",
            "epoch no.2 train no.2320  loss = 1737.25549 avg_loss = 4.16864\n",
            "epoch no.2 train no.2330  loss = 1703.13953 avg_loss = 4.16757\n",
            "epoch no.2 train no.2340  loss = 2451.07935 avg_loss = 4.16304\n",
            "epoch no.2 train no.2350  loss = 2419.50879 avg_loss = 4.16381\n",
            "epoch no.2 train no.2360  loss = 2507.15039 avg_loss = 4.16229\n",
            "epoch no.2 train no.2370  loss = 1633.21155 avg_loss = 4.16012\n",
            "epoch no.2 train no.2380  loss = 1684.34045 avg_loss = 4.16112\n",
            "epoch no.2 train no.2390  loss = 1582.23328 avg_loss = 4.15814\n",
            "epoch no.2 train no.2400  loss = 2477.94287 avg_loss = 4.15296\n",
            "epoch no.2 train no.2410  loss = 1576.07458 avg_loss = 4.15311\n",
            "epoch no.2 train no.2420  loss = 1626.55811 avg_loss = 4.14748\n",
            "epoch no.2 train no.2430  loss = 1619.90942 avg_loss = 4.14957\n",
            "epoch no.2 train no.2440  loss = 1553.58362 avg_loss = 4.15013\n",
            "epoch no.2 train no.2450  loss = 2496.07153 avg_loss = 4.14580\n",
            "epoch no.2 train no.2460  loss = 1696.09656 avg_loss = 4.14106\n",
            "epoch no.2 train no.2470  loss = 1706.96472 avg_loss = 4.13899\n",
            "epoch no.2 train no.2480  loss = 2566.22095 avg_loss = 4.14389\n",
            "epoch no.2 train no.2490  loss = 1699.49304 avg_loss = 4.14675\n",
            "epoch no.2 train no.2500  loss = 1717.48657 avg_loss = 4.15236\n",
            "701\n",
            "to_tokens: ['▁[', '▁', '▁', '게', '도', '러', '▁', '를', '▁', '자', '▁말', '하지', '▁', '를', '▁', '하지', '▁말', '했', '▁너', '를', '▁', '이', '▁', '원', '히', '▁너', '를', '▁', '▁', '해', '▁', '보', '▁너', '어', '▁너', '▁', '해', '▁너', '원', '히', '▁너', '의', '▁사랑', '보', '▁너', '의', '▁', '가', '▁너', '해', '▁너', '를', '▁사랑', '할', '▁', '▁너', '가', '며', '▁너', '▁', '해', '▁너', '▁너', '고', '▁싶어', '를', '▁사랑', '▁너', '▁', '▁', '하지', '▁수', '▁없는', '▁너', '젠', '▁너', '이', '▁', '게', '해', '▁수', '▁없는', '▁너', '를', '▁', '해', '▁너', '를', '▁', '에', '▁', '해', '▁너', '를', '▁', '걸', '▁너', '가', '는', '▁너', '를', '▁사랑', '를', '▁사랑', '해', '▁너', '해', '▁', '면', '▁너', '를', '▁사랑', '이', '▁너', '이', '▁너', '를', '▁사랑', '해', '▁', '나', '픈', '▁너', '▁수', '면', '에', '겐', '해', '▁', '르', '▁너', '이', '▁', '가', '▁너', '를', '▁사랑', '이', '▁수', '▁없는', '▁너', '▁사랑', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '워', '이', '▁너', '픈', '이', '▁', '르', '▁사랑', '해', '▁너', '해', '▁너', '이', '▁', '워', '이', '겐', '이', '▁', '를', '▁사랑', '이', '▁', '▁너', '를', '▁사랑', '에', '해', '▁사랑', '를', '▁사랑', '가', '▁너', '를', '▁사랑', '해', '▁너', '별', '이', '▁', '도', '▁너', '를', '▁사랑', '해', '▁사랑', '해', '▁', '면', '▁너', '를', '▁사랑', '해', '▁너', '해', '▁사랑', '이', '을', '고', '▁너', '와', '▁함께', '를', '▁사랑', '해', '▁', '를', '▁사랑', '이', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁', '도', '려', '▁너', '가', '마', '고', '▁사랑', '를', '▁사랑', '해', '▁너', '별', '이', '▁', '이', '도', '픈', '▁사랑', '해', '▁사랑', '해', '▁', '서', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '▁너', '를', '▁사랑', '해', '▁너', '해', '▁사랑', '해', '▁너', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁너', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁너', '해', '▁사랑', '면', '▁사랑', '▁너', '를', '▁사랑', '해', '▁사랑', '야', '▁사랑', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁수', '가', '▁너', '해', '▁너', '해', '▁사랑', '▁사랑', '해', '▁', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '별', '이', '▁', '나', '해', '▁너', '해', '▁사랑', '해', '▁사랑', '별', '이', '▁', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁너', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '별', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '별', '이', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '별', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁너', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁너', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁너', '해', '▁사랑', '해', '▁사랑', '▁없어', '▁너', '해', '▁사랑', '해', '▁사랑', '별', '▁사랑', '▁너', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁너', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '▁사랑']\n",
            "너라면 내 앞에서 이젠 너의\n",
            "\n",
            "말하지 말로 나를생각하지 못난 너의 눈빛으로 영원히 나의 마음을 사랑으로 바라며웃던 날 기억해 영원히 너를\n",
            "\n",
            "바라보는 너를\n",
            "\n",
            "떠나버린 사랑했던 너를사랑이 남아 떠나보던 날 기억해도 울고\n",
            "\n",
            "너를향한 내게말할 수 없는 이젠 눈물이 내\n",
            "\n",
            "사랑할 수 없는 너를 사랑해 너의 가슴을사랑해 너의모든 것을 떠나가는 너를너를 사랑한 사랑이지나면 너의 사랑한 사랑했던 나를 사랑이 너무 슬퍼질때문에 사랑이 흐린 눈물이\n",
            "\n",
            "떠나버린 너의사랑할 수 없는내겐 너를 사랑해 너를그리움에 슬픔이흐를 사랑해 사랑해 사랑이 그리움에 눈물이 나의 눈물이면 너의모습 사랑해 너를 떠나면 나를 사랑해 이별이 아직도 너를사랑해 사랑이지나면 너를사랑해 사랑해서 눈물만 울고 돌아와 나의 사랑이 너의 마음에 너를 사랑해너를사랑이 흘러내고 떠나지않고 나를 사랑해 이별이 날까지슬픈 사랑해 사랑이\n",
            "\n",
            "흘러라 사랑했던 너를 사랑하는 사랑해 너의 사랑해 너를 사랑해도너를사랑해 사랑해사랑해 내 사랑해너를\n",
            "\n",
            "사랑해 사랑해 사랑해 사랑해 너를 사랑해 사랑해 너를\n",
            "\n",
            "사랑해 사랑해 사랑해 사랑해 떠나지마 너를사랑한거야 내 사랑해 너의 사랑할 수 없는 사랑해 사랑해 내 사랑이 나를 사랑해 나의 사랑해너를\n",
            "\n",
            "사랑해 너를 사랑해 사랑해너를 사랑해 이별이 너무 사랑해 사랑해 사랑해 이별이사랑해 사랑해 너를 사랑해 사랑해 사랑해 너를 사랑해 사랑해 사랑해사랑해 사랑해 사랑해 이 내 사랑해 사랑해 사랑해도 이별이 너를 사랑해 사랑해 이대로 너를 사랑해 사랑해 너의 사랑해 사랑해 사랑해 사랑해 너를 사랑해 사랑해 사랑해 사랑해 내 사랑해 사랑해도 사랑해 사랑해 너를 사랑해 사랑해 사랑해 사랑해 사랑해 사랑할수는 사랑해 사랑해 이러면 너를 사랑해 사랑해 너를 사랑해 사랑해 사랑해 너를 사랑해 내\n",
            "\n",
            "사랑해 사랑해 사랑해 사랑해 너를 사랑해 나의 사랑해 너를 사랑해 너를 사랑해 사랑해 사랑해 사랑해 너를 사랑해 사랑해 사랑해그 너를 사랑해 사랑해 이별이 사랑해 사랑해 사랑해 사랑해 사랑해 사랑해 사랑해 너를 사랑해 사랑해 너를 사랑해 사랑해 사랑해 사랑해 사랑해 사랑해 사랑해 이 사랑해 너를 사랑해 너를 사랑해 사랑해 사랑해 너를 사랑해 사랑해 나만 사랑해 나를 사랑해 사랑해 너를 사랑해 사랑해 사랑해 사랑해 사랑해 사랑해 너를 사랑해 사랑해 너를 사랑해 사랑해 사랑해 사랑해 사랑해 너를 사랑해 사랑해 너를 \n",
            "epoch no.2 train no.2510  loss = 1671.23511 avg_loss = 4.16076\n",
            "epoch no.3 train no.2520  loss = 1646.63867 avg_loss = 4.15262\n",
            "epoch no.3 train no.2530  loss = 1546.67297 avg_loss = 4.14246\n",
            "epoch no.3 train no.2540  loss = 1600.97009 avg_loss = 4.13396\n",
            "epoch no.3 train no.2550  loss = 1561.33508 avg_loss = 4.12476\n",
            "epoch no.3 train no.2560  loss = 1636.19971 avg_loss = 4.12320\n",
            "epoch no.3 train no.2570  loss = 1597.64258 avg_loss = 4.12073\n",
            "epoch no.3 train no.2580  loss = 3906.69946 avg_loss = 4.10785\n",
            "epoch no.3 train no.2590  loss = 1504.86023 avg_loss = 4.09786\n",
            "epoch no.3 train no.2600  loss = 1528.13525 avg_loss = 4.08999\n",
            "epoch no.3 train no.2610  loss = 1674.56323 avg_loss = 4.08208\n",
            "epoch no.3 train no.2620  loss = 1595.36377 avg_loss = 4.08288\n",
            "epoch no.3 train no.2630  loss = 3951.56250 avg_loss = 4.08199\n",
            "epoch no.3 train no.2640  loss = 1626.72974 avg_loss = 4.07905\n",
            "epoch no.3 train no.2650  loss = 1689.69727 avg_loss = 4.08496\n",
            "epoch no.3 train no.2660  loss = 1593.06604 avg_loss = 4.07837\n",
            "epoch no.3 train no.2670  loss = 1607.34595 avg_loss = 4.07238\n",
            "epoch no.3 train no.2680  loss = 1656.15637 avg_loss = 4.06638\n",
            "epoch no.3 train no.2690  loss = 1609.01343 avg_loss = 4.06578\n",
            "epoch no.3 train no.2700  loss = 1571.72522 avg_loss = 4.06099\n",
            "epoch no.3 train no.2710  loss = 1547.38184 avg_loss = 4.05697\n",
            "epoch no.3 train no.2720  loss = 1631.31470 avg_loss = 4.06015\n",
            "epoch no.3 train no.2730  loss = 1603.32275 avg_loss = 4.05982\n",
            "epoch no.3 train no.2740  loss = 2427.03149 avg_loss = 4.05484\n",
            "epoch no.3 train no.2750  loss = 2365.47876 avg_loss = 4.05648\n",
            "epoch no.3 train no.2760  loss = 1630.34998 avg_loss = 4.05331\n",
            "epoch no.3 train no.2770  loss = 2368.22510 avg_loss = 4.05192\n",
            "epoch no.3 train no.2780  loss = 1548.73718 avg_loss = 4.05092\n",
            "epoch no.3 train no.2790  loss = 1591.76257 avg_loss = 4.05257\n",
            "epoch no.3 train no.2800  loss = 1537.90686 avg_loss = 4.04307\n",
            "epoch no.3 train no.2810  loss = 1583.62122 avg_loss = 4.04191\n",
            "epoch no.3 train no.2820  loss = 2427.39136 avg_loss = 4.03773\n",
            "epoch no.3 train no.2830  loss = 2349.57788 avg_loss = 4.03380\n",
            "epoch no.3 train no.2840  loss = 1617.03455 avg_loss = 4.03790\n",
            "epoch no.3 train no.2850  loss = 1606.10791 avg_loss = 4.03340\n",
            "epoch no.3 train no.2860  loss = 1548.56909 avg_loss = 4.02688\n",
            "epoch no.3 train no.2870  loss = 2401.39990 avg_loss = 4.03099\n",
            "epoch no.3 train no.2880  loss = 1622.38330 avg_loss = 4.02539\n",
            "epoch no.3 train no.2890  loss = 1691.84424 avg_loss = 4.02462\n",
            "epoch no.3 train no.2900  loss = 1659.22510 avg_loss = 4.01809\n",
            "epoch no.3 train no.2910  loss = 1645.57568 avg_loss = 4.01117\n",
            "epoch no.3 train no.2920  loss = 3881.97876 avg_loss = 4.00798\n",
            "epoch no.3 train no.2930  loss = 2383.24951 avg_loss = 4.00278\n",
            "epoch no.3 train no.2940  loss = 1624.44080 avg_loss = 3.99839\n",
            "epoch no.3 train no.2950  loss = 2436.02710 avg_loss = 4.00023\n",
            "epoch no.3 train no.2960  loss = 1624.21838 avg_loss = 4.01050\n",
            "epoch no.3 train no.2970  loss = 1613.45190 avg_loss = 4.00608\n",
            "epoch no.3 train no.2980  loss = 1580.43311 avg_loss = 4.00199\n",
            "epoch no.3 train no.2990  loss = 1648.91699 avg_loss = 4.00903\n",
            "epoch no.3 train no.3000  loss = 1595.08691 avg_loss = 4.00688\n",
            "101\n",
            "to_tokens: ['▁[', '▁', '▁', '를', '▁나', '라', '▁그', '▁나', '대', '▁사랑', '해', '야', '안', '해', '요', '▁그', '게', '도', '해', '▁그', '아', '요', '▁그', '이', '요', '▁그', '해', '요', '▁그', '대', '▁사랑', '▁사랑', '요', '댈', '여', '▁나', '해', '는', '▁할', '는', '▁그', '▁', '는', '▁그', '요', '마', '요', '▁나', '대', '는', '▁떠나', '가', '▁떠나', '지', '마', '하', '▁그', '▁떠나', '가', '마', '아', '요', '▁그', '▁날', '▁떠나', '▁떠나', '지', '는', '▁그', '대', '▁사랑', '해', '요', '▁그', '지', '▁말', '아', '요', '▁그', '해', '게', '요', '▁그', '대', '여', '요', '▁그', '지', '▁말', '아', '▁말', '요', '▁떠나', '지', '▁떠나', '는', '▁떠나', '해', '▁말', '아', '요', '▁그']\n",
            "너라면 나도 몰라요 그댈 사랑이 미안해요 힘들어 사랑이잖아요 사랑해요 사랑해요 그댈 위한걸 그대 때문에 왜 이제야\n",
            "\n",
            "이제는 내가 떠나는게 하지마요 그대는 떠나는 울지 못했던 날 떠나지 말아요 왜 날 위해 떠나가는 그댈 사랑해요 떠나가지 말아요 사랑할게요 그대여요 떠나지 말하지마요 떠나면 다시는 사랑한다는 말아요</s>\n",
            "epoch no.3 train no.3010  loss = 2420.82373 avg_loss = 3.99936\n",
            "epoch no.3 train no.3020  loss = 2278.42944 avg_loss = 3.99569\n",
            "epoch no.3 train no.3030  loss = 2395.80347 avg_loss = 3.99076\n",
            "epoch no.3 train no.3040  loss = 1546.30713 avg_loss = 3.99352\n",
            "epoch no.3 train no.3050  loss = 1595.04077 avg_loss = 3.99578\n",
            "epoch no.3 train no.3060  loss = 2386.88086 avg_loss = 3.99492\n",
            "epoch no.3 train no.3070  loss = 1556.58325 avg_loss = 3.99740\n",
            "epoch no.3 train no.3080  loss = 2535.29785 avg_loss = 3.99423\n",
            "epoch no.3 train no.3090  loss = 1681.29907 avg_loss = 4.00259\n",
            "epoch no.3 train no.3100  loss = 2377.78809 avg_loss = 3.99630\n",
            "epoch no.3 train no.3110  loss = 1618.92236 avg_loss = 3.99251\n",
            "epoch no.3 train no.3120  loss = 1574.63354 avg_loss = 3.98871\n",
            "epoch no.3 train no.3130  loss = 1532.36145 avg_loss = 3.98539\n",
            "epoch no.3 train no.3140  loss = 1525.39978 avg_loss = 3.98089\n",
            "epoch no.3 train no.3150  loss = 1648.99426 avg_loss = 3.97758\n",
            "epoch no.3 train no.3160  loss = 1571.94666 avg_loss = 3.97732\n",
            "epoch no.3 train no.3170  loss = 1611.26685 avg_loss = 3.98123\n",
            "epoch no.3 train no.3180  loss = 1564.76111 avg_loss = 3.97640\n",
            "epoch no.3 train no.3190  loss = 2305.17627 avg_loss = 3.97545\n",
            "epoch no.3 train no.3200  loss = 1546.40332 avg_loss = 3.97506\n",
            "epoch no.3 train no.3210  loss = 4028.52441 avg_loss = 3.97308\n",
            "epoch no.3 train no.3220  loss = 1546.35767 avg_loss = 3.97264\n",
            "epoch no.3 train no.3230  loss = 1560.91199 avg_loss = 3.97287\n",
            "epoch no.3 train no.3240  loss = 1645.41589 avg_loss = 3.97394\n",
            "epoch no.3 train no.3250  loss = 1586.17639 avg_loss = 3.97035\n",
            "epoch no.3 train no.3260  loss = 1625.98608 avg_loss = 3.96751\n",
            "epoch no.3 train no.3270  loss = 2339.27026 avg_loss = 3.96335\n",
            "epoch no.3 train no.3280  loss = 1539.39282 avg_loss = 3.95584\n",
            "epoch no.3 train no.3290  loss = 2377.15063 avg_loss = 3.95113\n",
            "epoch no.3 train no.3300  loss = 2502.64722 avg_loss = 3.95657\n",
            "epoch no.3 train no.3310  loss = 1606.24756 avg_loss = 3.96094\n",
            "epoch no.3 train no.3320  loss = 1582.68396 avg_loss = 3.96011\n",
            "epoch no.3 train no.3330  loss = 1580.74536 avg_loss = 3.96108\n",
            "epoch no.3 train no.3340  loss = 1552.34521 avg_loss = 3.95617\n",
            "epoch no.4 train no.3350  loss = 4104.85791 avg_loss = 3.95080\n",
            "epoch no.4 train no.3360  loss = 2325.17334 avg_loss = 3.94262\n",
            "epoch no.4 train no.3370  loss = 1573.95068 avg_loss = 3.93229\n",
            "epoch no.4 train no.3380  loss = 1561.91919 avg_loss = 3.92648\n",
            "epoch no.4 train no.3390  loss = 1514.11279 avg_loss = 3.91623\n",
            "epoch no.4 train no.3400  loss = 1535.63562 avg_loss = 3.90182\n",
            "epoch no.4 train no.3410  loss = 1497.99341 avg_loss = 3.90038\n",
            "epoch no.4 train no.3420  loss = 1498.40759 avg_loss = 3.89462\n",
            "epoch no.4 train no.3430  loss = 1522.04480 avg_loss = 3.88577\n",
            "epoch no.4 train no.3440  loss = 2226.66528 avg_loss = 3.88529\n",
            "epoch no.4 train no.3450  loss = 1535.12903 avg_loss = 3.88897\n",
            "epoch no.4 train no.3460  loss = 1559.06824 avg_loss = 3.88429\n",
            "epoch no.4 train no.3470  loss = 1655.05737 avg_loss = 3.87992\n",
            "epoch no.4 train no.3480  loss = 1488.58411 avg_loss = 3.87335\n",
            "epoch no.4 train no.3490  loss = 2359.54810 avg_loss = 3.86819\n",
            "epoch no.4 train no.3500  loss = 1514.05994 avg_loss = 3.86871\n",
            "701\n",
            "to_tokens: ['▁[', '▁', '▁', '▁너', '야', '▁', '▁', '만', '지', '대', '로', '▁있어', '요', '▁그', '게', '는', '하지', '줘', '▁그', '대', '▁사랑', '해', '▁그', '대', '에게', '젠', '을', '▁말', '은', '▁그', '대', '에게', '은', '▁사랑', '별', '을', '▁그', '대', '에게', '을', '▁말', '보', '▁그', '대', '는', '이', '걸', '▁알아', '별', '▁그', '는', '▁그', '▁번', '▁다시', '는', '▁그', '는', '만', '을', '▁', '해', '▁말', '하지', '요', '▁그', '대', '만', '▁그', '대', '만', '▁그', '는', '도', '▁그', '데', '해', '요', '대', '는', '만', '▁수', '▁없', '나', '요', '▁그', '해', '▁그', '대', '는', '▁그', '대', '는', '해', '▁수', '▁없', '데', '의', '▁사랑', '해', '▁그', '대', '는', '이', '▁그', '나', '요', '▁그', '대', '는', '▁그', '를', '▁사랑', '걸', '▁그', '▁있', '나', '요', '▁그', '대', '▁사랑', '해', '▁그', '대', '는', '해', '▁그', '대', '에게', '해', '요', '대', '여', '▁내', '대', '여', '▁그', '게', '요', '아', '요', '▁그', '대', '는', '로', '가', '을', '해', '요', '▁그', '대', '는', '을', '▁그', '지', '요', '나', '아', '요', '▁그', '대', '는', '▁그', '게', '곁', '▁그', '대', '는', '▁그', '게', '해', '대', '는', '▁그', '대', '여', '▁그', '게', '▁그', '대', '는', '▁그', '대', '는', '▁그', '지', '▁그', '를', '▁사랑', '파', '▁그', '대', '는', '▁그', '대', '여', '▁그', '대', '여', '을', '▁사랑', '대', '는', '인', '가', '요', '▁그', '대', '여', '▁그', '게', '▁말해', '해', '▁그', '대', '여', '▁그', '▁', '▁그', '대', '▁사랑', '해', '▁그', '▁그', '대', '여', '▁그', '보', '아', '▁그', '대', '여', '▁그', '젠', '▁그', '대', '는', '▁그', '게', '▁말해', '대', '여', '▁그', '를', '▁사랑', '해', '요', '대', '는', '▁내', '대', '는', '▁그', '게', '해', '▁그', '대', '여', '▁내', '대', '는', '▁그', '대', '는', '해', '▁그', '대', '는', '▁그', '고', '▁그', '대', '여', '곁', '▁그', '대', '여', '대', '는', '인', '대', '는', '해', '▁그', '대', '는', '▁그', '대', '는', '게', '에', '대', '는', '을', '▁그', '해', '대', '여', '을', '는', '▁그', '원', '히', '▁그', '대', '는', '▁내', '대', '여', '▁내', '▁그', '대', '여', '를', '대', '여', '곁', '▁내', '대', '는', '을', '▁', '곁', '을', '대', '는', '▁그', '대', '는', '해', '▁그', '▁그', '대', '는', '인', '가', '대', '여', '▁그', '대', '는', '▁그', '대', '는', '▁내', '게', '▁그', '▁그', '대', '는', '▁그', '▁그', '해', '대', '여', '▁그', '게', '▁말해', '대', '는', '▁그', '▁', '▁그', '해', '▁그', '대', '여', '▁그', '▁', '해', '대', '는', '▁그', '▁', '▁그', '▁그', '를', '▁사랑', '해', '대', '여', '▁그', '게', '▁그', '젠', '▁그', '대', '는', '을', '▁사랑', '대', '여', '을', '▁그', '게', '▁말', '아', '▁그', '대', '는', '▁그', '게', '곁', '을', '▁그', '해', '▁그', '대', '여', '▁내', '대', '여', '▁내', '대', '는', '▁그', '대', '는', '▁그', '게', '요', '와', '▁그', '대', '는', '▁그', '대', '는', '는', '▁그', '대', '는', '▁내', '대', '여', '▁그', '게', '해', '▁그', '대', '는', '▁그', '▁', '을', '▁그', '대', '는', '▁내', '대', '는', '▁그', '대', '는', '▁그', '대', '는', '▁그', '▁밤', '을', '▁그', '▁그', '대', '는', '▁내', '가', '▁그', '게', '▁그', '를', '는', '▁그', '대', '는', '▁그', '대', '여', '는', '▁그', '대', '는', '▁그', '대', '여', '▁그', '대', '여', '▁그', '게', '▁그', '대', '는', '게', '로', '어', '▁그', '대', '여', '▁그', '대', '여', '곁', '▁그', '해', '▁그', '대', '는', '대', '는', '▁내', '▁그', '▁그', '대', '는', '▁내', '▁', '▁내', '대', '는', '해', '▁그', '대', '는', '▁내', '대', '여', '▁그', '게', '해', '▁그', '대', '는', '▁내', '게', '▁그', '요', '▁그', '대', '는', '▁내', '게', '에', '▁그', '대', '여', '▁내', '게', '요', '▁그', '해', '▁그', '대', '여', '▁그', '게', '해', '대', '는', '▁그', '▁', '▁그', '대', '여', '을', '대', '는', '해', '▁그', '대', '는', '▁그', '▁그', '대', '는', '▁', '에', '▁그', '대', '는', '▁그', '해', '▁그', '대', '는', '▁그', '젠', '▁내', '▁그', '대', '는', '해', '▁그', '게', '▁그', '대', '는', '대', '는', '▁그', '대', '여', '▁내', '대', '는', '을', '▁그', '해', '▁그', '대', '여', '을', '대', '는', '게', '▁그', '대', '는', '▁그', '대', '는', '▁그', '대', '는', '린', '▁그', '대', '는', '▁내', '대', '는', '로', '오', '▁그', '대', '는', '▁그', '대', '▁사랑', '해', '▁그', '대', '는', '▁그', '대', '는', '▁그', '대', '는', '▁그', '대', '여', '▁그', '해', '대', '는', '▁그', '▁', '▁그', '을', '▁그', '대', '여', '▁그', '▁', '해', '▁그', '대', '는', '▁그', '대', '는', '해', '대', '여', '을', '▁그']\n",
            "너라면 지금이내게로는 그 말하고 있어도 내게말아요 그댈 사랑하는 그대 이별이란 말도그대만을 이별에그대만을 바라는 그대 뿐인걸 이젠\n",
            "\n",
            "다시는 한 번 다시는 다시 한번만을 사랑한다고 말아요 그대여 그대는 아파도 없는 사랑해 그대에게 할 수 있나요 사랑하는 그대와 그대 사랑할 수 없는 나를 기억해 그대뿐이었나요 그대여 나의 모든걸 알고 있나요 그댈 사랑했던 그대 사랑해 그대 사랑아 그대여 그대여 내게 말아요 그대에게 다신 사랑해요 그대만을 떠나가 없잖아요 그대여 내 겐 그대는 내사랑 그대는 그대는 내마음 그대여 그대는 떠나면 나를아파 그대는 그대는 그대만의 그대 여인가요 그대여 내게 사랑해 그대여 내 마음 그대를 사랑해요 그대 모습 바라보면 그대는 이젠 그대는 내게 그대여 나의 사랑해 그대는 그대는 내 사랑해 그대여 그대는 그대 사랑해 그대는 울고 그대 는 그대 그대뿐 그대 사랑해 그대는 그대 내 마음 그대만을 사랑 그대만 바라는 영원히 그대여 그대는 없는그대나 그대는 그대만 내 맘 그대는 그대 사랑해요 그대 여인 그대는 그대는 그대는 내\n",
            "\n",
            "마음에 그대여요 사랑 그대여 내게 그대는 내게 사랑해 그대 없는 내 사랑 그대여 내게로 나를\n",
            "\n",
            "사랑 그대여 내 마음 이젠 그대만을 그대만은 내게 말아 그대여 내 맘을 기억하는 그대는 그대여 그대는 그대는 내게 돌아여 그대는 그대 여린 그대여 그대는 내 사랑하는 그대여 내곁에 그대여 그대여 그대여 그대여 이 밤을 보면 그대는 떠나면 내게 요타는 그대는 그대 여에 그대여 그대여 그대는 내 마음그대 내게 주었던 그대는 그대 는 사랑해 그대 그대여 사랑해 그대여 내 게 그대 사랑해 그대는 그대는 내 사랑해 그대는 내게 말해요 그대여 내마음에그대는 내게 올 사랑해 그대는 내 사랑 그대는 내사랑 그대만 그대 사랑해 그대 사랑해 그대 내 마음 속에 그대여 사랑해 그대는 이 밤은 그대 사랑하는 내 게 그대 그대는 그대는 그대만을 사랑하는 그대만 그대 내게 그대여 그대는 그대 여리 그대는 그대에게 주지 그대는 그대를 사랑해 그대여 그대여 그대여 그대여 사랑 그대여 내게만을그대는 내 사랑해 그대는 그대사랑 그대만 하나뿐\n",
            "epoch no.4 train no.3510  loss = 1655.91028 avg_loss = 3.87122\n",
            "epoch no.4 train no.3520  loss = 1503.69617 avg_loss = 3.87145\n",
            "epoch no.4 train no.3530  loss = 2384.60962 avg_loss = 3.87195\n",
            "epoch no.4 train no.3540  loss = 1499.83215 avg_loss = 3.86699\n",
            "epoch no.4 train no.3550  loss = 1527.24622 avg_loss = 3.86058\n",
            "epoch no.4 train no.3560  loss = 2395.93604 avg_loss = 3.86520\n",
            "epoch no.4 train no.3570  loss = 1623.04077 avg_loss = 3.86284\n",
            "epoch no.4 train no.3580  loss = 1594.28162 avg_loss = 3.85586\n",
            "epoch no.4 train no.3590  loss = 2358.50366 avg_loss = 3.85215\n",
            "epoch no.4 train no.3600  loss = 1582.41345 avg_loss = 3.85583\n",
            "epoch no.4 train no.3610  loss = 1455.67908 avg_loss = 3.84835\n",
            "epoch no.4 train no.3620  loss = 1576.27368 avg_loss = 3.85251\n",
            "epoch no.4 train no.3630  loss = 2347.30591 avg_loss = 3.84942\n",
            "epoch no.4 train no.3640  loss = 1516.24500 avg_loss = 3.84367\n",
            "epoch no.4 train no.3650  loss = 1527.07458 avg_loss = 3.84232\n",
            "epoch no.4 train no.3660  loss = 1659.20520 avg_loss = 3.84461\n",
            "epoch no.4 train no.3670  loss = 1526.14233 avg_loss = 3.84518\n",
            "epoch no.4 train no.3680  loss = 1471.99133 avg_loss = 3.83799\n",
            "epoch no.4 train no.3690  loss = 2288.59814 avg_loss = 3.83681\n",
            "epoch no.4 train no.3700  loss = 1604.99805 avg_loss = 3.84310\n",
            "epoch no.4 train no.3710  loss = 1531.62390 avg_loss = 3.84587\n",
            "epoch no.4 train no.3720  loss = 1507.59119 avg_loss = 3.84360\n",
            "epoch no.4 train no.3730  loss = 2263.27710 avg_loss = 3.84258\n",
            "epoch no.4 train no.3740  loss = 2192.48242 avg_loss = 3.84445\n",
            "epoch no.4 train no.3750  loss = 2238.88525 avg_loss = 3.83700\n",
            "epoch no.4 train no.3760  loss = 2280.93286 avg_loss = 3.83927\n",
            "epoch no.4 train no.3770  loss = 1562.71472 avg_loss = 3.84440\n",
            "epoch no.4 train no.3780  loss = 1478.61829 avg_loss = 3.83922\n",
            "epoch no.4 train no.3790  loss = 1576.98535 avg_loss = 3.83594\n",
            "epoch no.4 train no.3800  loss = 1487.16760 avg_loss = 3.83005\n",
            "epoch no.4 train no.3810  loss = 2211.26685 avg_loss = 3.82774\n",
            "epoch no.4 train no.3820  loss = 1536.66882 avg_loss = 3.83087\n",
            "epoch no.4 train no.3830  loss = 3829.98975 avg_loss = 3.82409\n",
            "epoch no.4 train no.3840  loss = 1454.56238 avg_loss = 3.82656\n",
            "epoch no.4 train no.3850  loss = 1527.31213 avg_loss = 3.83053\n",
            "epoch no.4 train no.3860  loss = 2245.37964 avg_loss = 3.83200\n",
            "epoch no.4 train no.3870  loss = 1474.83740 avg_loss = 3.82715\n",
            "epoch no.4 train no.3880  loss = 1638.18433 avg_loss = 3.82826\n",
            "epoch no.4 train no.3890  loss = 2260.90698 avg_loss = 3.82303\n",
            "epoch no.4 train no.3900  loss = 1498.74707 avg_loss = 3.81782\n",
            "epoch no.4 train no.3910  loss = 1544.50549 avg_loss = 3.81172\n",
            "epoch no.4 train no.3920  loss = 2212.84644 avg_loss = 3.81560\n",
            "epoch no.4 train no.3930  loss = 1514.25415 avg_loss = 3.81465\n",
            "epoch no.4 train no.3940  loss = 2374.48193 avg_loss = 3.81767\n",
            "epoch no.4 train no.3950  loss = 2227.26758 avg_loss = 3.81826\n",
            "epoch no.4 train no.3960  loss = 1586.79248 avg_loss = 3.82121\n",
            "epoch no.4 train no.3970  loss = 1603.54651 avg_loss = 3.82587\n",
            "epoch no.4 train no.3980  loss = 3565.24341 avg_loss = 3.82551\n",
            "epoch no.4 train no.3990  loss = 1459.09229 avg_loss = 3.82158\n",
            "epoch no.4 train no.4000  loss = 1523.02808 avg_loss = 3.82391\n",
            "701\n",
            "to_tokens: ['▁[', '▁나', '▁너', '게', '는', '가', '와', '▁나', '의', '▁떠나', '고', '면', '▁', '게', '▁다', '가', '와', '▁나', '를', '▁', '게', '▁떠나', '별', '진', '워', '야', '▁너', '고', '▁너', '별', '▁떠나', '가', '잊', '와', '▁나', '대', '는', '▁나', '게', '▁다', '해', '▁그', '▁', '를', '▁떠나', '해', '▁말', '하고', '▁하는', '▁내', '해', '니까', '▁내', '대', '여', '▁내', '게', '▁말', '와', '▁나', '▁내', '를', '▁떠나', '가', '▁그', '돼', '▁그', '대', '여', '▁내', '▁내', '게', '▁다', '가', '와', '줘', '▁내', '게', '▁다', '하', '니까', '▁그', '가', '와', '▁나', '를', '을', '해', '▁사랑', '대', '여', '를', '▁사랑', '가', '면', '▁안', '를', '▁사랑', '가', '마', '▁나', '게', '▁다', '줘', '게', '▁말', '줘', '▁내', '▁내', '게', '▁말', '가', '와', '줘', '요', '를', '▁떠나', '가', '줘', '줘', '대', '▁내', '▁내', '를', '▁떠나', '가', '와', '줘', '요', '▁내', '해', '▁그', '요', '해', '줘', '해', '줘', '해', '▁사랑', '게', '▁돌아', '대', '▁내', '▁내', '대', '▁내', '▁나', '해', '▁사랑', '대', '여', '▁내', '대', '여', '▁나', '게', '해', '요', '대', '▁내', '게', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '게', '▁다', '줘', '요', '▁내', '를', '▁사랑', '가', '▁내', '게', '▁사랑', '게', '해', '▁그', '▁내', '해', '▁그', '대', '여', '를', '▁사랑', '해', '▁내', '해', '▁그', '게', '▁사랑', '해', '줘', '요', '해', '▁사랑', '▁사랑', '▁그', '게', '▁사랑', '▁내', '게', '▁말', '로', '줘', '게', '▁다', '▁내', '게', '▁사랑', '줘', '요', '▁그', '대', '여', '게', '서', '▁나', '를', '▁사랑', '해', '▁그', '게', '▁다', '가', '와', '▁나', '대', '▁내', '▁내', '를', '▁떠나', '해', '▁그', '게', '▁사랑', '▁내', '게', '▁사랑', '해', '▁사랑', '해', '▁그', '해', '▁그', '대', '는', '▁내', '해', '▁그', '대', '여', '▁내', '를', '▁사랑', '가', '요', '▁내', '해', '요', '▁내', '게', '▁다', '▁나', '대로', '이', '게', '▁사랑', '게', '▁사랑', '아', '▁말', '로', '▁내', '를', '▁사랑', '가', '와', '가', '와', '▁그', '대', '는', '해', '▁그', '를', '▁사랑', '해', '▁그', '▁사랑', '▁떠나', '▁그', '해', '▁사랑', '대', '▁내', '게', '▁다', '가', '와', '요', '▁사랑', '가', '와', '줘', '게', '▁사랑', '▁내', '게', '▁사랑', '가', '와', '▁나', '게', '▁사랑', '해', '▁사랑', '대', '▁내', '▁사랑', '▁다', '게', '▁그', '▁사랑', '해', '▁그', '게', '▁사랑', '대', '▁사랑', '게', '▁다', '▁내', '게', '▁사랑', '해', '가', '요', '게', '해', '▁그', '해', '▁내', '게', '▁사랑', '▁사랑', '를', '▁사랑', '해', '▁그', '대', '여', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '게', '▁돌아', '가', '와', '▁사랑', '게', '▁사랑', '아', '▁사랑', '를', '▁사랑', '해', '▁사랑', '게', '▁사랑', '줘', '요', '▁사랑', '게', '▁사랑', '면', '게', '▁사랑', '와', '▁내', '를', '▁떠나', '해', '▁그', '대', '▁내', '▁나', '대', '▁사랑', '게', '▁사랑', '대', '여', '게', '로', '▁다', '가', '와', '▁내', '해', '요', '게', '▁사랑', '▁사랑', '가', '와', '▁내', '게', '▁사랑', '게', '▁사랑', '대', '여', '▁사랑', '해', '▁그', '대', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '를', '대', '▁사랑', '를', '▁사랑', '해', '▁그', '▁내', '해', '요', '▁내', '게', '▁사랑', '해', '▁사랑', '해', '▁그', '해', '▁사랑', '대', '▁사랑', '게', '로', '▁사랑', '▁내', '를', '▁사랑', '가', '와', '해', '▁사랑', '▁그', '해', '▁사랑', '대', '▁사랑', '해', '▁그', '해', '▁사랑', '대', '▁사랑', '해', '▁내', '해', '▁내', '해', '▁사랑', '를', '▁사랑', '가', '▁말', '로', '네', '▁사랑', '를', '▁사랑', '면', '▁않아', '대', '▁사랑', '게', '해', '▁사랑', '해', '▁사랑', '게', '▁사랑', '▁떠나', '▁사랑', '와', '줘', '▁사랑', '대', '여', '▁사랑', '▁사랑', '해', '▁사랑', '대', '▁사랑', '▁떠나', '게', '면', '▁내', '게', '해', '▁내', '해', '요', '▁내', '게', '해', '▁그', '대', '여', '해', '해', '▁내', '게', '▁사랑', '▁말', '해', '대', '만', '▁내', '게', '▁사랑', '게', '해', '해', '▁그', '게', '▁사랑', '▁내', '해', '▁사랑', '해', '▁사랑', '게', '해', '▁사랑', '해', '▁사랑', '▁사랑', '이', '을', '해', '▁사랑', '해', '▁사랑', '게', '▁사랑', '해', '▁그', '대', '▁내', '▁내', '를', '▁떠나', '해', '▁그', '대', '▁내', '▁사랑', '가', '와', '게', '▁사랑', '러', '▁사랑', '가', '와', '가', '와', '▁내', '대', '▁사랑', '게', '해', '▁사랑', '대', '▁내', '해', '▁사랑', '게', '해', '▁사랑', '대', '▁사랑', '해', '▁사랑', '해', '▁내', '게', '▁사랑', '해', '▁내', '해', '▁사랑', '해', '▁그', '해', '▁사랑', '게', '▁사랑', '로', '가', '와', '▁내', '해', '▁사랑', '▁내', '해', '▁그', '▁그', '대', '▁사랑', '▁사랑', '대', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '대', '여', '해', '▁사랑', '게', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁내', '해', '▁사랑', '해', '▁내', '해', '▁내', '게', '▁사랑', '게', '▁사랑', '맘', '▁내', '대', '여', '게', '▁사랑', '해', '▁그', '▁내', '대', '▁사랑', '▁사랑', '해', '▁사랑', '대', '만', '해', '▁사랑', '게', '해', '▁사랑', '대', '여', '▁사랑', '게', '▁사랑', '해', '▁사랑', '해', '▁내']\n",
            "너라면 내게다가와 나를 떠나가고 내 게 다가와 나를 모르고이러 지워도 모르게이대로 다 가와 그대여 내게 사랑하는 사람 나를 사랑한다고 말해야 해 사랑하니까 그대는내게 돌아와줘 나를 떠나면 안돼 그대는 왜 내게 다가와줘 내게 말하니까 다가와 나만 사랑해 그대 나를 떠나보면 나를 떠나지마 내게해 내게 말해줘요 내게다가와줘 나를 떠나려해 그대는 나를 떠나가와줘요 사랑해줘 사랑해 사랑해 사랑해 내게 그대는 그대여 사랑해 그대여 그대와 내 사랑해 그대 내게 나를 사랑해 사랑해 내게 말해줘요 나를 떠나는 내게 내 사랑해요 사랑해 그대 나를 사랑해 사랑해 내게 말을 해줘 사랑해 이대로내게로 내게 말아 내게로 내게 말해줘요 그대 내게와 나를 사랑해 내 마음을 다가와 그대여 나를 사랑해 내게서 내게 사랑해 사랑해 사랑해 그대는 사랑해 그대여 나를 떠나줘요 사랑해요 내게와 이별 내게 내게 말하지 말로 나를 떠나가 떠나가면 그대 사랑해 나의 사랑해 이대로 나는 사랑해 그대 내게 다가줘요 떠나가와 내게서 내게 다가와 내게 사랑해 그대만이 내게데 사랑해 내게 그대 내게는 내게 다 떠나줘 내 사랑해 사랑해 내게만 나를 사랑해 그대 사랑해도 사랑해 사랑해 내게 다가오 내게 말은 나의 사랑해 내게 말해줘도 내게 오 내게 돌아와나를 사랑해 그대와 그대 내게 그대 내게로 다가와 사랑해 내게로 다가와 내게 내게 그대만 사랑해 그대 나의 사랑해 사랑해 나 그대나만 사랑해요 사랑해요 내게 사랑해 사랑해 사랑해 그대 내게 말로 나를 떠나가 사랑해요 사랑해 그대 사랑해 사랑해 그대 사랑해 사랑해 사랑해 나를 떠나지 말하니까 나를 떠나지 그대 내 사랑해 사랑해 내게로 다가와도 그대 내게 사랑해 그대여 내 게요 내 사랑해 사랑해요 내 사랑해 그대 사랑 사랑해 내게 이 말 그대여 내게 내 사랑 사랑해 내게요 사랑해 사랑해 내 사랑해 사랑해 이별만 사랑해 사랑해 내게 사랑해 그대여 나를 사랑해 그대만 떠나가 내게 서를 떠나가 떠나가네 그대 내 사랑해 그대 사랑해 내 사랑해 그대 사랑해 사랑해 내게 사랑해 사랑해 사랑해 사랑해 내게 말 다가와 사랑해요 사랑해요 그대만 그대만 사랑해 사랑해 그대 사랑해 내게 사랑해 사랑해 사랑해 사랑해 사랑해 사랑해 내게 내게 는 그대 내게 사랑해요 그대여 사랑해 그대 사랑해 내 사랑해 그대만 내게 사랑해 사랑해 사랑\n",
            "epoch no.4 train no.4010  loss = 1626.26514 avg_loss = 3.82761\n",
            "epoch no.4 train no.4020  loss = 1561.57837 avg_loss = 3.82897\n",
            "epoch no.4 train no.4030  loss = 1481.97717 avg_loss = 3.82964\n",
            "epoch no.4 train no.4040  loss = 1536.60034 avg_loss = 3.82811\n",
            "epoch no.4 train no.4050  loss = 1544.60425 avg_loss = 3.81803\n",
            "epoch no.4 train no.4060  loss = 1551.92419 avg_loss = 3.81554\n",
            "epoch no.4 train no.4070  loss = 1573.26758 avg_loss = 3.81197\n",
            "epoch no.4 train no.4080  loss = 1567.99316 avg_loss = 3.81040\n",
            "epoch no.4 train no.4090  loss = 1519.76465 avg_loss = 3.80715\n",
            "epoch no.4 train no.4100  loss = 1566.55750 avg_loss = 3.80671\n",
            "epoch no.4 train no.4110  loss = 1505.64807 avg_loss = 3.80300\n",
            "epoch no.4 train no.4120  loss = 1536.20923 avg_loss = 3.80462\n",
            "epoch no.4 train no.4130  loss = 1523.49683 avg_loss = 3.80213\n",
            "epoch no.4 train no.4140  loss = 1521.50012 avg_loss = 3.80334\n",
            "epoch no.4 train no.4150  loss = 1549.64111 avg_loss = 3.80285\n",
            "epoch no.4 train no.4160  loss = 1481.13818 avg_loss = 3.80104\n",
            "epoch no.4 train no.4170  loss = 1443.18896 avg_loss = 3.79780\n",
            "epoch no.4 train no.4180  loss = 1416.17017 avg_loss = 3.80655\n",
            "epoch no.5 train no.4190  loss = 1439.66248 avg_loss = 3.79758\n",
            "epoch no.5 train no.4200  loss = 2236.96436 avg_loss = 3.79015\n",
            "epoch no.5 train no.4210  loss = 1454.41162 avg_loss = 3.78656\n",
            "epoch no.5 train no.4220  loss = 1435.80872 avg_loss = 3.77893\n",
            "epoch no.5 train no.4230  loss = 1501.71362 avg_loss = 3.76629\n",
            "epoch no.5 train no.4240  loss = 1507.78442 avg_loss = 3.76581\n",
            "epoch no.5 train no.4250  loss = 1421.18164 avg_loss = 3.75094\n",
            "epoch no.5 train no.4260  loss = 1468.92419 avg_loss = 3.75271\n",
            "epoch no.5 train no.4270  loss = 1374.18030 avg_loss = 3.74667\n",
            "epoch no.5 train no.4280  loss = 1548.33655 avg_loss = 3.73857\n",
            "epoch no.5 train no.4290  loss = 1455.07446 avg_loss = 3.73112\n",
            "epoch no.5 train no.4300  loss = 1492.11060 avg_loss = 3.72546\n",
            "epoch no.5 train no.4310  loss = 1424.33984 avg_loss = 3.71531\n",
            "epoch no.5 train no.4320  loss = 2165.10547 avg_loss = 3.71567\n",
            "epoch no.5 train no.4330  loss = 1451.43286 avg_loss = 3.71585\n",
            "epoch no.5 train no.4340  loss = 2184.18042 avg_loss = 3.71572\n",
            "epoch no.5 train no.4350  loss = 1400.56604 avg_loss = 3.71286\n",
            "epoch no.5 train no.4360  loss = 3767.06519 avg_loss = 3.70911\n",
            "epoch no.5 train no.4370  loss = 1549.73083 avg_loss = 3.70734\n",
            "epoch no.5 train no.4380  loss = 1482.33838 avg_loss = 3.70401\n",
            "epoch no.5 train no.4390  loss = 1493.35315 avg_loss = 3.69937\n",
            "epoch no.5 train no.4400  loss = 2145.52734 avg_loss = 3.69476\n",
            "epoch no.5 train no.4410  loss = 1521.91553 avg_loss = 3.69857\n",
            "epoch no.5 train no.4420  loss = 1422.13550 avg_loss = 3.69470\n",
            "epoch no.5 train no.4430  loss = 1451.10217 avg_loss = 3.69127\n",
            "epoch no.5 train no.4440  loss = 1384.82288 avg_loss = 3.68720\n",
            "epoch no.5 train no.4450  loss = 1428.21692 avg_loss = 3.68675\n",
            "epoch no.5 train no.4460  loss = 1431.95459 avg_loss = 3.68303\n",
            "epoch no.5 train no.4470  loss = 1565.37061 avg_loss = 3.68857\n",
            "epoch no.5 train no.4480  loss = 2213.57495 avg_loss = 3.67984\n",
            "epoch no.5 train no.4490  loss = 2387.29150 avg_loss = 3.68144\n",
            "epoch no.5 train no.4500  loss = 2211.80811 avg_loss = 3.68270\n",
            "691\n",
            "to_tokens: ['▁[', '▁나', '▁', '가', '▁', '다', '보', '▁', '면', '▁', '가', '가', '▁', '워', '이', '▁', '▁', '오', '▁', '▁', '움', '이', '▁', '다', '▁않는', '▁그리', '을', '▁', '을', '▁', '으면', '도', '▁그리', '을', '신', '▁', '▁', '으면', '서', '▁', '도', '는', '▁', '대', '▁모습', '에', '▁그리', '▁그', '대', '는', '에', '▁나', '게', '로', '▁떠', '르', '는', '▁그', '도', '대', '▁모습', '에', '워', '도', '▁수', '가', '지', '▁같아', '▁같아', '▁그', '대', '▁모습', '은', '올', '나', '봐', '대', '는', '▁내', '워', '▁수', '가', '▁그', '대', '는', '나', '▁그', '▁그리', '해', '▁', '윈', '해', '▁그', '대', '는', '한', '지', '면', '의', '▁그', '에', '▁감', '파', '▁마음', '이', '▁아', '▁그', '▁그', '대', '▁모습', '게', '을', '에', '▁그', '대', '는', '▁그', '이', '▁아', '의', '▁사랑', '할', '▁수', '가', '나', '요', '▁그', '대', '는', '▁없지만', '▁그', '대', '▁모습', '▁그', '▁그', '대', '는', '▁없지만', '▁그', '게', '▁말', '직', '▁그', '▁그', '▁사랑', '요', '▁그', '대', '는', '▁나', '게', '▁말', '▁그', '대', '는', '이', '▁그', '대', '는', '린', '▁수', '▁없', '▁그', '대', '는', '▁내', '대', '는', '▁내', '이', '▁그', '나', '중', '히', '어요', '▁그', '의', '▁사랑', '대', '는', '이', '요', '▁그', '대', '는', '▁내', '▁걸', '▁나', '의', '▁사랑', '▁그', '대', '는', '▁내', '게', '▁말', '▁싶은', '지만', '▁그', '대', '는', '나', '▁그', '해', '▁나', '워', '도', '▁그', '▁그', '대', '는', '▁사랑', '는', '며', '▁그', '대', '는', '▁내', '▁그', '대', '는', '게', '▁그', '주', '다', '는', '▁내', '게', '속', '▁그', '고', '워', '▁수', '▁그', '대', '는', '▁그', '게', '▁그', '하', '▁그', '이', '▁그', '대', '는', '곁', '▁그', '▁그', '게', '▁그', '대', '는', '▁그', '해', '▁그', '▁그', '대', '는', '▁내', '대', '는', '대', '는', '의', '▁그', '대', '는', '곁', '▁그', '게', '속', '대', '는', '▁내', '▁그', '대', '는', '▁내', '▁수', '▁없어', '▁그', '▁그', '대', '는', '▁없지만', '의', '▁그', '▁그', '프', '▁그', '▁그', '에', '겐', '들', '▁그', '대', '는', '▁내', '게', '▁그', '▁그', '대', '는', '▁그', '게', '▁그', '대', '는', '의', '▁그', '▁그', '대', '는', '▁내', '게', '▁그', '도', '▁그', '의', '▁그', '대', '는', '가', '▁말', '요', '▁그', '대', '▁내', '▁그', '젠', '▁그', '대', '는', '의', '▁그', '이', '대', '는', '▁없지만', '처럼', '▁그', '대', '는', '▁내', '도', '대', '는', '▁그', '게', '는', '대', '는', '▁그', '는', '▁그', '대', '는', '게', '▁그', '해', '▁그', '▁그', '대', '는', '곁', '▁내', '▁수', '▁있', '▁그', '대', '는', '▁마음', '는', '▁그', '대', '는', '게', '▁그', '대', '▁내', '워', '▁그', '▁그', '▁그', '대', '는', '대', '는', '▁없지만', '대', '는', '▁내', '게', '▁말해', '▁내', '게', '▁그', '와', '▁그', '원', '히', '▁그', '대', '는', '곁', '▁내', '게', '▁말해', '은', '▁그', '대', '▁내', '곁', '▁그', '대', '는', '▁그', '게', '▁그', '▁그', '대', '▁내', '곁', '▁내', '게', '속', '에', '▁그', '워', '▁내', '▁그', '이', '▁내', '게', '▁그', '▁그', '대', '▁내', '게', '속', '▁그', '대', '는', '▁내', '대', '는', '▁그', '의', '▁사랑', '대', '▁내', '▁그', '대', '는', '▁내', '대', '는', '게', '는', '▁그', '▁내', '게', '은', '▁그', '젠', '곁', '가', '는', '대', '는', '이', '▁그', '대', '는', '▁내', '추', '▁', '지', '는', '▁그', '대', '는', '▁그', '대', '▁내', '▁', '는', '대', '는', '▁내', '대', '는', '▁내', '게', '지', '게', '는', '▁내', '▁그', '▁그', '대', '는', '▁그', '대', '는', '▁그', '의', '▁사랑', '대', '는', '가', '▁그', '▁그', '대', '는', '▁그', '▁그', '대', '는', '▁그', '해', '▁그', '대', '는', '게', '은', '에', '▁그', '대', '는', '▁내', '▁그', '대', '▁내', '▁내', '의', '▁그', '대', '는', '▁그', '▁그', '▁그', '대', '는', '이', '▁그', '대', '는', '▁그', '게', '는', '대', '는', '게', '▁그', '▁내', '▁', '속', '에', '▁그', '▁밤', '▁그', '게', '는', '▁그', '대', '는', '곁', '▁내', '대', '는', '▁그', '▁그', '대', '는', '▁그', '게', '지', '이', '▁그', '게', '▁그', '대', '▁내', '은', '▁그', '대', '는', '▁그', '로', '는', '▁그', '▁내', '게', '▁그', '대', '는', '▁그', '▁그', '대', '▁내', '▁그', '대', '는', '▁내', '대', '은', '에', '▁그', '들', '▁그', '대', '는', '▁그', '대', '▁내', '▁내', '게', '는', '▁내', '대', '는', '게', '는', '▁그', '다', '▁그', '대', '는', '▁내', '게', '▁그', '대', '는', '게', '▁말', '와', '▁그', '대', '는', '▁그', '게', '속', '대', '는', '▁그', '게', '속', '해', '▁그', '게', '▁그', '요', '▁내', '의', '▁그', '대', '는', '▁내', '▁그', '대', '는', '▁그']\n",
            "너라면하루가살다가 지나면 지나쳐도 그리움이 이렇게 찾아와도\n",
            "\n",
            "그리움에 살지 않는 가슴에 눈을감아도 눈부신을\n",
            "\n",
            "감고서 살아가면 그대 모습도 나는 그대모습은 내게로 흐르는 아직 그대 모습 그리워 할 수 없을 것만 같아 그대 모습 떠났나 그대는 지울 수 없었던 그대 생각에 내가 사랑이 야위어 그대 사랑하는지 나의 가슴을 아픈 마음이 남아서 그대 내맘속에 그대는 사랑이 나에게 말할 수 있나요 그대는 없지만 그대는 나는 그대는 내가 내게 오면 나는 너무나요 그대여 내게요 그대 사랑이 그대 여울 수 있게그대는 그대는 바람이 너무 소용없어 나의 그대 사랑해요 그대는 눈길을이 나의 마음을 그대는 내게 주고싶어요 그대 생각으로 사랑이 지워도 나는 그대에게로 살며 그대는 없지만 그대 내게 말해준다는 내 마음에 머물러울까 그대는 내게 말없이 사랑한다고 그대 는 지금 내게 그대는 사랑해도 그대는 그대 그대 나도 그대 는 내마음 그대는건 그대는 느낄 수 있어도 그대는 나의마음을 아픈 마음속에 잠을 그대는 내게도 그대는 내게 그대 나의 사랑을 그대는 내게 말해도 나의 그대 떠나지나요 그대는 이젠 그대 나의 사랑 그대는 바람처럼 그대는아직 그대여 내게 그대는 모르게 그대 내게 사랑이 이렇게 그대 는 알수 있을까 그대 내게 나는그대 내게 그대 그리워지 않아 그대 그대는 그대는 내게는 내게 돌아와 영원히 그대는 모르게 말은 그대 는 그대는 내게는 그대 는 내 마음속에 지는 너무 사랑이내게 이렇게 그대 내 마음은 그대는 그대는 나를 그대 모습 그대는 그대 내게는 지금 내마음 난 이 젠가 그대 사랑이 그대는 비에 머물다는 그대여 그대 내게 그대는 그대는 내게 내게는 나의 그대와 그대여나의 그대 눈가요 그대는 지금 그대는 사랑이그대 내 마음속에 그대는 나는 그대는 나의 그대는지 나는 그대 사랑이그대는 내게 그대내게는 내마음속을 이젠 내게는그대 는 그대는는 그대는 내 게 사랑이 내 마음 그대 모습 너무 그대는 외로이는 내 게 그대여 난 그대여 그대는 어떤 모습속에 잠처럼 그대는 그대는 내게는 그대 내게 말을 걷지만 그대는 내 마음 그대 내게 돌아와 그대는 내 마음 그대는 내마음 가득어 내게 말해는 나를 그대는 나는 그대는</s>\n",
            "epoch no.5 train no.4510  loss = 1397.78418 avg_loss = 3.67613\n",
            "epoch no.5 train no.4520  loss = 2239.02075 avg_loss = 3.68030\n",
            "epoch no.5 train no.4530  loss = 1434.17114 avg_loss = 3.68474\n",
            "epoch no.5 train no.4540  loss = 2160.69995 avg_loss = 3.67948\n",
            "epoch no.5 train no.4550  loss = 1417.22827 avg_loss = 3.67863\n",
            "epoch no.5 train no.4560  loss = 1411.98401 avg_loss = 3.67748\n",
            "epoch no.5 train no.4570  loss = 1481.66663 avg_loss = 3.66967\n",
            "epoch no.5 train no.4580  loss = 1461.31604 avg_loss = 3.67373\n",
            "epoch no.5 train no.4590  loss = 1467.52747 avg_loss = 3.67141\n",
            "epoch no.5 train no.4600  loss = 1495.66614 avg_loss = 3.67191\n",
            "epoch no.5 train no.4610  loss = 3565.19702 avg_loss = 3.67212\n",
            "epoch no.5 train no.4620  loss = 1482.93347 avg_loss = 3.67697\n",
            "epoch no.5 train no.4630  loss = 2264.52466 avg_loss = 3.67447\n",
            "epoch no.5 train no.4640  loss = 1465.94885 avg_loss = 3.66808\n",
            "epoch no.5 train no.4650  loss = 1455.00000 avg_loss = 3.66433\n",
            "epoch no.5 train no.4660  loss = 1457.30042 avg_loss = 3.66800\n",
            "epoch no.5 train no.4670  loss = 1518.34680 avg_loss = 3.66539\n",
            "epoch no.5 train no.4680  loss = 2142.19214 avg_loss = 3.66068\n",
            "epoch no.5 train no.4690  loss = 1407.29419 avg_loss = 3.65626\n",
            "epoch no.5 train no.4700  loss = 1412.64404 avg_loss = 3.65907\n",
            "epoch no.5 train no.4710  loss = 1445.16797 avg_loss = 3.65963\n",
            "epoch no.5 train no.4720  loss = 2114.34351 avg_loss = 3.65756\n",
            "epoch no.5 train no.4730  loss = 1234.37537 avg_loss = 3.65440\n",
            "epoch no.5 train no.4740  loss = 1419.39917 avg_loss = 3.64348\n",
            "epoch no.5 train no.4750  loss = 1465.33350 avg_loss = 3.64276\n",
            "epoch no.5 train no.4760  loss = 1529.36084 avg_loss = 3.65652\n",
            "epoch no.5 train no.4770  loss = 1523.28833 avg_loss = 3.65779\n",
            "epoch no.5 train no.4780  loss = 2109.80737 avg_loss = 3.65258\n",
            "epoch no.5 train no.4790  loss = 3712.27002 avg_loss = 3.65451\n",
            "epoch no.5 train no.4800  loss = 1424.69849 avg_loss = 3.65786\n",
            "epoch no.5 train no.4810  loss = 2095.20459 avg_loss = 3.65488\n",
            "epoch no.5 train no.4820  loss = 2234.29346 avg_loss = 3.64934\n",
            "epoch no.5 train no.4830  loss = 1443.42493 avg_loss = 3.64485\n",
            "epoch no.5 train no.4840  loss = 1474.87817 avg_loss = 3.64301\n",
            "epoch no.5 train no.4850  loss = 1416.69995 avg_loss = 3.64984\n",
            "epoch no.5 train no.4860  loss = 3754.87646 avg_loss = 3.64642\n",
            "epoch no.5 train no.4870  loss = 1507.75647 avg_loss = 3.63962\n",
            "epoch no.5 train no.4880  loss = 1512.65076 avg_loss = 3.64384\n",
            "epoch no.5 train no.4890  loss = 1493.39294 avg_loss = 3.64162\n",
            "epoch no.5 train no.4900  loss = 1390.10059 avg_loss = 3.63428\n",
            "epoch no.5 train no.4910  loss = 1957.65149 avg_loss = 3.63194\n",
            "epoch no.5 train no.4920  loss = 1430.43933 avg_loss = 3.62423\n",
            "epoch no.5 train no.4930  loss = 2121.97852 avg_loss = 3.62785\n",
            "epoch no.5 train no.4940  loss = 1429.05261 avg_loss = 3.63031\n",
            "epoch no.5 train no.4950  loss = 3531.28418 avg_loss = 3.63006\n",
            "epoch no.5 train no.4960  loss = 2169.28979 avg_loss = 3.62315\n",
            "epoch no.5 train no.4970  loss = 1585.95105 avg_loss = 3.62769\n",
            "epoch no.5 train no.4980  loss = 1516.11780 avg_loss = 3.63117\n",
            "epoch no.5 train no.4990  loss = 1478.34277 avg_loss = 3.64081\n",
            "epoch no.5 train no.5000  loss = 1476.16382 avg_loss = 3.64255\n",
            "701\n",
            "to_tokens: ['▁[', '▁내', '▁', '▁너', '를', '▁', '도', '▁마음', '은', '에', '▁', '를', '▁', '가', '는', '▁나', '▁너', '를', '▁사랑', '▁너', '를', '▁사랑', '싶', '마', '데', '에', '▁나는', '았', '▁나는', '▁너', '▁너', '를', '▁나는', '날', '어', '▁나는', '▁너', '▁너', '를', '▁나는', '보', '며', '▁나는', '▁너', '를', '▁나는', '▁너', '를', '▁나는', '하', '네', '▁나는', '▁나는', '▁너', '를', '▁나는', '▁너', '▁너', '를', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '를', '▁나는', '▁나는', '를', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '를', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '를', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '를', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는', '▁나는']\n",
            "너라면 나는 너는 나의 마음속에 너를 떠나가는 나는 너를 나는 너를 보고 고운 눈빛을 보면서 나는 나는 너를 떠났지 나는 나는 너를 바라보며 나는 너를 나는 너를 생각하네 나는 나는 너는 나는 나는 너는 나는 나는 나는 나는 너를 나는 너는 나는 나는 나는 나는 너를 나는 나는 나는 나는 나는 나는 나는 나는 나는 너는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 너는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는 나는\n",
            "epoch no.5 train no.5010  loss = 3748.91333 avg_loss = 3.63749\n",
            "epoch no.5 train no.5020  loss = 1432.63623 avg_loss = 3.62873\n",
            "epoch no.6 train no.5030  loss = 1402.33801 avg_loss = 3.62363\n",
            "epoch no.6 train no.5040  loss = 1563.33752 avg_loss = 3.62331\n",
            "epoch no.6 train no.5050  loss = 1410.60754 avg_loss = 3.61271\n",
            "epoch no.6 train no.5060  loss = 1396.27136 avg_loss = 3.60873\n",
            "epoch no.6 train no.5070  loss = 1360.93066 avg_loss = 3.59409\n",
            "epoch no.6 train no.5080  loss = 1330.07056 avg_loss = 3.58037\n",
            "epoch no.6 train no.5090  loss = 1408.81042 avg_loss = 3.57194\n",
            "epoch no.6 train no.5100  loss = 2130.94849 avg_loss = 3.56432\n",
            "epoch no.6 train no.5110  loss = 1479.20068 avg_loss = 3.56027\n",
            "epoch no.6 train no.5120  loss = 1443.71570 avg_loss = 3.55778\n",
            "epoch no.6 train no.5130  loss = 1491.79321 avg_loss = 3.55564\n",
            "epoch no.6 train no.5140  loss = 1393.92432 avg_loss = 3.54940\n",
            "epoch no.6 train no.5150  loss = 1439.08972 avg_loss = 3.54947\n",
            "epoch no.6 train no.5160  loss = 2268.79224 avg_loss = 3.54353\n",
            "epoch no.6 train no.5170  loss = 1431.96851 avg_loss = 3.54495\n",
            "epoch no.6 train no.5180  loss = 1377.58521 avg_loss = 3.54000\n",
            "epoch no.6 train no.5190  loss = 1373.83557 avg_loss = 3.53060\n",
            "epoch no.6 train no.5200  loss = 1314.94360 avg_loss = 3.51622\n",
            "epoch no.6 train no.5210  loss = 2107.95190 avg_loss = 3.50928\n",
            "epoch no.6 train no.5220  loss = 1500.09131 avg_loss = 3.51514\n",
            "epoch no.6 train no.5230  loss = 1390.09290 avg_loss = 3.51459\n",
            "epoch no.6 train no.5240  loss = 1490.57117 avg_loss = 3.52179\n",
            "epoch no.6 train no.5250  loss = 1466.19116 avg_loss = 3.52644\n",
            "epoch no.6 train no.5260  loss = 2013.84119 avg_loss = 3.52022\n",
            "epoch no.6 train no.5270  loss = 2077.52905 avg_loss = 3.52155\n",
            "epoch no.6 train no.5280  loss = 2087.53662 avg_loss = 3.52006\n",
            "epoch no.6 train no.5290  loss = 3434.68213 avg_loss = 3.51624\n",
            "epoch no.6 train no.5300  loss = 2034.22620 avg_loss = 3.50856\n",
            "epoch no.6 train no.5310  loss = 1432.65979 avg_loss = 3.51173\n",
            "epoch no.6 train no.5320  loss = 1473.83557 avg_loss = 3.51562\n",
            "epoch no.6 train no.5330  loss = 1177.62122 avg_loss = 3.50943\n",
            "epoch no.6 train no.5340  loss = 1475.32910 avg_loss = 3.51218\n",
            "epoch no.6 train no.5350  loss = 1402.22839 avg_loss = 3.50594\n",
            "epoch no.6 train no.5360  loss = 2155.84253 avg_loss = 3.50325\n",
            "epoch no.6 train no.5370  loss = 3099.24609 avg_loss = 3.49858\n",
            "epoch no.6 train no.5380  loss = 2122.63867 avg_loss = 3.49811\n",
            "epoch no.6 train no.5390  loss = 1510.36304 avg_loss = 3.50292\n",
            "epoch no.6 train no.5400  loss = 2141.66626 avg_loss = 3.50366\n",
            "epoch no.6 train no.5410  loss = 1308.75732 avg_loss = 3.50068\n",
            "epoch no.6 train no.5420  loss = 1326.17773 avg_loss = 3.49577\n",
            "epoch no.6 train no.5430  loss = 3343.06323 avg_loss = 3.49958\n",
            "epoch no.6 train no.5440  loss = 1433.83606 avg_loss = 3.49594\n",
            "epoch no.6 train no.5450  loss = 2053.17432 avg_loss = 3.48987\n",
            "epoch no.6 train no.5460  loss = 2181.82031 avg_loss = 3.51137\n",
            "epoch no.6 train no.5470  loss = 1479.89478 avg_loss = 3.50804\n",
            "epoch no.6 train no.5480  loss = 2293.66016 avg_loss = 3.51293\n",
            "epoch no.6 train no.5490  loss = 1431.64136 avg_loss = 3.51746\n",
            "epoch no.6 train no.5500  loss = 1335.76111 avg_loss = 3.52320\n",
            "205\n",
            "to_tokens: ['▁[', '▁', '▁', '▁', '했던', '▁', '▁', '▁몰', '▁', '주', '면', '▁', '▁너무', '▁미', '랐', '어', '어', '▁너', '의', '▁몰', '의', '▁사랑을', '▁말', '보', '야', '고', '▁너', '의', '▁마음', '로', '▁너', '의', '▁너무', '▁너', '는', '▁너', '▁미', '한', '의', '▁사랑', '해', '▁너', '▁사랑', '젠', '▁정말', '▁미', '안', '해', '▁너', '의', '▁마음', '▁몰', '줘', '▁너', '녕', '니', '▁너', '▁미', '안', '해', '▁너', '를', '▁마음', '을', '▁', '며', '▁너', '하지', '마', '▁말', '아', '요', '▁너', '의', '로', '아', '▁않아', '도', '의', '▁마음', '▁걸', '▁다', '해', '▁너', '▁너', '를', '▁마음', '속', '별', '▁너', '를', '▁나', '는', '▁너', '의', '▁사랑', '해', '▁너', '면', '마', '도', '넌', '▁나', '젠', '▁너', '의', '▁사랑', '해', '▁너', '를', '▁마음', '▁말', '줘', '도', '▁너', '를', '▁사랑', '해', '▁너', '널', '▁너', '의', '▁마음', '속', '겐', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁마음', '속', '▁사랑', '▁마음', '속', '▁곳', '에', '겐', '얀', '▁', '의', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁마음', '▁너', '프', '해', '▁너', '의', '▁마음', '▁너', '를', '▁마음', '▁말', '파', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너']\n",
            "너라면내가사랑한다 그땐 잘해주렴 난정말 몰랐었어 너는 나의 마음을바보내는 너의 말야 너는 알아 이제는 정말 좋아 너를 사랑해도 이젠 정말 미안해 나의마음을 알아도 안되니 내가 미안해너의 눈을\n",
            "\n",
            "보며 말하지는 말아줘 너에게 말하지 않아 나의 모든걸 사랑해도 너의 마음 이젠너는 모르니 너를 사랑해주지 않아 도 이젠 나를 사랑해 너의 마음을 알아봐도너를 사랑해 줘 나의 마음에겐 너를 사랑해 너의 마음도내 마음 깊은 곳에 하얀 너를 사랑해 너를 사랑해 너를 사랑해 너를 사랑해 너의 마음을 아파해 나의 마음을 너의 마음을 아파해 너를 사랑해 너를 사랑해 너를 사랑해 사랑해 너를 사랑해 너를 사랑해</s>\n",
            "epoch no.6 train no.5510  loss = 2075.49731 avg_loss = 3.51712\n",
            "epoch no.6 train no.5520  loss = 2132.83081 avg_loss = 3.52059\n",
            "epoch no.6 train no.5530  loss = 1422.01868 avg_loss = 3.51200\n",
            "epoch no.6 train no.5540  loss = 1391.59863 avg_loss = 3.50989\n",
            "epoch no.6 train no.5550  loss = 1382.06360 avg_loss = 3.50070\n",
            "epoch no.6 train no.5560  loss = 1316.66968 avg_loss = 3.50000\n",
            "epoch no.6 train no.5570  loss = 1334.21655 avg_loss = 3.50110\n",
            "epoch no.6 train no.5580  loss = 2079.03662 avg_loss = 3.50289\n",
            "epoch no.6 train no.5590  loss = 3657.77515 avg_loss = 3.50016\n",
            "epoch no.6 train no.5600  loss = 1488.06226 avg_loss = 3.48799\n",
            "epoch no.6 train no.5610  loss = 1550.25256 avg_loss = 3.48764\n",
            "epoch no.6 train no.5620  loss = 1368.74365 avg_loss = 3.47818\n",
            "epoch no.6 train no.5630  loss = 1290.99182 avg_loss = 3.48086\n",
            "epoch no.6 train no.5640  loss = 1404.68726 avg_loss = 3.47497\n",
            "epoch no.6 train no.5650  loss = 2019.78699 avg_loss = 3.48190\n",
            "epoch no.6 train no.5660  loss = 1903.54944 avg_loss = 3.47941\n",
            "epoch no.6 train no.5670  loss = 1398.65784 avg_loss = 3.48009\n",
            "epoch no.6 train no.5680  loss = 1334.93811 avg_loss = 3.47914\n",
            "epoch no.6 train no.5690  loss = 1382.42310 avg_loss = 3.47926\n",
            "epoch no.6 train no.5700  loss = 1360.85852 avg_loss = 3.47282\n",
            "epoch no.6 train no.5710  loss = 1489.01294 avg_loss = 3.47560\n",
            "epoch no.6 train no.5720  loss = 1529.26721 avg_loss = 3.47923\n",
            "epoch no.6 train no.5730  loss = 1339.55408 avg_loss = 3.48012\n",
            "epoch no.6 train no.5740  loss = 2266.69629 avg_loss = 3.48286\n",
            "epoch no.6 train no.5750  loss = 1384.21826 avg_loss = 3.47352\n",
            "epoch no.6 train no.5760  loss = 1348.06714 avg_loss = 3.47515\n",
            "epoch no.6 train no.5770  loss = 1252.59570 avg_loss = 3.47595\n",
            "epoch no.6 train no.5780  loss = 2112.60474 avg_loss = 3.47680\n",
            "epoch no.6 train no.5790  loss = 1251.69922 avg_loss = 3.47272\n",
            "epoch no.6 train no.5800  loss = 1451.53857 avg_loss = 3.47539\n",
            "epoch no.6 train no.5810  loss = 1353.84021 avg_loss = 3.47211\n",
            "epoch no.6 train no.5820  loss = 1424.33374 avg_loss = 3.47283\n",
            "epoch no.6 train no.5830  loss = 1310.36792 avg_loss = 3.46744\n",
            "epoch no.6 train no.5840  loss = 1457.41943 avg_loss = 3.46497\n",
            "epoch no.6 train no.5850  loss = 1992.19592 avg_loss = 3.46119\n",
            "epoch no.7 train no.5860  loss = 3325.84937 avg_loss = 3.45549\n",
            "epoch no.7 train no.5870  loss = 1218.56641 avg_loss = 3.44037\n",
            "epoch no.7 train no.5880  loss = 1395.63611 avg_loss = 3.43132\n",
            "epoch no.7 train no.5890  loss = 3150.66016 avg_loss = 3.42377\n",
            "epoch no.7 train no.5900  loss = 1229.07861 avg_loss = 3.41219\n",
            "epoch no.7 train no.5910  loss = 1306.20251 avg_loss = 3.40799\n",
            "epoch no.7 train no.5920  loss = 1266.52686 avg_loss = 3.39580\n",
            "epoch no.7 train no.5930  loss = 1884.86865 avg_loss = 3.38723\n",
            "epoch no.7 train no.5940  loss = 1433.60022 avg_loss = 3.38751\n",
            "epoch no.7 train no.5950  loss = 2120.99756 avg_loss = 3.38667\n",
            "epoch no.7 train no.5960  loss = 1334.84595 avg_loss = 3.38941\n",
            "epoch no.7 train no.5970  loss = 1419.15186 avg_loss = 3.38838\n",
            "epoch no.7 train no.5980  loss = 3252.01270 avg_loss = 3.37850\n",
            "epoch no.7 train no.5990  loss = 1243.94678 avg_loss = 3.37570\n",
            "epoch no.7 train no.6000  loss = 1374.83679 avg_loss = 3.37578\n",
            "372\n",
            "to_tokens: ['▁[', '▁나', '▁', '▁', '▁너', '은', '▁날', '▁날', '이', '▁', '▁', '가', '면', '▁', '▁', '▁싶은', '▁사랑', '▁모두', '▁', '파', '서', '▁사랑', '▁', '▁그', '들', '▁모두', '▁모두', '▁', '게', '에', '▁묻', '은', '▁말', '▁말', '한', '요', '대', '▁모습', '해', '▁', '▁모두', '▁', '와', '면', '파', '도', '▁', '말', '도', '▁없이', '하', '▁떠나', '▁번', '▁사랑', '▁말', '가', '가', '▁그', '신', '이', '서', '질', '▁수', '봐', '대', '는', '▁그', '해', '▁사랑', '대', '▁사랑', '까', '▁없', '▁사랑', '해', '▁사랑', '대', '▁사랑', '해', '▁그', '대를', '▁사랑', '해', '▁사랑', '해', '▁그', '대를', '▁사랑', '게', '해', '요', '대', '▁사랑', '▁사랑', '보', '▁보', '▁싶은', '가', '면', '▁그', '를', '▁사랑', '해', '▁그', '해', '▁사랑', '해', '▁그', '해', '▁사랑', '해', '▁그', '해', '▁그', '대', '▁사랑', '해', '▁그', '해', '▁그', '대', '▁사랑', '해', '▁그', '대를', '▁사랑', '해', '▁그', '대를', '▁사랑', '해', '▁그', '해', '▁그', '대', '▁사랑', '해', '▁그', '▁밤', '▁그', '▁말', '해', '▁그', '해', '▁사랑', '해', '▁그', '해', '▁그', '대를', '여', '게', '해', '▁그', '해', '▁그', '해', '▁사랑', '대', '▁사랑', '▁내', '▁사랑', '해', '▁그', '해', '▁사랑', '대를', '▁사랑', '해', '▁사랑', '해', '▁그', '해', '▁그', '해', '▁사랑', '대', '▁사랑', '해', '▁사랑', '대', '만', '▁', '▁', '해', '▁그', '대', '▁사랑', '해', '▁그', '대', '▁내', '해', '▁그', '해', '▁그', '대', '▁사랑', '해', '▁그', '대', '▁사랑', '해', '▁그', '대', '▁내', '▁내', '가', '가', '해', '▁사랑', '해', '▁그', '대', '▁내', '▁', '요', '대', '▁사랑', '▁사랑', '해', '▁그', '대', '▁사랑', '해', '▁사랑', '해', '▁사랑', '대', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁그', '대', '▁내', '▁', '▁사랑', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁그', '▁사랑', '▁', '▁사랑', '만', '▁사랑', '해', '▁사랑', '대', '여', '만', '▁사랑', '▁사랑', '해', '▁그', '게', '가', '▁그', '▁사랑', '꾸', '▁사랑', '대', '▁사랑', '▁밤', '서', '▁사랑', '해', '▁사랑', '대', '▁사랑', '보', '▁', '해', '▁사랑', '해', '▁사랑', '해', '▁그', '대', '▁사랑', '해', '▁사랑', '해', '▁그', '대를', '▁사랑', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '▁그', '해', '▁그', '대를', '▁사랑', '해', '▁그', '해', '▁그', '해', '▁그', '대', '▁사랑', '해', '▁사랑', '해', '▁사랑', '▁사랑', '만', '▁', '네', '▁사랑', '▁사랑', '해', '▁사랑', '대', '▁사랑', '해', '▁사랑', '해', '▁그', '▁사랑', '해', '▁그', '해', '▁그', '해', '▁사랑', '대', '▁사랑', '▁내']\n",
            "너라면 그런 날사랑했던 그말 모두\n",
            "\n",
            "모두\n",
            "\n",
            "떠나가 모두 다주고픈 날 너무 아파도 못했던 날들모두 다 내가슴에 말은 싫어사랑해그대 사랑은 모두 다가가 아파서 아무말도 못하게한사람이라고 떠나가면 다 신기 만질까 그대는 사랑해 그대를 볼 수 없어사랑해 그대를 사랑해 그댈 사랑해 사랑해 그대 내 사랑해 그대만 바라만 주고 떠나가면 나를 사랑해 사랑해 사랑해 사랑해 사랑해 사랑해 그대를 사랑해 사랑해 그대를 사랑해 그대를 사랑해 그댈 사랑해 사랑해 그대를 사랑해 이대로 이별해 사랑해 사랑해 사랑해 그대 내 사랑해 사랑해 사랑해 그대여 내사랑해 사랑해 그대를 사랑해 사랑해 사랑해 사랑해 그대 사랑해 그대 내\n",
            "\n",
            "게 사랑해 그대를 사랑해 그대 사랑해 사랑해 그대를 사랑해 그대 사랑해 그대는 한 여자 사랑해 사랑해 그대 내게 그대만 사랑해 그대를 사랑해 사랑해 그대를 사랑해요 사랑해 그대 내게요 사랑해요 사랑해 사랑해 내사랑해 사랑해요 내 마음을 하나만 사랑해 그대 나만 오 사랑해 내맘에자꾸그대 이기서 사랑해 그대 여에 기대 난 사랑해 사랑해 그대를 사랑해 사랑해 그대만\n",
            "\n",
            "사랑해 사랑해 사랑해 사랑해 그대 사랑해 사랑해 사랑해 그대를 사랑해 사랑해 이 마음에 있나고 사랑해 그대 사랑해 사랑해요 사랑해 사랑해 사랑해 그대여</s>\n",
            "epoch no.7 train no.6010  loss = 1367.98901 avg_loss = 3.36761\n",
            "epoch no.7 train no.6020  loss = 1353.96729 avg_loss = 3.37465\n",
            "epoch no.7 train no.6030  loss = 1920.83984 avg_loss = 3.37767\n",
            "epoch no.7 train no.6040  loss = 1307.79688 avg_loss = 3.36707\n",
            "epoch no.7 train no.6050  loss = 1435.41565 avg_loss = 3.36690\n",
            "epoch no.7 train no.6060  loss = 1259.40332 avg_loss = 3.36250\n",
            "epoch no.7 train no.6070  loss = 2026.80554 avg_loss = 3.36332\n",
            "epoch no.7 train no.6080  loss = 1417.32971 avg_loss = 3.35932\n",
            "epoch no.7 train no.6090  loss = 1319.89001 avg_loss = 3.35867\n",
            "epoch no.7 train no.6100  loss = 1396.02722 avg_loss = 3.35465\n",
            "epoch no.7 train no.6110  loss = 3556.94263 avg_loss = 3.35502\n",
            "epoch no.7 train no.6120  loss = 1383.71167 avg_loss = 3.35437\n",
            "epoch no.7 train no.6130  loss = 1281.09351 avg_loss = 3.35267\n",
            "epoch no.7 train no.6140  loss = 1394.46155 avg_loss = 3.35144\n",
            "epoch no.7 train no.6150  loss = 1258.91382 avg_loss = 3.34465\n",
            "epoch no.7 train no.6160  loss = 1451.35706 avg_loss = 3.34710\n",
            "epoch no.7 train no.6170  loss = 1348.40369 avg_loss = 3.34223\n",
            "epoch no.7 train no.6180  loss = 1267.41418 avg_loss = 3.33510\n",
            "epoch no.7 train no.6190  loss = 1235.05627 avg_loss = 3.34088\n",
            "epoch no.7 train no.6200  loss = 1261.61755 avg_loss = 3.33946\n",
            "epoch no.7 train no.6210  loss = 1280.52087 avg_loss = 3.33633\n",
            "epoch no.7 train no.6220  loss = 1869.30908 avg_loss = 3.33184\n",
            "epoch no.7 train no.6230  loss = 1306.01392 avg_loss = 3.33426\n",
            "epoch no.7 train no.6240  loss = 1412.73145 avg_loss = 3.33133\n",
            "epoch no.7 train no.6250  loss = 1294.19116 avg_loss = 3.32525\n",
            "epoch no.7 train no.6260  loss = 1248.10645 avg_loss = 3.32547\n",
            "epoch no.7 train no.6270  loss = 1350.94556 avg_loss = 3.32234\n",
            "epoch no.7 train no.6280  loss = 1341.27893 avg_loss = 3.32260\n",
            "epoch no.7 train no.6290  loss = 1394.39673 avg_loss = 3.32939\n",
            "epoch no.7 train no.6300  loss = 1360.48999 avg_loss = 3.33558\n",
            "epoch no.7 train no.6310  loss = 1209.52051 avg_loss = 3.33283\n",
            "epoch no.7 train no.6320  loss = 1486.03662 avg_loss = 3.34102\n",
            "epoch no.7 train no.6330  loss = 1320.14966 avg_loss = 3.34038\n",
            "epoch no.7 train no.6340  loss = 1289.61597 avg_loss = 3.34118\n",
            "epoch no.7 train no.6350  loss = 1789.94739 avg_loss = 3.33238\n",
            "epoch no.7 train no.6360  loss = 1266.91174 avg_loss = 3.33416\n",
            "epoch no.7 train no.6370  loss = 1271.42224 avg_loss = 3.33467\n",
            "epoch no.7 train no.6380  loss = 1434.93176 avg_loss = 3.33954\n",
            "epoch no.7 train no.6390  loss = 1279.85974 avg_loss = 3.34158\n",
            "epoch no.7 train no.6400  loss = 1234.49341 avg_loss = 3.34132\n",
            "epoch no.7 train no.6410  loss = 1819.48108 avg_loss = 3.32975\n",
            "epoch no.7 train no.6420  loss = 1258.59656 avg_loss = 3.33093\n",
            "epoch no.7 train no.6430  loss = 1909.27625 avg_loss = 3.33777\n",
            "epoch no.7 train no.6440  loss = 1314.72021 avg_loss = 3.33290\n",
            "epoch no.7 train no.6450  loss = 1234.57007 avg_loss = 3.33358\n",
            "epoch no.7 train no.6460  loss = 2044.75806 avg_loss = 3.33593\n",
            "epoch no.7 train no.6470  loss = 1368.91284 avg_loss = 3.33182\n",
            "epoch no.7 train no.6480  loss = 2036.52747 avg_loss = 3.34367\n",
            "epoch no.7 train no.6490  loss = 1050.83228 avg_loss = 3.33539\n",
            "epoch no.7 train no.6500  loss = 1383.01672 avg_loss = 3.33260\n",
            "182\n",
            "to_tokens: ['▁[', '▁나', '▁', '▁헤어', '▁사랑', '이', '▁', '니', '▁우리', '젠', '▁우리', '의', '▁슬', '▁', '▁돌아', '젠', '▁다시', '를', '▁', '워', '지', '▁해', '▁너', '를', '▁모르', '▁있', '어', '▁너', '를', '▁', '▁수', '가', '▁없는', '▁나', '를', '▁', '아', '이란', '이', '▁너', '를', '▁', '속', '▁너', '를', '▁떠나', '해', '줘', '▁나', '게', '은', '널', '▁너', '▁기억', '여', '▁내', '를', '▁', '해', '▁너', '를', '▁', '려', '도', '▁너', '를', '▁사랑', '해', '▁그', '를', '▁사랑', '해', '▁너', '해', '▁나', '를', '▁', '해', '▁너', '를', '▁사랑', '해', '▁나', '를', '▁', '가', '면', '▁해', '▁나', '를', '▁사랑', '울', '▁수', '가', '▁없어', '▁사랑', '를', '▁사랑', '해', '▁너', '▁세상', '이', '▁그', '대', '여', '▁나', '대', '도', '▁나', '를', '▁사랑', '해', '▁그', '해', '▁너', '대', '▁사랑', '▁나', '해', '▁너', '를', '▁사랑', '해', '▁너', '해', '▁나', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁이', '를', '▁사랑', '해', '▁사랑', '대', '여', '▁나', '를', '▁사랑', '해', '▁사랑', '젠', '▁너', '▁사랑', '를', '▁사랑', '해', '▁그', '대', '▁다시', '▁사랑', '를', '▁사랑', '해', '▁사랑', '해', '▁그', '를', '▁사랑', '해', '▁나']\n",
            "너라면 우리의 사랑이 라면\n",
            "\n",
            "이젠 너는 내게 이젠 너를 지우려 해 나도 알고 있었어 너를 볼 수가 없어 나를\n",
            "\n",
            "안녕 사랑해 너의기억해나를 기억해줘 내 사랑 은 그대여 나를 사랑해 나를 버려도 너를\n",
            "\n",
            "사랑해 너를\n",
            "\n",
            "사랑해 사랑해 나를 사랑해 너를사랑해 나를\n",
            "\n",
            "떠나가게 해 너를 지울 수가 없는 나를\n",
            "\n",
            "사랑해 이 밤도 그대여 그 모습도 나를 사랑해 사랑해 그대여 사랑해 너를 사랑해 사랑해 너를 사랑해 나를 사랑해 너를 사랑해 그대여 나를사랑해 이젠 다시\n",
            "\n",
            "나를 사랑해 그 번 다시 나를 사랑해 사랑해 너를 사랑해</s>\n",
            "epoch no.7 train no.6510  loss = 3446.24097 avg_loss = 3.33465\n",
            "epoch no.7 train no.6520  loss = 1989.94958 avg_loss = 3.32782\n",
            "epoch no.7 train no.6530  loss = 3194.62061 avg_loss = 3.33021\n",
            "epoch no.7 train no.6540  loss = 1912.38330 avg_loss = 3.32641\n",
            "epoch no.7 train no.6550  loss = 1317.21289 avg_loss = 3.32705\n",
            "epoch no.7 train no.6560  loss = 1303.59644 avg_loss = 3.32005\n",
            "epoch no.7 train no.6570  loss = 1291.46667 avg_loss = 3.31901\n",
            "epoch no.7 train no.6580  loss = 1436.70190 avg_loss = 3.31887\n",
            "epoch no.7 train no.6590  loss = 1417.24927 avg_loss = 3.32866\n",
            "epoch no.7 train no.6600  loss = 1396.77588 avg_loss = 3.33041\n",
            "epoch no.7 train no.6610  loss = 1366.93750 avg_loss = 3.33328\n",
            "epoch no.7 train no.6620  loss = 1371.74573 avg_loss = 3.33358\n",
            "epoch no.7 train no.6630  loss = 1264.08191 avg_loss = 3.33145\n",
            "epoch no.7 train no.6640  loss = 1426.90271 avg_loss = 3.32837\n",
            "epoch no.7 train no.6650  loss = 1268.04993 avg_loss = 3.32080\n",
            "epoch no.7 train no.6660  loss = 2036.83447 avg_loss = 3.32249\n",
            "epoch no.7 train no.6670  loss = 1356.53992 avg_loss = 3.31526\n",
            "epoch no.7 train no.6680  loss = 1250.99988 avg_loss = 3.32105\n",
            "epoch no.7 train no.6690  loss = 1317.36072 avg_loss = 3.32389\n",
            "epoch no.8 train no.6700  loss = 1999.11731 avg_loss = 3.30835\n",
            "epoch no.8 train no.6710  loss = 1234.97961 avg_loss = 3.30045\n",
            "epoch no.8 train no.6720  loss = 1263.63757 avg_loss = 3.28497\n",
            "epoch no.8 train no.6730  loss = 3585.44580 avg_loss = 3.28001\n",
            "epoch no.8 train no.6740  loss = 1903.68628 avg_loss = 3.26766\n",
            "epoch no.8 train no.6750  loss = 1272.87964 avg_loss = 3.26635\n",
            "epoch no.8 train no.6760  loss = 1335.35657 avg_loss = 3.25888\n",
            "epoch no.8 train no.6770  loss = 1245.96008 avg_loss = 3.24323\n",
            "epoch no.8 train no.6780  loss = 1808.16174 avg_loss = 3.23251\n",
            "epoch no.8 train no.6790  loss = 1167.47461 avg_loss = 3.21690\n",
            "epoch no.8 train no.6800  loss = 1248.98645 avg_loss = 3.22100\n",
            "epoch no.8 train no.6810  loss = 3282.53442 avg_loss = 3.22496\n",
            "epoch no.8 train no.6820  loss = 1270.71814 avg_loss = 3.22181\n",
            "epoch no.8 train no.6830  loss = 1291.86194 avg_loss = 3.21818\n",
            "epoch no.8 train no.6840  loss = 1263.64294 avg_loss = 3.21314\n",
            "epoch no.8 train no.6850  loss = 1934.93188 avg_loss = 3.20108\n",
            "epoch no.8 train no.6860  loss = 1379.37805 avg_loss = 3.20447\n",
            "epoch no.8 train no.6870  loss = 1348.95532 avg_loss = 3.19730\n",
            "epoch no.8 train no.6880  loss = 1846.80603 avg_loss = 3.20012\n",
            "epoch no.8 train no.6890  loss = 1942.16504 avg_loss = 3.19813\n",
            "epoch no.8 train no.6900  loss = 1988.32068 avg_loss = 3.19861\n",
            "epoch no.8 train no.6910  loss = 1900.79468 avg_loss = 3.20079\n",
            "epoch no.8 train no.6920  loss = 1323.40405 avg_loss = 3.20735\n",
            "epoch no.8 train no.6930  loss = 1764.81384 avg_loss = 3.21946\n",
            "epoch no.8 train no.6940  loss = 1232.61169 avg_loss = 3.20719\n",
            "epoch no.8 train no.6950  loss = 1212.30359 avg_loss = 3.19951\n",
            "epoch no.8 train no.6960  loss = 2093.97632 avg_loss = 3.20981\n",
            "epoch no.8 train no.6970  loss = 1281.14490 avg_loss = 3.20495\n",
            "epoch no.8 train no.6980  loss = 1349.93262 avg_loss = 3.20562\n",
            "epoch no.8 train no.6990  loss = 1306.65735 avg_loss = 3.19650\n",
            "epoch no.8 train no.7000  loss = 1188.13818 avg_loss = 3.19102\n",
            "209\n",
            "to_tokens: ['▁[', '▁나', '▁', '▁', '▁세상', '상', '▁', '▁', '▁몰', '랐', '▁', '를', '▁위해', '▁', '야', '만', '▁하는', '▁거', '니', '▁', '를', '▁', '▁걸', '▁다', '는', '▁', '하지', '진', '▁너', '의', '▁사랑', '▁울', '줄', '게', '▁너', '의', '▁위해', '해', '▁거', '야', '▁너', '의', '▁위해', '▁거', '▁말', '▁마음', '이', '야', '▁너', '를', '▁내', '▁위해', '▁', '어', '마', '▁너', '픔', '이', '▁', '고', '줄', '거', '▁너', '의', '▁위해', '▁거', '별', '이', '야', '▁너', '를', '▁위해', '라면', '▁너', '를', '▁내', '▁너', '의', '▁마음', '이', '▁줄', '▁수', '▁', '를', '▁위해서', '다면', '▁위해', '줘', '래', '▁너', '▁세상', '▁너', '를', '▁위해', '▁너', '▁너', '를', '▁위해', '지', '▁날', '의', '▁마음', '▁다', '를', '▁위해', '려', '래', '야', '▁너', '를', '만', '마', '▁너', '를', '▁사랑', '은', '▁너', '게', '▁받아', '▁있어', '▁너', '를', '▁위해', '야', '▁너', '▁너', '를', '▁위해', '▁울', '게', '▁주', '를', '▁위해', '▁거', '▁너', '▁너', '를', '▁나', '를', '▁사랑', '▁너', '기에', '어', '▁나', '를', '▁위한', '▁이', '별', '을', '▁사랑', '은', '▁너', '를', '▁위해', '할', '▁너', '를', '▁사랑', '▁이', '별', '▁너', '원', '히', '▁나', '를', '▁위해', '▁울', '▁받아', '▁울', '는', '▁해', '마', '▁너', '를', '▁위해', '▁나', '를', '▁사랑', '할', '▁뿐', '야', '▁너', '를', '▁사랑', '할', '▁수', '▁너', '를', '▁사랑', '속', '가', '▁너', '게', '할', '▁너', '를', '▁느끼', '▁울']\n",
            "너라면니이세이라면\n",
            "\n",
            "난 몰라 나를 어떻게 보내야만 하는 거야 나의 모든 걸너에게 말하겠지만너를 위해 해줄게 너를 사랑하는 거야 나를 위한 그 내사랑이야 너는 날 위해 울지마 슬픔을안아 줄래 나를 위한 이별이야 너를 위해서라면 너는 없어 나의 마음 다 줄래나를위한 사랑을 해 줄래 이젠 너를 위해서라면 너를 보내는 나의 마음 나를 버릴거야 너에게 하지마 너의 사랑은 내 사랑을 알고 있어 너를 위해서라면 해 나를 위해 내게 너를 위한 마음은 너는 나의 마음 알았어나를 위한 이별의 사랑은 너를 사랑은 너를 위한 이대로 영원히 나를 위해 사랑을위해\n",
            "\n",
            "떠나게 하지마 너를 알아 나의 사랑일거야 나의 사랑할래 너의 마음 다가 내 사랑은 너를 위해</s>\n",
            "epoch no.8 train no.7010  loss = 1245.75488 avg_loss = 3.19429\n",
            "epoch no.8 train no.7020  loss = 1377.98645 avg_loss = 3.19799\n",
            "epoch no.8 train no.7030  loss = 1224.12878 avg_loss = 3.20475\n",
            "epoch no.8 train no.7040  loss = 1238.85425 avg_loss = 3.20638\n",
            "epoch no.8 train no.7050  loss = 1244.33472 avg_loss = 3.20375\n",
            "epoch no.8 train no.7060  loss = 2007.01172 avg_loss = 3.21151\n",
            "epoch no.8 train no.7070  loss = 1307.45105 avg_loss = 3.19981\n",
            "epoch no.8 train no.7080  loss = 1882.53125 avg_loss = 3.19445\n",
            "epoch no.8 train no.7090  loss = 1226.94495 avg_loss = 3.19750\n",
            "epoch no.8 train no.7100  loss = 2994.63208 avg_loss = 3.19381\n",
            "epoch no.8 train no.7110  loss = 1214.47070 avg_loss = 3.18911\n",
            "epoch no.8 train no.7120  loss = 1312.93665 avg_loss = 3.19325\n",
            "epoch no.8 train no.7130  loss = 1326.14246 avg_loss = 3.19522\n",
            "epoch no.8 train no.7140  loss = 2058.77930 avg_loss = 3.18894\n",
            "epoch no.8 train no.7150  loss = 1885.90344 avg_loss = 3.19030\n",
            "epoch no.8 train no.7160  loss = 1225.42139 avg_loss = 3.18672\n",
            "epoch no.8 train no.7170  loss = 1110.87012 avg_loss = 3.18144\n",
            "epoch no.8 train no.7180  loss = 2015.59143 avg_loss = 3.18998\n",
            "epoch no.8 train no.7190  loss = 1330.62988 avg_loss = 3.18390\n",
            "epoch no.8 train no.7200  loss = 1065.53455 avg_loss = 3.16507\n",
            "epoch no.8 train no.7210  loss = 1417.44165 avg_loss = 3.17145\n",
            "epoch no.8 train no.7220  loss = 1821.12280 avg_loss = 3.16591\n",
            "epoch no.8 train no.7230  loss = 1385.71387 avg_loss = 3.15905\n",
            "epoch no.8 train no.7240  loss = 1880.30334 avg_loss = 3.15319\n",
            "epoch no.8 train no.7250  loss = 1180.46680 avg_loss = 3.14147\n",
            "epoch no.8 train no.7260  loss = 3223.94360 avg_loss = 3.15727\n",
            "epoch no.8 train no.7270  loss = 1828.29492 avg_loss = 3.15901\n",
            "epoch no.8 train no.7280  loss = 3365.02710 avg_loss = 3.16437\n",
            "epoch no.8 train no.7290  loss = 1342.21765 avg_loss = 3.16593\n",
            "epoch no.8 train no.7300  loss = 1380.16260 avg_loss = 3.16527\n",
            "epoch no.8 train no.7310  loss = 1323.86304 avg_loss = 3.15806\n",
            "epoch no.8 train no.7320  loss = 1290.13440 avg_loss = 3.16123\n",
            "epoch no.8 train no.7330  loss = 1851.52637 avg_loss = 3.16495\n",
            "epoch no.8 train no.7340  loss = 1342.80139 avg_loss = 3.16064\n",
            "epoch no.8 train no.7350  loss = 1214.97620 avg_loss = 3.16534\n",
            "epoch no.8 train no.7360  loss = 1296.89148 avg_loss = 3.16991\n",
            "epoch no.8 train no.7370  loss = 1943.02124 avg_loss = 3.17265\n",
            "epoch no.8 train no.7380  loss = 1194.59741 avg_loss = 3.17783\n",
            "epoch no.8 train no.7390  loss = 1405.64429 avg_loss = 3.18335\n",
            "epoch no.8 train no.7400  loss = 1282.45190 avg_loss = 3.17703\n",
            "epoch no.8 train no.7410  loss = 1245.36694 avg_loss = 3.17164\n",
            "epoch no.8 train no.7420  loss = 1199.95239 avg_loss = 3.17113\n",
            "epoch no.8 train no.7430  loss = 1220.29688 avg_loss = 3.16876\n",
            "epoch no.8 train no.7440  loss = 1263.50122 avg_loss = 3.17138\n",
            "epoch no.8 train no.7450  loss = 1397.54871 avg_loss = 3.17552\n",
            "epoch no.8 train no.7460  loss = 1308.06738 avg_loss = 3.17881\n",
            "epoch no.8 train no.7470  loss = 1328.97803 avg_loss = 3.17585\n",
            "epoch no.8 train no.7480  loss = 1231.50452 avg_loss = 3.17613\n",
            "epoch no.8 train no.7490  loss = 1333.48376 avg_loss = 3.17674\n",
            "epoch no.8 train no.7500  loss = 1719.22437 avg_loss = 3.17468\n",
            "180\n",
            "to_tokens: ['▁[', '▁', '▁', '▁나', '▁사랑', '려', '는', '▁하는데', '거', '야', '▁', '를', '▁', '면', '▁너', '건', '에게', '▁내', '를', '▁떠나', '면', '▁안', '돼', '▁안', '를', '▁안', '돼', '▁안', '를', '▁', '고', '▁살', '는', '▁울', '▁세상', '이란', '▁', '파', '할', '▁싶어', '▁', '를', '▁보내', '한', '▁너', '들이', '▁이제', '를', '▁보내', '▁나', '▁마음', '걸', '▁', '별', '을', '거', '니', '▁나', '별', '에서', '▁너', '를', '▁보내', '야', '▁떠나', '▁할', '파', '할', '께', '▁있어', '▁너', '를', '▁위해', '야', '▁해', '었', '지', '▁나', '를', '▁모습', '모', '습', '에', '▁', '는', '▁떠나', '를', '▁모습', '▁사랑', '▁이', '▁보내', '야', '▁싶어', '어', '▁나', '를', '▁보내', '▁후', '는', '의', '▁보내', '▁후', '에', '▁나', '▁너', '면', '▁싶었', '▁너', '젠', '▁나', '면', '마', '▁너', '를', '▁보내', '수', '▁없는', '▁이', '▁너', '별', '의', '에', '▁서', '파', '지', '▁했던', '▁너', '▁너', '를', '▁사랑', '야', '▁있어', '▁너', '별', '▁너', '별', '을', '▁말', '수', '▁없는', '거', '야', '▁너', '를', '▁모습', '▁', '▁너', '게', '▁이', '할', '수', '▁있어', '어', '▁너', '별', '은', '▁말', '할', '수', '▁있어', '▁너', '를', '▁사랑', '모', '습', '은', '▁있어', '▁아']\n",
            "너라면니 날 떠나가야 할 거야 나를 떠나면 그 사람인데 나를\n",
            "\n",
            "떠나면 안돼 너는 안돼너를 보내고 떠나고\n",
            "\n",
            "이별은아파하고 있어 너를 사랑했던 기억들을 너를 향한 내 모든걸 이별할테니 이 세상에서\n",
            "\n",
            "너를 보내고 싶어 아파할수 있어 나를 보내려 했었기에 너의 뒷모습은 이제는 너의 마지막을알아 보내고 싶었어 너를 보낸다 너를 보낸 후로 나는떠나고 있어 이젠 떠나지 않아 너를 볼수 없지만 난 이별속에 아프게 해도 나는 너를 보내고있어이대로 이별을할수 없는거야 너의 모습을 나는네게 말할수있어 이별을 말할수 있어 나의 뒷모습이기에</s>\n",
            "epoch no.8 train no.7510  loss = 1066.09790 avg_loss = 3.16696\n",
            "epoch no.8 train no.7520  loss = 1204.87830 avg_loss = 3.16426\n",
            "epoch no.8 train no.7530  loss = 1942.47046 avg_loss = 3.17320\n",
            "epoch no.9 train no.7540  loss = 1867.01672 avg_loss = 3.16719\n",
            "epoch no.9 train no.7550  loss = 1922.30603 avg_loss = 3.16008\n",
            "epoch no.9 train no.7560  loss = 1975.06848 avg_loss = 3.15108\n",
            "epoch no.9 train no.7570  loss = 1283.49060 avg_loss = 3.14292\n",
            "epoch no.9 train no.7580  loss = 1258.03284 avg_loss = 3.12980\n",
            "epoch no.9 train no.7590  loss = 1168.92847 avg_loss = 3.11082\n",
            "epoch no.9 train no.7600  loss = 1274.62537 avg_loss = 3.10708\n",
            "epoch no.9 train no.7610  loss = 1236.11951 avg_loss = 3.10455\n",
            "epoch no.9 train no.7620  loss = 1137.69495 avg_loss = 3.09340\n",
            "epoch no.9 train no.7630  loss = 1373.80420 avg_loss = 3.08466\n",
            "epoch no.9 train no.7640  loss = 1187.30310 avg_loss = 3.07860\n",
            "epoch no.9 train no.7650  loss = 2919.00317 avg_loss = 3.06397\n",
            "epoch no.9 train no.7660  loss = 3054.18896 avg_loss = 3.06025\n",
            "epoch no.9 train no.7670  loss = 1983.78625 avg_loss = 3.04536\n",
            "epoch no.9 train no.7680  loss = 1215.29163 avg_loss = 3.03229\n",
            "epoch no.9 train no.7690  loss = 1223.34924 avg_loss = 3.04275\n",
            "epoch no.9 train no.7700  loss = 1209.78735 avg_loss = 3.05454\n",
            "epoch no.9 train no.7710  loss = 1251.88623 avg_loss = 3.04755\n",
            "epoch no.9 train no.7720  loss = 1198.98901 avg_loss = 3.05455\n",
            "epoch no.9 train no.7730  loss = 1799.55078 avg_loss = 3.04839\n",
            "epoch no.9 train no.7740  loss = 1060.49084 avg_loss = 3.05397\n",
            "epoch no.9 train no.7750  loss = 1811.46155 avg_loss = 3.05001\n",
            "epoch no.9 train no.7760  loss = 1824.35913 avg_loss = 3.04397\n",
            "epoch no.9 train no.7770  loss = 1157.79028 avg_loss = 3.04067\n",
            "epoch no.9 train no.7780  loss = 3369.15015 avg_loss = 3.04265\n",
            "epoch no.9 train no.7790  loss = 1109.85938 avg_loss = 3.03815\n",
            "epoch no.9 train no.7800  loss = 1990.90405 avg_loss = 3.03659\n",
            "epoch no.9 train no.7810  loss = 1944.28821 avg_loss = 3.03030\n",
            "epoch no.9 train no.7820  loss = 1230.54077 avg_loss = 3.02859\n",
            "epoch no.9 train no.7830  loss = 1169.70959 avg_loss = 3.02172\n",
            "epoch no.9 train no.7840  loss = 1903.60205 avg_loss = 3.03195\n",
            "epoch no.9 train no.7850  loss = 1308.65149 avg_loss = 3.03762\n",
            "epoch no.9 train no.7860  loss = 1225.24951 avg_loss = 3.03447\n",
            "epoch no.9 train no.7870  loss = 1807.53308 avg_loss = 3.03550\n",
            "epoch no.9 train no.7880  loss = 1365.75854 avg_loss = 3.04097\n",
            "epoch no.9 train no.7890  loss = 1185.87793 avg_loss = 3.04027\n",
            "epoch no.9 train no.7900  loss = 982.94373 avg_loss = 3.03123\n",
            "epoch no.9 train no.7910  loss = 1208.86243 avg_loss = 3.02656\n",
            "epoch no.9 train no.7920  loss = 1198.21753 avg_loss = 3.02762\n",
            "epoch no.9 train no.7930  loss = 1856.99963 avg_loss = 3.02545\n",
            "epoch no.9 train no.7940  loss = 1122.54041 avg_loss = 3.02239\n",
            "epoch no.9 train no.7950  loss = 1153.02820 avg_loss = 3.01819\n",
            "epoch no.9 train no.7960  loss = 1207.44446 avg_loss = 3.02361\n",
            "epoch no.9 train no.7970  loss = 1227.05518 avg_loss = 3.02447\n",
            "epoch no.9 train no.7980  loss = 1304.84387 avg_loss = 3.01816\n",
            "epoch no.9 train no.7990  loss = 1305.04993 avg_loss = 3.02600\n",
            "epoch no.9 train no.8000  loss = 1871.48291 avg_loss = 3.02804\n",
            "245\n",
            "to_tokens: ['▁[', '▁', '▁', '▁수', '▁없는', '겠', '니', '▁', '발', '▁', '도', '를', '▁사랑', '인', '▁', '게', '속', '엔', '▁너', '의', '▁', '다', '고', '▁말', '하고', '지', '지', '▁', '▁', '▁알고', '▁수', '▁왜', '▁말', '▁사랑', '고', '▁', '서', '의', '▁', '을', '에', '▁', '픔', '이', '▁', '마', '했', '▁너', '젠', '▁나', '의', '▁', '야', '▁', '▁하는', '▁나', '가', '▁내', '▁', '속', '에', '▁남아', '▁', '의', '▁지', '워', '야', '렸', '어', '봐', '▁나', '의', '▁사랑', '로', '▁', '의', '▁사랑', '픔', '을', '▁너', '가', '▁', '지', '▁나', '대', '을', '▁나', '의', '▁모습', '▁나', '의', '▁', '픔', '을', '▁나', '워', '▁나', '▁마음', '▁너', '는', '지', '의', '▁사랑', '하는', '단', '▁', '로', '▁', '고', '▁있어', '▁내', '▁마음', '속', '삭', '▁너', '서', '▁너', '의', '▁', '▁', '▁', '픔', '▁미소', '가', '고', '▁있어', '▁내', '젠', '의', '▁되어', '▁슬', '서', '▁너', '의', '▁사랑', '하고', '어', '지', '▁너', '의', '▁마음', '속', '별', '▁너', '▁이상', '▁나', '픔', '을', '▁슬', '을', '었', '▁슬', '파', '서', '▁', '의', '▁떠나', '리', '▁해', '어', '▁너', '의', '▁', '픔', '이', '▁', '대', '▁', '▁눈에', '워', '▁나', '로', '▁아니', '▁마음', '속', '에', '▁너', '픔', '이', '▁', '픔', '이', '에', '▁', '를', '▁슬', '▁', '▁', '고', '▁싶어', '의', '▁슬', '을', '▁떠나', '파', '▁내', '▁나', '의', '▁슬', '픔', '▁사랑', '가', '▁', '고', '▁슬', '가', '▁내', '▁내', '▁마음', '속', '에', '▁슬', '파', '거', '▁떠나', '▁사랑', '고', '▁내', '▁마음', '속', '▁슬', '야', '</s>']\n",
            "너라면할 수 없겠지 제가 없어 나의 사람을 내 마음속엔 너를 보낸다고 말했었지 내 마음을 알면서 그댈 안고싶어 너의집가에 슬픔을 아라\n",
            "\n",
            "했지만 이젠 나를 떠나려야 했던 네가 내\n",
            "\n",
            "마음속에 가득\n",
            "\n",
            "너를 지워버렸나봐 나의 눈물로나의 슬픔을 네게 돌아오는 그 사람과 너의 마음을 너의 슬픔을 비친 내마음을 아는 너를사랑한단 말로 울고 있지만 내마음 속엔 남아서 너의 눈물 속에슬픈 노래 부르고 있지만 이별이 너무 많아서 너를 사랑했었어나의 마음 이젠더이상슬픔의 아픔이 너무 아파서 나를 울게 했어 너의 슬픔의 그저 두려서 눈물이 내 마음속에슬픔에 슬픔속에 너의 모습이흘러 지나고 나의 아픔을 아파와 나의 슬픈 미소로\n",
            "\n",
            "울고 떠나던가 내 마음속에 아픈 노래를울지만 내마음은 아니야</s>\n",
            "epoch no.9 train no.8010  loss = 1231.75793 avg_loss = 3.03313\n",
            "epoch no.9 train no.8020  loss = 3275.68457 avg_loss = 3.03866\n",
            "epoch no.9 train no.8030  loss = 1203.70093 avg_loss = 3.03888\n",
            "epoch no.9 train no.8040  loss = 1321.58923 avg_loss = 3.04508\n",
            "epoch no.9 train no.8050  loss = 1243.66797 avg_loss = 3.04844\n",
            "epoch no.9 train no.8060  loss = 1285.10266 avg_loss = 3.05146\n",
            "epoch no.9 train no.8070  loss = 1811.73193 avg_loss = 3.06484\n",
            "epoch no.9 train no.8080  loss = 1143.46545 avg_loss = 3.06132\n",
            "epoch no.9 train no.8090  loss = 1099.08093 avg_loss = 3.05438\n",
            "epoch no.9 train no.8100  loss = 1173.21155 avg_loss = 3.04752\n",
            "epoch no.9 train no.8110  loss = 1370.61792 avg_loss = 3.05211\n",
            "epoch no.9 train no.8120  loss = 1312.29102 avg_loss = 3.05334\n",
            "epoch no.9 train no.8130  loss = 1150.25525 avg_loss = 3.06064\n",
            "epoch no.9 train no.8140  loss = 1157.44360 avg_loss = 3.05469\n",
            "epoch no.9 train no.8150  loss = 1810.85571 avg_loss = 3.05318\n",
            "epoch no.9 train no.8160  loss = 1202.40161 avg_loss = 3.04605\n",
            "epoch no.9 train no.8170  loss = 1742.38232 avg_loss = 3.05299\n",
            "epoch no.9 train no.8180  loss = 1866.26245 avg_loss = 3.06031\n",
            "epoch no.9 train no.8190  loss = 1138.12537 avg_loss = 3.06528\n",
            "epoch no.9 train no.8200  loss = 1270.60669 avg_loss = 3.06632\n",
            "epoch no.9 train no.8210  loss = 1242.50928 avg_loss = 3.07341\n",
            "epoch no.9 train no.8220  loss = 1107.53369 avg_loss = 3.06800\n",
            "epoch no.9 train no.8230  loss = 1231.39502 avg_loss = 3.06325\n",
            "epoch no.9 train no.8240  loss = 1220.70898 avg_loss = 3.05533\n",
            "epoch no.9 train no.8250  loss = 1295.14307 avg_loss = 3.05585\n",
            "epoch no.9 train no.8260  loss = 1109.25146 avg_loss = 3.03696\n",
            "epoch no.9 train no.8270  loss = 1384.96899 avg_loss = 3.03552\n",
            "epoch no.9 train no.8280  loss = 2839.13525 avg_loss = 3.02595\n",
            "epoch no.9 train no.8290  loss = 2954.30981 avg_loss = 3.03287\n",
            "epoch no.9 train no.8300  loss = 1182.74084 avg_loss = 3.02722\n",
            "epoch no.9 train no.8310  loss = 3063.42212 avg_loss = 3.04057\n",
            "epoch no.9 train no.8320  loss = 1179.69604 avg_loss = 3.04512\n",
            "epoch no.9 train no.8330  loss = 1238.25659 avg_loss = 3.04446\n",
            "epoch no.9 train no.8340  loss = 1019.24408 avg_loss = 3.03210\n",
            "epoch no.9 train no.8350  loss = 1765.52307 avg_loss = 3.02487\n",
            "epoch no.9 train no.8360  loss = 3104.32056 avg_loss = 3.02927\n",
            "epoch no.10 train no.8370  loss = 1062.28394 avg_loss = 3.02431\n",
            "epoch no.10 train no.8380  loss = 1168.57996 avg_loss = 3.01484\n",
            "epoch no.10 train no.8390  loss = 1939.14136 avg_loss = 3.00627\n",
            "epoch no.10 train no.8400  loss = 1236.30359 avg_loss = 3.00037\n",
            "epoch no.10 train no.8410  loss = 1100.56348 avg_loss = 2.99166\n",
            "epoch no.10 train no.8420  loss = 1196.28906 avg_loss = 2.97519\n",
            "epoch no.10 train no.8430  loss = 1135.53589 avg_loss = 2.96663\n",
            "epoch no.10 train no.8440  loss = 1118.46814 avg_loss = 2.96251\n",
            "epoch no.10 train no.8450  loss = 1211.34082 avg_loss = 2.95614\n",
            "epoch no.10 train no.8460  loss = 1314.20227 avg_loss = 2.95089\n",
            "epoch no.10 train no.8470  loss = 1168.04114 avg_loss = 2.94897\n",
            "epoch no.10 train no.8480  loss = 1216.70093 avg_loss = 2.93530\n",
            "epoch no.10 train no.8490  loss = 1179.88623 avg_loss = 2.92594\n",
            "epoch no.10 train no.8500  loss = 1147.60828 avg_loss = 2.92557\n",
            "701\n",
            "to_tokens: ['▁[', '▁나', '▁', '▁사랑', '▁수', '▁없', '나', '아', '▁', '대', '여', '다', '대', '▁수', '▁있', '나', '아', '요', '▁나', '▁', '이', '파', '▁수', '야', '▁', '게', '▁그', '▁', '준', '도', '▁그', '대', '▁', '▁아', '파', '서', '▁나', '대', '도', '▁괜찮', '파', '요', '▁아', '대', '▁', '대', '▁다', '만', '▁내가', '해', '▁내', '▁그', '▁떠나', '봐', '요', '▁날', '대', '여', '를', '▁떠나', '리', '▁말', '래', '요', '▁그', '마', '▁사랑', '도', '대', '▁내', '게', '▁말해', '줘', '▁그', '파', '도', '▁아', '게', '은', '▁사람', '▁', '▁바라', '게', '서', '줘', '요', '▁그', '대', '▁내', '▁모르', '는', '▁그', '를', '▁더', '▁그', '대', '▁내', '▁나', '게', '▁말해', '줘', '▁그', '젠', '▁나', '를', '▁사랑', '가', '▁말', '아', '요', '▁그', '해', '▁그', '▁그', '게', '▁말해', '줘', '▁그', '대', '▁내', '한', '▁수', '▁있', '나', '요', '▁그', '를', '▁사랑', '해', '▁나', '▁사랑', '▁그', '맘', '▁그', '대', '여', '▁내', '▁사랑', '해', '요', '▁그', '를', '▁사랑', '▁걸', '▁다', '▁', '지', '▁말', '아', '요', '▁그', '대', '▁내', '게', '▁말해', '줘', '▁그', '▁사랑', '해', '▁그', '▁그', '대', '▁내', '해', '▁아', '파', '지', '▁말해', '요', '▁그', '해', '▁내', '파', '하는', '▁아', '해', '▁말해', '도', '▁그', '파', '지', '▁말', '아', '요', '▁그', '대', '▁사랑', '해', '▁말해', '를', '대', '여', '로', '▁바라', '는', '▁내', '만으로', '▁', '봐', '▁그', '게', '▁말해', '▁그', '해', '요', '▁그', '게', '▁말해', '▁아', '해', '▁아', '를', '▁사랑', '해', '요', '해', '요', '▁아', '프', '▁내', '이', '는', '게', '▁말해', '요', '▁그', '를', '대', '▁내', '▁아', '파', '해', '요', '▁그', '게', '▁말해', '줘', '요', '▁사랑', '대', '▁내', '게', '▁말해', '요', '▁내', '▁그', '▁말해', '요', '▁사랑', '파', '요', '▁내', '게', '▁말해', '요', '요', '▁사랑', '해', '요', '▁내', '게', '▁말해', '요', '▁그', '대', '▁내', '해', '요', '▁내', '해', '게', '▁사랑', '게', '▁아', '게', '▁말해', '요', '▁사랑', '해', '요', '▁사랑', '대', '▁내', '게', '▁말해', '요', '▁그', '프', '요', '▁그', '해', '요', '▁사랑', '해', '만', '이', '▁그', '도', '▁사랑', '▁사랑', '해', '요', '▁그', '▁사랑', '▁말해', '요', '▁사랑', '대', '여', '▁내', '▁내', '대', '는', '▁말해', '요', '요', '▁내', '게', '▁말해', '요', '▁그', '게', '▁말해', '요', '▁사랑', '▁사랑', '▁말해', '요', '▁내', '해', '요', '대', '▁사랑', '▁내', '게', '▁말해', '요', '▁내', '해', '요', '▁사랑', '해', '요', '▁내', '해', '▁사랑', '▁내', '게', '해', '▁사랑', '▁내', '게', '▁내', '▁바라', '봐', '▁내', '대', '▁사랑', '해', '요', '대', '여', '게', '▁말해', '요', '▁그', '해', '▁사랑', '대', '▁사랑', '게', '▁말해', '요', '▁사랑', '파', '지', '▁내', '게', '▁말해', '도', '▁내', '대', '▁내', '게', '▁말해', '요', '▁사랑', '파', '서', '▁아', '게', '▁말해', '요', '▁내', '해', '요', '▁사랑', '대', '▁내', '해', '▁사랑', '해', '요', '▁내', '해', '요', '▁내', '해', '요', '해', '요', '▁내', '게', '해', '요', '▁내', '게', '해', '요', '해', '요', '▁그', '대', '▁내', '해', '▁그', '게', '▁말해', '요', '▁내', '해', '▁사랑', '해', '▁사랑', '▁사랑', '해', '▁사랑', '해', '요', '해', '▁사랑', '▁내', '게', '▁말해', '도', '▁사랑', '해', '▁사랑', '▁그', '게', '▁말해', '요', '▁아', '파', '다', '▁내', '도', '▁사랑', '해', '요', '해', '▁사랑', '▁그', '게', '▁말해', '요', '▁내', '게', '▁말해', '요', '▁사랑', '해', '해', '▁사랑', '▁그', '대', '▁사랑', '▁내', '해', '요', '해', '▁사랑', '▁사랑', '게', '▁말해', '요', '▁사랑', '대', '▁하나', '▁내', '▁내', '대', '여', '▁사랑', '게', '▁말해', '로', '▁그', '해', '요', '▁내', '대', '▁사랑', '▁사랑', '봐', '▁내', '게', '▁말해', '도', '▁내', '▁하나', '▁사랑', '게', '▁말해', '요', '▁아', '해', '▁사랑', '▁사랑', '게', '▁말해', '요', '▁내', '게', '▁말해', '▁내', '해', '▁사랑', '대', '여', '▁내', '게', '▁말해', '요', '▁내', '게', '해', '요', '▁내', '해', '요', '▁사랑', '▁사랑', '▁말해', '요', '▁사랑', '게', '해', '요', '▁내', '게', '▁말해', '도', '▁사랑', '게', '▁말해', '요', '요', '▁내', '해', '▁사랑', '해', '요', '▁내', '요', '요', '▁내', '게', '해', '요', '▁사랑', '해', '요', '▁그', '를', '▁사랑', '해', '▁사랑', '해', '▁사랑', '대', '여', '해', '▁사랑', '해', '게', '해', '▁사랑', '▁그', '파', '▁사랑', '대', '▁내', '게', '▁말해', '요', '▁내', '게', '▁말해', '요', '▁내', '해', '요', '▁그', '대', '▁사랑', '▁내', '▁내', '해', '▁사랑', '해', '요', '▁사랑', '대', '▁내', '▁내', '게', '▁말해', '줘', '요', '▁내', '해', '요', '해', '▁사랑', '해', '▁사랑', '해', '▁사랑', '대', '여', '게', '해', '요', '▁사랑', '해', '▁사랑', '해', '▁사랑', '해', '요', '대', '여', '▁내', '대', '여', '▁내', '게', '▁말해', '요', '▁사랑', '해', '▁사랑', '도', '▁사랑', '게', '▁말해', '요', '▁내', '게', '▁말해', '도', '▁사랑', '프', '요', '요', '▁사랑', '해', '요', '해', '▁사랑', '원', '히', '▁내', '게', '▁말해', '요', '▁사랑', '해', '도', '▁내', '대', '▁내', '▁내', '게', '▁말해', '해', '요', '해', '요', '해', '▁사랑']\n",
            "너라면 다시 볼 수 있잖아그대 떠난 그럴 수 있잖아요 내 마음 아플거야\n",
            "\n",
            "내 마음 다 해봐요 그대도아파했던 그 날도 아파도 그대 그 기억 하나요 사랑이 나를 지켜봐요 그대 나를 울리지 않을게요 아픈 사랑 그대 내게 말해요 아파도 내 사랑한 사람만 내게 말해줘요 그대밖에 모르죠 나보다 더 그대는 내게 말해요 이젠나를떠나가지 말아요 사랑해요 내게 말해요 그대 행복 할 수 있나요 나를 사랑하는 내 사랑 도 그대여 날 사랑해요 나의 모든 걸 다주지 말아요 그대내게 말해요 내 사랑은 난 그대 사랑은 아프게 말해요 사랑은 아파도 사랑한다고 말해요 아프지 말아요 그대를 사랑한다고 나 그대에게만 바라보는것 다 해요 내게요 사랑해요 내게도 사랑도 나를 사랑해 사랑해도 아픈 눈물로 내게 말해요 나 그대도 아 사랑해요 내게 말해줘요 그대 내게 말해요 나에게 말해요 아나요 내게 말해봐도 사랑해요 내게말해요 그대 사랑해요 사랑 내 게 내 게 내게 말해요 사랑해요 그대 내게 말해요 아나요 사랑해요 사랑하나뿐이 나와 같은 사람 사랑해요 내게 말해요 그대여요 그대에게 말해줘요 내게 말해요 내게 말해요 내게 말해요 사랑해 그대 없는 내게 말해요 사랑해요 사랑해요 사랑해요 내 사랑해요 내 사랑만 바라는 그대 사랑해 그대 내게 말해요 사랑해 그대 내게 말해요 아프고 내게 말해요 그대 내게 말해요 아파도 내게 말해요 사랑해요 그대 사랑해 사랑해요 사랑해도 사랑해 사랑아요 내 사랑해요 내 사랑해 사랑해요 그대 사랑하는데 내게 말해요 사랑해 사랑해도 사랑해 사랑해 사랑해요 내게 말해요 사랑해요 내게 말해도 아프고 있어도 사랑해 사랑해요 내게 말해요 내게 말해도 사랑 사랑해요 그대여 사랑해 사랑 그대 내게 말해요 그대여요 그대는 내게 말해서 사랑해요 그대만 바라보는 내게 말해 요 너는 내게 말해도 사랑해요 내게 말해요 내게도 사랑해 그대여 내게 말해요 내 사랑해요 사랑해요 내게 말해요 내 사랑해요 내게 말해요 내게 말해줘요 사랑해 사랑해요 말해줘도 내 사랑해도 사랑해요 나를 사랑해 사랑해 그대 사랑해 사랑 내 사랑해요 아픈 그대 내게 말해요 내게 말해요 사랑해요 그대여요 사랑해 사랑해요 그대여 내게 말해줘서 사랑해 사랑해 사랑해 사랑은 그대 내 사랑해요 사랑해 사랑해 사랑해 그대는 그대는 내게 말해요 사랑은 아직도 내게 있어요 내게 말해도 아나봐요 사랑해 사랑은 영원히 내게 있어요 사랑해요 그대여 내게 사랑해 사랑해 사랑해 그\n",
            "epoch no.10 train no.8510  loss = 1638.22278 avg_loss = 2.92241\n",
            "epoch no.10 train no.8520  loss = 1161.58606 avg_loss = 2.91940\n",
            "epoch no.10 train no.8530  loss = 1200.90259 avg_loss = 2.91948\n",
            "epoch no.10 train no.8540  loss = 1306.14038 avg_loss = 2.92145\n",
            "epoch no.10 train no.8550  loss = 1672.73938 avg_loss = 2.92587\n",
            "epoch no.10 train no.8560  loss = 1212.93274 avg_loss = 2.92784\n",
            "epoch no.10 train no.8570  loss = 1195.40833 avg_loss = 2.92703\n",
            "epoch no.10 train no.8580  loss = 1099.10339 avg_loss = 2.93310\n",
            "epoch no.10 train no.8590  loss = 1247.11890 avg_loss = 2.91932\n",
            "epoch no.10 train no.8600  loss = 1802.91504 avg_loss = 2.91705\n",
            "epoch no.10 train no.8610  loss = 1056.57874 avg_loss = 2.92372\n",
            "epoch no.10 train no.8620  loss = 1132.79346 avg_loss = 2.92980\n",
            "epoch no.10 train no.8630  loss = 1095.47668 avg_loss = 2.91849\n",
            "epoch no.10 train no.8640  loss = 1179.35120 avg_loss = 2.92352\n",
            "epoch no.10 train no.8650  loss = 1164.22424 avg_loss = 2.92342\n",
            "epoch no.10 train no.8660  loss = 1314.79443 avg_loss = 2.92786\n",
            "epoch no.10 train no.8670  loss = 1153.14478 avg_loss = 2.92540\n",
            "epoch no.10 train no.8680  loss = 1153.52368 avg_loss = 2.92004\n",
            "epoch no.10 train no.8690  loss = 1126.14453 avg_loss = 2.92019\n",
            "epoch no.10 train no.8700  loss = 1167.60229 avg_loss = 2.92300\n",
            "epoch no.10 train no.8710  loss = 1023.12537 avg_loss = 2.91746\n",
            "epoch no.10 train no.8720  loss = 1266.96082 avg_loss = 2.90837\n",
            "epoch no.10 train no.8730  loss = 1051.84058 avg_loss = 2.90820\n",
            "epoch no.10 train no.8740  loss = 1233.67444 avg_loss = 2.91004\n",
            "epoch no.10 train no.8750  loss = 1080.56592 avg_loss = 2.90188\n",
            "epoch no.10 train no.8760  loss = 1592.40491 avg_loss = 2.90217\n",
            "epoch no.10 train no.8770  loss = 1060.93323 avg_loss = 2.89766\n",
            "epoch no.10 train no.8780  loss = 914.74219 avg_loss = 2.88511\n",
            "epoch no.10 train no.8790  loss = 2790.92114 avg_loss = 2.88384\n",
            "epoch no.10 train no.8800  loss = 1893.07422 avg_loss = 2.88977\n",
            "epoch no.10 train no.8810  loss = 1129.37219 avg_loss = 2.88575\n",
            "epoch no.10 train no.8820  loss = 2801.93066 avg_loss = 2.89099\n",
            "epoch no.10 train no.8830  loss = 1016.25079 avg_loss = 2.88068\n",
            "epoch no.10 train no.8840  loss = 2685.69165 avg_loss = 2.88159\n",
            "epoch no.10 train no.8850  loss = 1233.23291 avg_loss = 2.88606\n",
            "epoch no.10 train no.8860  loss = 1200.42822 avg_loss = 2.89360\n",
            "epoch no.10 train no.8870  loss = 1118.45239 avg_loss = 2.88612\n",
            "epoch no.10 train no.8880  loss = 2731.79175 avg_loss = 2.88584\n",
            "epoch no.10 train no.8890  loss = 1309.13623 avg_loss = 2.89486\n",
            "epoch no.10 train no.8900  loss = 1126.48132 avg_loss = 2.89698\n",
            "epoch no.10 train no.8910  loss = 1227.89136 avg_loss = 2.90322\n",
            "epoch no.10 train no.8920  loss = 1150.25342 avg_loss = 2.89838\n",
            "epoch no.10 train no.8930  loss = 1032.57581 avg_loss = 2.88929\n",
            "epoch no.10 train no.8940  loss = 1879.68091 avg_loss = 2.88580\n",
            "epoch no.10 train no.8950  loss = 1032.73145 avg_loss = 2.88790\n",
            "epoch no.10 train no.8960  loss = 1185.06299 avg_loss = 2.88369\n",
            "epoch no.10 train no.8970  loss = 2606.44019 avg_loss = 2.88254\n",
            "epoch no.10 train no.8980  loss = 1143.65735 avg_loss = 2.88770\n",
            "epoch no.10 train no.8990  loss = 1191.68079 avg_loss = 2.89570\n",
            "epoch no.10 train no.9000  loss = 1972.99170 avg_loss = 2.89495\n",
            "420\n",
            "to_tokens: ['▁[', '▁나', '다', '▁', '▁', '했', '어', '아', '▁너', '젠', '▁', '한', '단', '▁', '프', '도', '▁수', '야', '▁', '▁', '▁', '가', '는', '▁너', '▁', '를', '▁위해', '고', '▁수', '▁없어', '▁내', '게', '아', '▁', '▁이상', '은', '▁', '이', '으니', '아', '▁사랑', '▁', '가', '줘', '▁', '를', '▁사랑', '했', '잖', '아', '▁', '▁', '▁', '▁떠나', '을', '▁수', '▁있어', '잖', '▁', '▁사랑', '가', '는', '거', '을', '▁', '거', '야', '▁너', '▁', '를', '▁', '가', '도', '▁너', '가', '도', '▁날', '를', '▁뒤', '픔', '이', '▁나', '▁', '했', '거', '야', '▁너', '것', '도', '▁하지', '마', '▁너', '말', '도', '▁할', '▁수', '▁없', '▁내', '를', '▁떠나', '며', '마', '▁너', '▁', '가', '줘', '▁사랑', '했', '잖', '아', '▁그렇게', '를', '▁위해', '했', '어', '까', '▁', '▁떠나', '했', '어', '▁너', '▁', '▁', '를', '▁사랑', '가', '도', '▁너', '했', '단', '야', '▁너', '만', '▁사랑', '했', '으니', '까', '▁', '▁', '했', '어', '▁', '가', '는', '▁너', '했', '어', '아', '▁그렇게', '했', '어', '까', '▁사랑', '했', '어', '봐', '▁', '했', '으니', '▁', '했', '으니', '아', '▁사랑', '했', '어', '▁나', '를', '▁사랑', '를', '▁사랑', '했', '으니', '아', '▁떠나', '했', '으니', '▁너', '것', '도', '▁떠나', '가', '▁떠나', '▁떠나', '를', '▁떠나', '가', '▁사랑', '▁떠나', '를', '을', '▁', '했', '어', '▁너', '했', '어', '▁너', '▁너', '를', '나', '했', '어', '▁떠나', '▁떠나', '를', '을', '했', '어', '봐', '▁정말', '를', '▁사랑', '했', '어', '▁', '가', '는', '했', '어', '봐', '▁사랑', '했', '어', '</s>', '를', '▁사랑', '했', '어', '봐', '▁떠나', '했', '▁떠나', '했', '어', '▁사랑', '를', '▁사랑', '했', '어', '▁사랑', '게', '▁이', '만', '▁사랑', '있', '어', '▁사랑', '했', '어', '▁나', '했', '단', '▁', '어', '▁너', '라', '했', '했', '어', '▁사랑', '를', '을', '했', '어', '까', '를', '인', '▁너', '▁사랑', '▁사랑', '했', '어', '▁사랑', '▁사랑', '봐', '했', '어', '</s>', '했', '어', '▁사랑', '▁사랑', '했', '어', '▁사랑', '를', '을', '▁사랑', '했', '</s>', '했', '어', '▁사랑', '를', '▁사랑', '했', '어', '▁', '마음', '이', '▁', '만', '▁나', '▁', '가', '▁', '가', '▁', '▁사랑', '했', '어', '▁', '▁사랑', '▁나는', '▁떠나', '가', '는', '▁떠나', '▁떠나', '가', '▁내', '▁떠나', '가', '▁사랑', '가', '는', '가', '는', '했', '어', '어', '</s>', '만', '▁사랑', '가', '는', '▁사랑', '했', '어', '▁사랑', '만', '을', '▁날', '▁사랑', '어', '까', '▁사랑', '만', '나', '까', '가', '나', '▁사랑', '데', '만', '을', '</s>', '가', '는', '▁떠나', '가', '▁너무', '▁사랑', '봐', '</s>', '▁사랑', '▁너', '를', '▁사랑', '했', '어', '▁사랑', '를', '▁떠나', '가', '는', '▁사랑', '했', '어', '▁사랑']\n",
            "너라면 내게 말했잖아 이젠 사랑한 만큼 아파할거라면 그렇게\n",
            "\n",
            "날 떠나가줘 내가 너를 붙잡을 수 없어내 사랑이\n",
            "\n",
            "더 이상은 사랑했잖아그렇게 떠나가지만\n",
            "\n",
            "너를 사랑했잖아 그렇게\n",
            "\n",
            "날 위해 웃을 수 있겠니 정말\n",
            "\n",
            "떠나가는 길을 잃은거야 그렇게나를 떠나가면 떠나가는 너의 슬픔도 그렇게 사랑한거야 아무말도 하지마 아무것도 할 수 없어 너를 보지마내가 떠나가도 사랑했잖아 너를 사랑했으니까 왜 사랑했나봐 하지만\n",
            "\n",
            "너를 떠나가도 사랑한거야 너를 사랑했으니까 정말 사랑했어 떠나가니사랑했잖아 사랑했으니까 사랑했나봐\n",
            "\n",
            "사랑했어 사랑했잖아 사랑했어 너만 너를 사랑했잖아 사랑했어 아무것처럼 떠나가는 나를 떠나가는 너만을사랑했어 사랑했어 나는 너만 사랑했어 왜 나만 사랑했나봐\n",
            "\n",
            "너를\n",
            "\n",
            "사랑했어 떠나가사랑했나봐 사랑했어 나를 사랑했나봐 사랑이 사랑했어 나를 사랑했어내겐 너만 남아싶어 사랑했어 사랑한 사람이있어 차라 사랑했어 너만 사랑했으니 너뿐인데만을 사랑했어 너무나 사랑했어 사랑했어 정말 사랑했어 너만을 사랑아 사랑했어 나를사랑했어 내마음도 너와도 떠나는 떠나가 너무 사랑했어정말로 날 떠나가는 날떠나가 날 떠나가떠나가 떠나가 사랑했었어 너를 떠나가 정말 사랑했어 너만 왜라했으니까 나만을떠나가 내겐 너만 있으면 떠나가는떠나가 너무나봐도 난 너만 사랑했어 너를 떠나가 너무 사랑했어</s>\n",
            "epoch no.10 train no.9010  loss = 2695.84961 avg_loss = 2.90292\n",
            "epoch no.10 train no.9020  loss = 1191.95837 avg_loss = 2.91173\n",
            "epoch no.10 train no.9030  loss = 1988.65906 avg_loss = 2.90890\n",
            "epoch no.10 train no.9040  loss = 2950.08765 avg_loss = 2.90586\n",
            "epoch no.10 train no.9050  loss = 1203.25708 avg_loss = 2.90710\n",
            "epoch no.10 train no.9060  loss = 1170.88647 avg_loss = 2.89591\n",
            "epoch no.10 train no.9070  loss = 1031.51562 avg_loss = 2.89201\n",
            "epoch no.10 train no.9080  loss = 1189.46387 avg_loss = 2.88001\n",
            "epoch no.10 train no.9090  loss = 1035.61707 avg_loss = 2.87439\n",
            "epoch no.10 train no.9100  loss = 1229.24963 avg_loss = 2.86831\n",
            "epoch no.10 train no.9110  loss = 1041.74792 avg_loss = 2.86814\n",
            "epoch no.10 train no.9120  loss = 1842.33533 avg_loss = 2.86963\n",
            "epoch no.10 train no.9130  loss = 1044.96277 avg_loss = 2.86813\n",
            "epoch no.10 train no.9140  loss = 1102.49622 avg_loss = 2.87184\n",
            "epoch no.10 train no.9150  loss = 1065.67749 avg_loss = 2.87707\n",
            "epoch no.10 train no.9160  loss = 1179.69800 avg_loss = 2.87113\n",
            "epoch no.10 train no.9170  loss = 1189.30017 avg_loss = 2.86792\n",
            "epoch no.10 train no.9180  loss = 1133.27014 avg_loss = 2.86781\n",
            "epoch no.10 train no.9190  loss = 1162.89734 avg_loss = 2.86085\n",
            "epoch no.10 train no.9200  loss = 1676.89331 avg_loss = 2.86757\n",
            "epoch no.11 train no.9210  loss = 850.58020 avg_loss = 2.86201\n",
            "epoch no.11 train no.9220  loss = 983.28906 avg_loss = 2.85100\n",
            "epoch no.11 train no.9230  loss = 1092.25439 avg_loss = 2.84421\n",
            "epoch no.11 train no.9240  loss = 1544.46326 avg_loss = 2.83498\n",
            "epoch no.11 train no.9250  loss = 1014.52386 avg_loss = 2.81925\n",
            "epoch no.11 train no.9260  loss = 2758.57617 avg_loss = 2.81400\n",
            "epoch no.11 train no.9270  loss = 1176.90002 avg_loss = 2.80445\n",
            "epoch no.11 train no.9280  loss = 1984.28552 avg_loss = 2.80001\n",
            "epoch no.11 train no.9290  loss = 1182.53796 avg_loss = 2.80775\n",
            "epoch no.11 train no.9300  loss = 1180.37512 avg_loss = 2.79844\n",
            "epoch no.11 train no.9310  loss = 1055.71521 avg_loss = 2.78869\n",
            "epoch no.11 train no.9320  loss = 1235.14270 avg_loss = 2.77491\n",
            "epoch no.11 train no.9330  loss = 1004.38568 avg_loss = 2.75770\n",
            "epoch no.11 train no.9340  loss = 1171.43054 avg_loss = 2.75709\n",
            "epoch no.11 train no.9350  loss = 1162.89185 avg_loss = 2.75979\n",
            "epoch no.11 train no.9360  loss = 1101.62622 avg_loss = 2.75685\n",
            "epoch no.11 train no.9370  loss = 1055.32507 avg_loss = 2.75746\n",
            "epoch no.11 train no.9380  loss = 1180.50171 avg_loss = 2.75030\n",
            "epoch no.11 train no.9390  loss = 1098.15991 avg_loss = 2.75357\n",
            "epoch no.11 train no.9400  loss = 1025.69116 avg_loss = 2.75239\n",
            "epoch no.11 train no.9410  loss = 1657.74512 avg_loss = 2.74038\n",
            "epoch no.11 train no.9420  loss = 1436.87512 avg_loss = 2.73905\n",
            "epoch no.11 train no.9430  loss = 1644.85120 avg_loss = 2.72807\n",
            "epoch no.11 train no.9440  loss = 981.90088 avg_loss = 2.73454\n",
            "epoch no.11 train no.9450  loss = 1062.15759 avg_loss = 2.73059\n",
            "epoch no.11 train no.9460  loss = 1004.51385 avg_loss = 2.73502\n",
            "epoch no.11 train no.9470  loss = 1122.81470 avg_loss = 2.73066\n",
            "epoch no.11 train no.9480  loss = 1143.41321 avg_loss = 2.72970\n",
            "epoch no.11 train no.9490  loss = 1138.17383 avg_loss = 2.72290\n",
            "epoch no.11 train no.9500  loss = 2448.05542 avg_loss = 2.72723\n",
            "170\n",
            "to_tokens: ['▁[', '▁', '▁뭐', '▁', '▁미', '줘', '▁', '▁이', '게', '▁', '잖', '아', '▁', '는', '▁', '▁', '▁', '잖', '아', '▁나', '는', '▁사랑', '하게', '단', '▁그', '야', '▁하지', '마', '아', '줘', '▁그냥', '를', '▁사랑', '할', '줘', '▁너', '를', '▁', '을', '▁알', '잖', '▁없어', '잖', '아', '▁너', '의', '▁사랑', '게', '▁', '잖', '아', '▁너', '거', '▁', '이', '를', '이', '야', '▁', '▁', '런', '도', '▁난', '고', '▁있어', '가', '워', '▁내', '이', '▁불', '어', '와', '면', '봐', '▁너', '▁외', '퍼', '이', '▁난', '▁아', '플', '지', '▁않아', '겠', '아', '▁너', '를', '▁마음', '을', '▁', '얀', '▁', '▁있', '잖', '아', '▁너', '날', '▁', '해', '봐', '를', '▁', '이', '▁', '의', '▁사랑', '해', '▁있어', '잖', '아', '▁너', '와', '지', '마', '▁아무', '▁', '다', '엔', '▁너무', '▁', '워', '할', '▁알고', '했', '잖', '아', '▁너', '를', '▁', '프', '지', '마', '▁내가', '는', '▁', '이', '▁아닌', '뭔', '어', '아', '▁너', '것', '도', '▁할', '▁수', '▁없는', '▁이렇게', '▁나', '게', '▁돌아', '줘', '</s>', '▁내', '를', '▁떠나', '하지', '▁수', '▁없어', '잖', '아', '▁너', '파', '도', '줘', '▁너']\n",
            "너라면 내게 말해줘 그냥 네가알잖아 너의 사랑을 내가 알잖아 너를 사랑한단 말은 하지 말아줘 나를 이해해줘 너의 눈빛을 알 수 있잖아 너를 힘들게 했잖아 이런 내마음 너 뿐이야 해 아무것도 모르고 차가운 바람이 불어오나봐 이렇게 슬픔도 이렇게 아프지 않잖아 너의얼굴이\n",
            "\n",
            "하룰 수 있잖아 지난날 사랑해 너의아픔은 너를 사랑하고 있잖아 돌아보지마내가 떠난후엔 내가미워도 사랑했잖아 너를 아프지마 너의 끝이 었잖아 아무것도 알 수 없어 다시 내게 말해줘 다시 나를 사랑할 수 있잖아 아파해줘</s>\n",
            "epoch no.11 train no.9510  loss = 1141.85791 avg_loss = 2.72269\n",
            "epoch no.11 train no.9520  loss = 1079.22339 avg_loss = 2.72171\n",
            "epoch no.11 train no.9530  loss = 1069.27649 avg_loss = 2.72282\n",
            "epoch no.11 train no.9540  loss = 1700.76001 avg_loss = 2.72779\n",
            "epoch no.11 train no.9550  loss = 1150.38123 avg_loss = 2.73221\n",
            "epoch no.11 train no.9560  loss = 1012.77295 avg_loss = 2.73815\n",
            "epoch no.11 train no.9570  loss = 1097.14392 avg_loss = 2.74179\n",
            "epoch no.11 train no.9580  loss = 1122.75342 avg_loss = 2.74428\n",
            "epoch no.11 train no.9590  loss = 1058.15356 avg_loss = 2.73568\n",
            "epoch no.11 train no.9600  loss = 966.13361 avg_loss = 2.72640\n",
            "epoch no.11 train no.9610  loss = 1570.54590 avg_loss = 2.73246\n",
            "epoch no.11 train no.9620  loss = 1860.79785 avg_loss = 2.73952\n",
            "epoch no.11 train no.9630  loss = 1160.08801 avg_loss = 2.73949\n",
            "epoch no.11 train no.9640  loss = 1051.31555 avg_loss = 2.73990\n",
            "epoch no.11 train no.9650  loss = 1179.01306 avg_loss = 2.74571\n",
            "epoch no.11 train no.9660  loss = 1023.06567 avg_loss = 2.74825\n",
            "epoch no.11 train no.9670  loss = 1009.67828 avg_loss = 2.74541\n",
            "epoch no.11 train no.9680  loss = 1143.14453 avg_loss = 2.73678\n",
            "epoch no.11 train no.9690  loss = 1031.02393 avg_loss = 2.74889\n",
            "epoch no.11 train no.9700  loss = 903.80353 avg_loss = 2.75166\n",
            "epoch no.11 train no.9710  loss = 1037.31262 avg_loss = 2.74412\n",
            "epoch no.11 train no.9720  loss = 1201.43286 avg_loss = 2.74363\n",
            "epoch no.11 train no.9730  loss = 1186.62097 avg_loss = 2.75861\n",
            "epoch no.11 train no.9740  loss = 1077.73291 avg_loss = 2.76567\n",
            "epoch no.11 train no.9750  loss = 1754.16687 avg_loss = 2.75477\n",
            "epoch no.11 train no.9760  loss = 1806.64673 avg_loss = 2.75871\n",
            "epoch no.11 train no.9770  loss = 1392.89795 avg_loss = 2.76445\n",
            "epoch no.11 train no.9780  loss = 1176.27051 avg_loss = 2.76269\n",
            "epoch no.11 train no.9790  loss = 1060.60107 avg_loss = 2.76133\n",
            "epoch no.11 train no.9800  loss = 1054.54248 avg_loss = 2.76004\n",
            "epoch no.11 train no.9810  loss = 1107.67322 avg_loss = 2.75350\n",
            "epoch no.11 train no.9820  loss = 978.74939 avg_loss = 2.74975\n",
            "epoch no.11 train no.9830  loss = 1187.34509 avg_loss = 2.75871\n",
            "epoch no.11 train no.9840  loss = 1082.88953 avg_loss = 2.76011\n",
            "epoch no.11 train no.9850  loss = 992.20020 avg_loss = 2.74423\n",
            "epoch no.11 train no.9860  loss = 1206.00989 avg_loss = 2.74808\n",
            "epoch no.11 train no.9870  loss = 1137.70398 avg_loss = 2.75023\n",
            "epoch no.11 train no.9880  loss = 1184.12964 avg_loss = 2.74725\n",
            "epoch no.11 train no.9890  loss = 948.33270 avg_loss = 2.74013\n",
            "epoch no.11 train no.9900  loss = 1240.83228 avg_loss = 2.75474\n",
            "epoch no.11 train no.9910  loss = 1455.61804 avg_loss = 2.75246\n",
            "epoch no.11 train no.9920  loss = 971.31274 avg_loss = 2.74780\n",
            "epoch no.11 train no.9930  loss = 1639.41479 avg_loss = 2.75729\n",
            "epoch no.11 train no.9940  loss = 1048.23132 avg_loss = 2.74955\n",
            "epoch no.11 train no.9950  loss = 1077.62903 avg_loss = 2.75029\n",
            "epoch no.11 train no.9960  loss = 982.94391 avg_loss = 2.74006\n",
            "epoch no.11 train no.9970  loss = 1129.77759 avg_loss = 2.74996\n",
            "epoch no.11 train no.9980  loss = 1155.42395 avg_loss = 2.73425\n",
            "epoch no.11 train no.9990  loss = 1502.15808 avg_loss = 2.72412\n",
            "epoch no.11 train no.10000  loss = 1247.06616 avg_loss = 2.72505\n",
            "266\n",
            "to_tokens: ['▁[', '▁오늘', '▁나는', '▁', '▁그', '▁그', '부터', '야', '▁할', '▁했', '야', '▁', '날', '▁사랑', '와', '▁만나', '났', '던', '▁너', '부터', '▁너', '를', '▁만', '▁울', '춰', '야', '어', '▁몰', '를', '▁사랑', '앞', '▁서', '고', '▁싶었', '지', '▁너', '린', '▁다시', '던', '▁않아', '어', '▁너', '린', '이라도', '▁', '▁너', '를', '▁만나', '며', '어', '▁우리', '를', '▁만나', '기', '▁전', '엔', '▁', '▁', '를', '▁만나', '지', '▁전', '엔', '▁너무', '를', '▁만나', '기', '▁전', '▁너무', '의', '겐', '은', '▁', '냐', '고', '▁너', '토록', '▁너', '를', '▁생각', '기', '▁했', '꺼', '야', '▁너', '의', '▁가슴', '일', '▁너', '▁할', '꺼', '야', '▁너', '를', '▁모습', '은', '야', '려', '오', '▁너', '▁날', '▁너', '를', '▁생각', '해', '어', '▁너', '젠', '▁너', '의', '▁떠나', '야', '▁전에', '▁너', '▁너', '▁만나', '기', '▁말', '아', '줘', '▁너', '▁누구', '▁만나', '야', '▁하', '▁너', '토록', '▁사랑', '하는', '테', '▁너', '▁너', '▁너', '▁너', '를', '▁만나', '야', '▁위해', '▁너', '▁너', '를', '▁만나', '야', '▁했', '▁사람', '▁우', '의', '▁마음', '이', '▁아', '를', '▁만나', '▁나는', '▁너', '를', '▁사랑', '▁너', '▁너', '를', '▁사랑', '지', '▁못하고', '면', '▁나는', '를', '▁만나', '▁나는', '▁너', '야', '만', '▁하', '를', '▁마음', '은', '▁나', '를', '▁안', '야', '지', '를', '▁위해', '야', '▁너', '▁수', '야', '▁너', '네', '▁너', '의', '▁마음', '이', '▁나', '꺼', '▁너', '를', '▁만나', '▁사랑', '▁위해', '▁나는', '▁너', '별', '은', '▁너', '를', '▁만나', '▁너', '를', '▁위해', '▁나는', '▁너', '려', '야', '</s>', '▁너', '를', '▁만나', '지', '▁나는', '▁너', '▁만나', '▁수', '▁있어', '▁너', '의', '▁마음', '은', '▁너', '를', '▁만나', '지', '▁나는', '▁너', '하', '니까', '지', '</s>', '고', '▁너', '를', '▁위해', '지', '를', '▁너', '야', '▁너', '를', '▁만나', '▁나는', '▁너', '▁너', '를', '▁만나', '지', '하고', '▁너', '의', '▁마음', '걸', '▁너']\n",
            "너라면니 처음 만난 날이야만이야그토록 너를 만났던 날부터 나를 위해 비워했지 너의 집을 걷고싶어 우린 같지 않았어 우연히라도 너를 보냈지 너를 만나기 전엔 난 너를만나기 전엔 너를 만나기엔 나의 마음은아냐고 그땐 너를 만나야 할거야 나의 생을함께 할꺼야 너의 마음이 떨려오는 많은데 너를 사랑했어 이젠 나를 만나기 전에 내가 다시 만나지 말아줘 그댈 만나야 해 그토록 사랑할 때도\n",
            "\n",
            "없이 나는 너를 만나기전에 나는 너를 만나야 할지 나의 마음은 너를 위해 나는 너를 위해서 나는너를 만나지 못했다면너를 위해 내가 살아야만 너의 마음은 너를 만나러 너를 만나야 할거야 하니까 나의 마음은 없을까 너를 만나기 위해 나는 이별을 너를 위해 너를 위해 나는 두려야 나는 너를 만나지 나는 사랑을 할 수 있어 나의 마음은 너를 만나지 나는 행복하겠지 못했다면 너를 만나 너를 만나야 너를 위해 나는 나는 너를 만나 사랑은 나의 모든걸</s>\n",
            "epoch no.11 train no.10010  loss = 1084.06543 avg_loss = 2.72574\n",
            "epoch no.11 train no.10020  loss = 1701.27026 avg_loss = 2.72881\n",
            "epoch no.11 train no.10030  loss = 1142.68274 avg_loss = 2.74820\n",
            "epoch no.11 train no.10040  loss = 1080.96057 avg_loss = 2.74637\n",
            "epoch no.12 train no.10050  loss = 1203.40527 avg_loss = 2.73757\n",
            "epoch no.12 train no.10060  loss = 1053.02625 avg_loss = 2.73340\n",
            "epoch no.12 train no.10070  loss = 1006.23071 avg_loss = 2.72712\n",
            "epoch no.12 train no.10080  loss = 852.44159 avg_loss = 2.70153\n",
            "epoch no.12 train no.10090  loss = 1021.17712 avg_loss = 2.70352\n",
            "epoch no.12 train no.10100  loss = 1142.65637 avg_loss = 2.69341\n",
            "epoch no.12 train no.10110  loss = 1020.90979 avg_loss = 2.70080\n",
            "epoch no.12 train no.10120  loss = 1059.71448 avg_loss = 2.69355\n",
            "epoch no.12 train no.10130  loss = 1070.20020 avg_loss = 2.67144\n",
            "epoch no.12 train no.10140  loss = 773.32166 avg_loss = 2.65968\n",
            "epoch no.12 train no.10150  loss = 1055.44739 avg_loss = 2.65825\n",
            "epoch no.12 train no.10160  loss = 1020.65735 avg_loss = 2.65841\n",
            "epoch no.12 train no.10170  loss = 1135.34338 avg_loss = 2.65691\n",
            "epoch no.12 train no.10180  loss = 1729.39941 avg_loss = 2.64862\n",
            "epoch no.12 train no.10190  loss = 1017.57037 avg_loss = 2.65075\n",
            "epoch no.12 train no.10200  loss = 1473.24670 avg_loss = 2.64071\n",
            "epoch no.12 train no.10210  loss = 1110.19983 avg_loss = 2.62408\n",
            "epoch no.12 train no.10220  loss = 1056.78491 avg_loss = 2.62685\n",
            "epoch no.12 train no.10230  loss = 1130.37781 avg_loss = 2.62581\n",
            "epoch no.12 train no.10240  loss = 1609.93542 avg_loss = 2.62493\n",
            "epoch no.12 train no.10250  loss = 1050.66846 avg_loss = 2.61374\n",
            "epoch no.12 train no.10260  loss = 1039.89758 avg_loss = 2.60087\n",
            "epoch no.12 train no.10270  loss = 1071.88818 avg_loss = 2.60666\n",
            "epoch no.12 train no.10280  loss = 1093.60120 avg_loss = 2.61055\n",
            "epoch no.12 train no.10290  loss = 1082.23792 avg_loss = 2.61899\n",
            "epoch no.12 train no.10300  loss = 1048.90076 avg_loss = 2.62130\n",
            "epoch no.12 train no.10310  loss = 1035.65186 avg_loss = 2.61281\n",
            "epoch no.12 train no.10320  loss = 1094.95508 avg_loss = 2.61289\n",
            "epoch no.12 train no.10330  loss = 1094.62866 avg_loss = 2.61137\n",
            "epoch no.12 train no.10340  loss = 1157.06189 avg_loss = 2.61032\n",
            "epoch no.12 train no.10350  loss = 1145.15442 avg_loss = 2.61715\n",
            "epoch no.12 train no.10360  loss = 1051.49121 avg_loss = 2.62770\n",
            "epoch no.12 train no.10370  loss = 1135.97595 avg_loss = 2.62579\n",
            "epoch no.12 train no.10380  loss = 1034.05676 avg_loss = 2.61915\n",
            "epoch no.12 train no.10390  loss = 871.68768 avg_loss = 2.62122\n",
            "epoch no.12 train no.10400  loss = 972.56128 avg_loss = 2.60823\n",
            "epoch no.12 train no.10410  loss = 1454.81714 avg_loss = 2.61322\n",
            "epoch no.12 train no.10420  loss = 1013.47931 avg_loss = 2.61080\n",
            "epoch no.12 train no.10430  loss = 1435.31299 avg_loss = 2.60620\n",
            "epoch no.12 train no.10440  loss = 968.18964 avg_loss = 2.60350\n",
            "epoch no.12 train no.10450  loss = 1717.59998 avg_loss = 2.60809\n",
            "epoch no.12 train no.10460  loss = 1523.84668 avg_loss = 2.60380\n",
            "epoch no.12 train no.10470  loss = 1080.90405 avg_loss = 2.61501\n",
            "epoch no.12 train no.10480  loss = 1071.93677 avg_loss = 2.60865\n",
            "epoch no.12 train no.10490  loss = 1476.36304 avg_loss = 2.60248\n",
            "epoch no.12 train no.10500  loss = 967.74921 avg_loss = 2.59160\n",
            "68\n",
            "to_tokens: ['▁[', '▁나', '▁', '▁너', '▁', '운', '▁얼굴', '에', '▁지', '고', '▁별', '빛', '에', '▁', '의', '▁비', '슬', '처럼', '▁', '로', '움', '도', '▁나는', '로운', '▁밤', '의', '▁마음', '로', '▁', '은', '서', '▁나는', '하고', '▁사랑', '해', '▁그', '해', '▁너', '만', '▁마음', '▁아', '▁너', '답', '웠', '서', '▁사랑', '은', '▁사랑', '해', '▁사랑', '해', '▁내', '해', '▁영', '만', '을', '▁사랑', '해', '▁사랑', '해', '▁내', '해', '▁내', '▁사랑', '해', '▁사랑']\n",
            "너라면해가 고운 바람에\n",
            "\n",
            "지고 달빛도 너는 이슬처럼외로워도 외로운 나의 얼굴에 맺어서 사랑해 사랑해 사랑해 나의 마음은 아름다워서 사랑해 사랑해 사랑해 사랑해 너만을 사랑해 사랑해 사랑해 내 사랑해</s>\n",
            "epoch no.12 train no.10510  loss = 1169.83362 avg_loss = 2.59429\n",
            "epoch no.12 train no.10520  loss = 916.33490 avg_loss = 2.59002\n",
            "epoch no.12 train no.10530  loss = 1108.38440 avg_loss = 2.60580\n",
            "epoch no.12 train no.10540  loss = 1215.47864 avg_loss = 2.60760\n",
            "epoch no.12 train no.10550  loss = 1576.15613 avg_loss = 2.61709\n",
            "epoch no.12 train no.10560  loss = 1398.58569 avg_loss = 2.61683\n",
            "epoch no.12 train no.10570  loss = 1111.34509 avg_loss = 2.62392\n",
            "epoch no.12 train no.10580  loss = 905.60071 avg_loss = 2.61772\n",
            "epoch no.12 train no.10590  loss = 934.60510 avg_loss = 2.62357\n",
            "epoch no.12 train no.10600  loss = 995.42285 avg_loss = 2.62262\n",
            "epoch no.12 train no.10610  loss = 988.87079 avg_loss = 2.60028\n",
            "epoch no.12 train no.10620  loss = 1468.15332 avg_loss = 2.60447\n",
            "epoch no.12 train no.10630  loss = 1523.93506 avg_loss = 2.59204\n",
            "epoch no.12 train no.10640  loss = 1224.32935 avg_loss = 2.60123\n",
            "epoch no.12 train no.10650  loss = 1785.50549 avg_loss = 2.61622\n",
            "epoch no.12 train no.10660  loss = 1195.70642 avg_loss = 2.62134\n",
            "epoch no.12 train no.10670  loss = 1745.44312 avg_loss = 2.61922\n",
            "epoch no.12 train no.10680  loss = 1071.04041 avg_loss = 2.61362\n",
            "epoch no.12 train no.10690  loss = 1082.48267 avg_loss = 2.62289\n",
            "epoch no.12 train no.10700  loss = 938.50330 avg_loss = 2.62452\n",
            "epoch no.12 train no.10710  loss = 1175.04150 avg_loss = 2.62988\n",
            "epoch no.12 train no.10720  loss = 1568.94739 avg_loss = 2.62098\n",
            "epoch no.12 train no.10730  loss = 1242.71057 avg_loss = 2.60917\n",
            "epoch no.12 train no.10740  loss = 1000.68408 avg_loss = 2.59469\n",
            "epoch no.12 train no.10750  loss = 1091.73389 avg_loss = 2.60280\n",
            "epoch no.12 train no.10760  loss = 1013.30804 avg_loss = 2.61222\n",
            "epoch no.12 train no.10770  loss = 914.48682 avg_loss = 2.60009\n",
            "epoch no.12 train no.10780  loss = 976.63257 avg_loss = 2.58950\n",
            "epoch no.12 train no.10790  loss = 1233.40051 avg_loss = 2.59759\n",
            "epoch no.12 train no.10800  loss = 1017.54675 avg_loss = 2.59320\n",
            "epoch no.12 train no.10810  loss = 1124.11096 avg_loss = 2.59708\n",
            "epoch no.12 train no.10820  loss = 1055.46924 avg_loss = 2.60306\n",
            "epoch no.12 train no.10830  loss = 1009.24255 avg_loss = 2.60604\n",
            "epoch no.12 train no.10840  loss = 1060.51013 avg_loss = 2.61167\n",
            "epoch no.12 train no.10850  loss = 867.08185 avg_loss = 2.61689\n",
            "epoch no.12 train no.10860  loss = 1199.15466 avg_loss = 2.62475\n",
            "epoch no.12 train no.10870  loss = 1001.88922 avg_loss = 2.61295\n",
            "epoch no.12 train no.10880  loss = 1115.38403 avg_loss = 2.60939\n",
            "epoch no.13 train no.10890  loss = 959.92566 avg_loss = 2.60195\n",
            "epoch no.13 train no.10900  loss = 998.76978 avg_loss = 2.58654\n",
            "epoch no.13 train no.10910  loss = 946.27905 avg_loss = 2.57930\n",
            "epoch no.13 train no.10920  loss = 941.27026 avg_loss = 2.56497\n",
            "epoch no.13 train no.10930  loss = 1014.07434 avg_loss = 2.55220\n",
            "epoch no.13 train no.10940  loss = 959.05469 avg_loss = 2.54531\n",
            "epoch no.13 train no.10950  loss = 1131.01135 avg_loss = 2.53608\n",
            "epoch no.13 train no.10960  loss = 1153.08777 avg_loss = 2.52816\n",
            "epoch no.13 train no.10970  loss = 883.54901 avg_loss = 2.51398\n",
            "epoch no.13 train no.10980  loss = 1119.55896 avg_loss = 2.52740\n",
            "epoch no.13 train no.10990  loss = 885.96552 avg_loss = 2.50232\n",
            "epoch no.13 train no.11000  loss = 910.84833 avg_loss = 2.50104\n",
            "177\n",
            "to_tokens: ['▁[', '▁내', '▁다시', '▁', '를', '▁함께', '한', '가', '의', '▁그', '▁약속', '을', '▁너', '던', '가', '▁가슴', '에', '▁', '와', '▁만나', '▁수', '▁없을', '니', '▁너', '의', '▁만나', '▁만난', '▁날', '▁날', '부터', '▁사랑', '▁했던', '을', '던', '▁그', '▁순간', '▁그', '와', '▁그', '▁', '▁기억', '하니', '▁너', '와', '▁이', '▁너', '젠', '▁너', '는', '▁너', '▁수', '▁없', '▁것', '▁난', '▁너', '▁', '대', '론', '▁그', '의', '▁사랑', '이', '에', '▁너', '파', '도', '도', '널', '▁', '도', '▁나는', '▁너', '를', '▁그', '에', '▁안', '겨', '▁너', '하', '▁너', '보', '며', '▁너', '어', '▁좋아', '▁난', '이', '▁흘러', '도', '▁너', '▁너', '를', '▁사랑', '아', '▁', '</s>', '의', '▁사랑', '해', '도', '▁말', '를', '▁사랑', '▁놓', '서', '▁아', '이', '▁흘러', '도', '▁', '대', '여', '▁놓', '▁바', '▁없', '나', '▁우리', '▁날', '▁우리', '▁처음', '이', '[UNK]', '▁하', '▁', '▁우리', '▁오늘', '</s>', '마', '도', '▁', '원', '히', '▁', '를', '▁손', '▁눈에', '에', '▁눈물', '의', '▁가슴', '에', '▁너무', '직', '▁너', '파', '도', '▁너', '의', '▁나', '의', '▁사랑', '은', '대', '여', '</s>', '원', '히', '▁순간', '도', '▁이제', '▁행복', '▁지켜', '해', '▁사랑', '▁사랑', '대', '와', '▁영', '▁지켜', '도', '</s>']\n",
            "너라면니너와 함께인 너의그 길을 걷다 내 품에서\n",
            "\n",
            "너를 볼 수 없기에너를 처음 만난 그 날 우리 함께 노오던 그 날 너의 약속을 기억해너도 난 이젠 다시 한번 볼 수 없을까봐도 그대도나의가슴속에 아파해 도대도나는 너의품에 안고 말없이 바라보며 기대도 돼 눈물이 흘러도난 너를 안고 싶어 너를 사랑해 난 너의 손을 잡고서 눈물이 흘러도 그대 손길 수 없던 지난 날 우리 사랑 하[UNK] 아파도 영원히너의 두눈에 나의 품이 오고 아파하고 너와 나의 사랑그대여 영원한 기억들만을 사랑해도 그대와 내가 살아줘</s>\n",
            "epoch no.13 train no.11010  loss = 1485.53198 avg_loss = 2.49670\n",
            "epoch no.13 train no.11020  loss = 991.27368 avg_loss = 2.50224\n",
            "epoch no.13 train no.11030  loss = 1102.09497 avg_loss = 2.50127\n",
            "epoch no.13 train no.11040  loss = 975.01843 avg_loss = 2.50909\n",
            "epoch no.13 train no.11050  loss = 963.52966 avg_loss = 2.50443\n",
            "epoch no.13 train no.11060  loss = 954.22687 avg_loss = 2.50349\n",
            "epoch no.13 train no.11070  loss = 1470.13489 avg_loss = 2.49929\n",
            "epoch no.13 train no.11080  loss = 993.73962 avg_loss = 2.49283\n",
            "epoch no.13 train no.11090  loss = 970.49854 avg_loss = 2.49328\n",
            "epoch no.13 train no.11100  loss = 983.96570 avg_loss = 2.49267\n",
            "epoch no.13 train no.11110  loss = 1373.31958 avg_loss = 2.47827\n",
            "epoch no.13 train no.11120  loss = 996.03235 avg_loss = 2.47917\n",
            "epoch no.13 train no.11130  loss = 1184.81934 avg_loss = 2.48338\n",
            "epoch no.13 train no.11140  loss = 1671.94751 avg_loss = 2.47534\n",
            "epoch no.13 train no.11150  loss = 2675.34473 avg_loss = 2.46730\n",
            "epoch no.13 train no.11160  loss = 1090.11865 avg_loss = 2.46878\n",
            "epoch no.13 train no.11170  loss = 1028.82935 avg_loss = 2.46586\n",
            "epoch no.13 train no.11180  loss = 921.47333 avg_loss = 2.46843\n",
            "epoch no.13 train no.11190  loss = 974.78656 avg_loss = 2.46241\n",
            "epoch no.13 train no.11200  loss = 1335.43848 avg_loss = 2.45930\n",
            "epoch no.13 train no.11210  loss = 1555.73389 avg_loss = 2.45891\n",
            "epoch no.13 train no.11220  loss = 901.25311 avg_loss = 2.45735\n",
            "epoch no.13 train no.11230  loss = 921.95996 avg_loss = 2.45374\n",
            "epoch no.13 train no.11240  loss = 1088.77698 avg_loss = 2.46588\n",
            "epoch no.13 train no.11250  loss = 1210.43982 avg_loss = 2.47625\n",
            "epoch no.13 train no.11260  loss = 1032.20911 avg_loss = 2.47277\n",
            "epoch no.13 train no.11270  loss = 2239.59668 avg_loss = 2.47430\n",
            "epoch no.13 train no.11280  loss = 901.75696 avg_loss = 2.47960\n",
            "epoch no.13 train no.11290  loss = 1116.83508 avg_loss = 2.47773\n",
            "epoch no.13 train no.11300  loss = 1518.59485 avg_loss = 2.47854\n",
            "epoch no.13 train no.11310  loss = 2544.47607 avg_loss = 2.47533\n",
            "epoch no.13 train no.11320  loss = 2607.60303 avg_loss = 2.48295\n",
            "epoch no.13 train no.11330  loss = 944.57935 avg_loss = 2.49337\n",
            "epoch no.13 train no.11340  loss = 1016.66992 avg_loss = 2.48739\n",
            "epoch no.13 train no.11350  loss = 1127.14734 avg_loss = 2.50119\n",
            "epoch no.13 train no.11360  loss = 730.78076 avg_loss = 2.49153\n",
            "epoch no.13 train no.11370  loss = 1033.94617 avg_loss = 2.48248\n",
            "epoch no.13 train no.11380  loss = 963.52960 avg_loss = 2.48297\n",
            "epoch no.13 train no.11390  loss = 1743.41638 avg_loss = 2.49499\n",
            "epoch no.13 train no.11400  loss = 1158.40649 avg_loss = 2.49339\n",
            "epoch no.13 train no.11410  loss = 938.70038 avg_loss = 2.49951\n",
            "epoch no.13 train no.11420  loss = 1002.46991 avg_loss = 2.49891\n",
            "epoch no.13 train no.11430  loss = 2364.88281 avg_loss = 2.49477\n",
            "epoch no.13 train no.11440  loss = 1514.24011 avg_loss = 2.48262\n",
            "epoch no.13 train no.11450  loss = 878.41370 avg_loss = 2.48100\n",
            "epoch no.13 train no.11460  loss = 2654.32373 avg_loss = 2.47812\n",
            "epoch no.13 train no.11470  loss = 1533.84961 avg_loss = 2.47964\n",
            "epoch no.13 train no.11480  loss = 911.39575 avg_loss = 2.47410\n",
            "epoch no.13 train no.11490  loss = 943.55536 avg_loss = 2.47516\n",
            "epoch no.13 train no.11500  loss = 970.54321 avg_loss = 2.47055\n",
            "234\n",
            "to_tokens: ['▁[', '▁나', '▁', '니', '▁', '▁', '봐', '▁수', '▁없', '▁없', '겠', '니', '▁나', '도', '▁수', '야', '▁그', '주', '▁', '게', '로', '▁', '와', '▁수', '▁없', '▁없', '▁너', '의', '▁사랑', '이', '▁미', '▁다시', '▁어떤', '▁수', '▁없', '잖', '아', '▁', '▁나', '간', '▁그', '도', '▁나', '지', '▁말', '아', '▁떠나', '▁그', '▁말', '린', '▁다시', '▁사랑', '▁위해', '워', '▁할', '▁건', '가', '가', '했던', '▁건', '야', '▁', '▁사랑', '▁싫어', '했던', '▁이', '를', '▁사랑', '했던', '잖', '아', '▁떠나', '발', '▁울', '를', '▁떠나', '가', '야', '만', '▁했', '지', '야', '▁정말', '▁너', '를', '▁위해', '했', '▁너', '▁사랑', '▁사랑', '▁소', '▁', '고', '잖', '아', '▁떠나', '▁사랑', '했', '잖', '아', '▁너', '를', '▁사랑', '했', '▁그', '도', '▁하지', '했', '이란', '니', '▁말', '도', '▁', '▁싫어', '한다면', '지도', '▁', '했', '▁너', '를', '▁사랑', '▁내가', '런', '▁말', '도', '▁하지', '▁못해', '도', '줘', '▁그', '발', '▁울', '가', '▁말', '▁너', '▁너', '▁떠나', '▁미', '를', '▁사랑', '했', '잖', '아', '▁떠나', '지', '만', '지', '지', '▁나는', '를', '▁그', '도', '▁할', '가', '▁너', '▁너', '를', '▁떠나', '가', '마', '▁너', '를', '▁떠나', '려', '게', '▁있어', '잖', '아', '▁제', '를', '을', '▁사랑', '망', '건', '▁정말', '▁떠나', '▁아', '잖', '아', '요', '거', '를', '▁울', '▁내가', '했', '잖', '아', '▁나', '▁정말', '▁사랑', '아', '▁가지', '마', '아', '▁사랑', '▁가지', '를', '▁떠나', '▁사랑', '했', '잖', '아', '▁떠나', '▁정말', '▁너', '한다고', '에', '겐', '▁정말', '했', '잖', '아', '▁떠나', '를', '▁사랑', '면', '▁그', '▁너', '를', '▁사랑', '▁나', '만', '수', '▁있', '▁할', '잖', '아', '▁떠나', '▁정말']\n",
            "너라면 든 내가 돌아올 수는 없겠지 생각할 거라면 말해도 내게로 돌아올 수가 있어 너의 사랑이라면 그럴 수 있잖아요 떠나간대도 울지 말고\n",
            "\n",
            "있어 그렇게 우린 서로를 그리워 하는건 다정한거야정말 내가 사랑했는데 너를 사랑했잖아 제발 나를\n",
            "\n",
            "떠나가야만 하는 거야 난 너를 사랑했는데 너무나도 싫어졌다 했잖아 정말 사랑하잖아 너를 사랑한다는 말도 안녕 이란 말만 내가 부담주지못해너를 위해 아무런 말도 하지 말아요 제발 떠나지마 내가 왜내가 너를 사랑했잖아 떠나야 하는건지 너의 눈빛도 모두가 있어 나를 떠나가지마 나를 버릴수 없잖아 너만을 원했던건 정말이었잖아 그런 너를 정말 사랑했잖아요 정말 괜찮아 가지말아요 너를 너무 사랑했잖아요 내가 사랑했기에 내가사랑했잖아 나를 떠나면 난 너를 정말로 살수밖에 모르잖아요</s>\n",
            "epoch no.13 train no.11510  loss = 1003.49188 avg_loss = 2.46779\n",
            "epoch no.13 train no.11520  loss = 1023.39819 avg_loss = 2.47181\n",
            "epoch no.13 train no.11530  loss = 1703.73474 avg_loss = 2.46994\n",
            "epoch no.13 train no.11540  loss = 901.34229 avg_loss = 2.47814\n",
            "epoch no.13 train no.11550  loss = 1016.92755 avg_loss = 2.48654\n",
            "epoch no.13 train no.11560  loss = 947.47723 avg_loss = 2.48266\n",
            "epoch no.13 train no.11570  loss = 1063.60327 avg_loss = 2.48229\n",
            "epoch no.13 train no.11580  loss = 1132.46326 avg_loss = 2.48332\n",
            "epoch no.13 train no.11590  loss = 1784.42908 avg_loss = 2.50135\n",
            "epoch no.13 train no.11600  loss = 1084.33923 avg_loss = 2.50956\n",
            "epoch no.13 train no.11610  loss = 1449.03284 avg_loss = 2.50593\n",
            "epoch no.13 train no.11620  loss = 884.47961 avg_loss = 2.49754\n",
            "epoch no.13 train no.11630  loss = 1387.77966 avg_loss = 2.49562\n",
            "epoch no.13 train no.11640  loss = 832.24170 avg_loss = 2.49671\n",
            "epoch no.13 train no.11650  loss = 1510.71655 avg_loss = 2.48363\n",
            "epoch no.13 train no.11660  loss = 863.40704 avg_loss = 2.49534\n",
            "epoch no.13 train no.11670  loss = 1070.76270 avg_loss = 2.50874\n",
            "epoch no.13 train no.11680  loss = 970.42761 avg_loss = 2.50966\n",
            "epoch no.13 train no.11690  loss = 1512.36682 avg_loss = 2.51154\n",
            "epoch no.13 train no.11700  loss = 1684.80847 avg_loss = 2.50182\n",
            "epoch no.13 train no.11710  loss = 936.88611 avg_loss = 2.52075\n",
            "epoch no.14 train no.11720  loss = 942.89783 avg_loss = 2.51269\n",
            "epoch no.14 train no.11730  loss = 1462.00696 avg_loss = 2.50171\n",
            "epoch no.14 train no.11740  loss = 1003.69580 avg_loss = 2.48368\n",
            "epoch no.14 train no.11750  loss = 821.47662 avg_loss = 2.46171\n",
            "epoch no.14 train no.11760  loss = 928.40051 avg_loss = 2.44522\n",
            "epoch no.14 train no.11770  loss = 895.00208 avg_loss = 2.42583\n",
            "epoch no.14 train no.11780  loss = 859.12616 avg_loss = 2.41051\n",
            "epoch no.14 train no.11790  loss = 992.00238 avg_loss = 2.38986\n",
            "epoch no.14 train no.11800  loss = 851.80389 avg_loss = 2.37999\n",
            "epoch no.14 train no.11810  loss = 894.41034 avg_loss = 2.37243\n",
            "epoch no.14 train no.11820  loss = 834.01880 avg_loss = 2.36593\n",
            "epoch no.14 train no.11830  loss = 851.63757 avg_loss = 2.35568\n",
            "epoch no.14 train no.11840  loss = 1015.46533 avg_loss = 2.35728\n",
            "epoch no.14 train no.11850  loss = 1015.94312 avg_loss = 2.35862\n",
            "epoch no.14 train no.11860  loss = 945.98712 avg_loss = 2.35141\n",
            "epoch no.14 train no.11870  loss = 945.93994 avg_loss = 2.34212\n",
            "epoch no.14 train no.11880  loss = 960.48431 avg_loss = 2.34214\n",
            "epoch no.14 train no.11890  loss = 1249.48755 avg_loss = 2.32995\n",
            "epoch no.14 train no.11900  loss = 927.16321 avg_loss = 2.33256\n",
            "epoch no.14 train no.11910  loss = 809.80206 avg_loss = 2.32553\n",
            "epoch no.14 train no.11920  loss = 1887.93542 avg_loss = 2.32155\n",
            "epoch no.14 train no.11930  loss = 937.89551 avg_loss = 2.31773\n",
            "epoch no.14 train no.11940  loss = 896.65710 avg_loss = 2.31870\n",
            "epoch no.14 train no.11950  loss = 949.65161 avg_loss = 2.31529\n",
            "epoch no.14 train no.11960  loss = 924.87909 avg_loss = 2.31676\n",
            "epoch no.14 train no.11970  loss = 2347.97290 avg_loss = 2.32679\n",
            "epoch no.14 train no.11980  loss = 2545.72876 avg_loss = 2.33455\n",
            "epoch no.14 train no.11990  loss = 1305.40552 avg_loss = 2.32707\n",
            "epoch no.14 train no.12000  loss = 1437.78320 avg_loss = 2.32603\n",
            "243\n",
            "to_tokens: ['▁[', '▁나', '▁', '▁만날', '▁올', '꺼', '어', '▁않을', '라', '▁', '은', '▁수', '▁없는', '▁', '의', '기에', '▁', '를', '▁눈물', '이', '▁너', '별', '▁', '▁', '를', '▁떠나', '게', '▁하', '▁수', '▁없는', '▁나', '의', '▁눈물', '픔', '▁미소', '로', '만', '움', '할', '▁말', '▁너', '를', '▁', '할', '▁수', '▁있는', '▁', '의', '▁슬', '은', '▁', '게', '▁돌아', '▁수', '▁수', '랐', '어', '▁너', '의', '▁눈물', '이', '널', '▁다시', '▁울', '서', '해', '▁다시', '대', '▁사랑', '게', '마', '▁너', '의', '▁내', '▁있었', '잖', '▁너', '의', '▁사랑', '이', '▁너', '의', '▁사랑', '이', '야', '도', '퍼', '▁말', '마', '▁너', '는', '▁슬', '어', '마', '▁너', '픔', '▁사랑', '▁눈물', '로', '데', '이', '야', '나', '▁날', '▁사랑', '려', '두', '▁수', '만', '▁수', '▁없는', '▁사랑', '대', '이', '▁너', '의', '도', '의', '▁사랑', '이', '▁너', '니', '▁뿐', '▁', '해', '▁사랑', '의', '▁', '이', '▁사랑', '이', '▁없는', '▁떠난', '▁너', '는', '▁그', '▁아', '▁너', '널', '▁', '▁너', '게', '▁사랑', '▁너', '야', '▁사랑', '▁', '▁사랑', '야', '▁', '게', '까지', '도', '를', '▁', '가', '에', '하늘', '▁', '을', '뜨', '▁', '봐', '▁너', '의', '▁눈물', '이', '▁', '의', '▁눈물', '픈', '을', '▁적', '시', '▁적', '시', '도', '▁울', '고', '▁하', '의', '▁눈물', '이', '▁', '의', '▁눈물', '▁눈물', '을', '▁', '해', '▁', '고', '▁하', '얀', '▁', '게', '▁하', '얀', '▁', '을', '▁적', '시', '데', '픈', '▁사랑', '아', '▁너', '직', '▁너', '▁한번', '도', '▁울', '게', '▁너', '고', '▁웃', '고', '▁사랑', '게', '</s>', '얀', '▁눈', '을', '▁너', '</s>']\n",
            "너라면 다시 못 올 울지 몰라 사랑할 수 없는 나였기에 나의 사랑은 이젠\n",
            "\n",
            "내가 너를힘들게 할 수 있게 나의 슬픈 눈물로 미워하지마 너를 사랑할 수 있게\n",
            "\n",
            "나의 사랑이내게 줄 줄 몰랐던 나의 아픔 으로날 용서해 그를 울리지마 너는 알고 있니 나의 사랑이 너의 사랑이 너무 슬퍼 하지마 너도 울지마 슬픈 내게 온 사랑이 언제나날 버려질게할 수 있는 그 사랑이 너와 나의 사랑이었을까 사랑해 너의 사랑아 끝이 날 떠난다는걸 이제 는 없어 그게 바로 너야만 하는 사람이야 그날까지 너의 눈가 에눈 을바라봐 너의 눈물이\n",
            "\n",
            "나의슬픔을 적을 적 없어도 울게 너의 눈물이\n",
            "\n",
            "너의 그 아픔이 사랑이 울게 하얀내게 하얀 눈을 적 없는 슬픈 사랑이\n",
            "\n",
            "오직 단 한번도 울고 웃고 웃는 내게 하얀 눈이야</s>\n",
            "epoch no.14 train no.12010  loss = 1422.17102 avg_loss = 2.34157\n",
            "epoch no.14 train no.12020  loss = 824.58258 avg_loss = 2.34014\n",
            "epoch no.14 train no.12030  loss = 2506.85645 avg_loss = 2.35547\n",
            "epoch no.14 train no.12040  loss = 1622.83179 avg_loss = 2.37596\n",
            "epoch no.14 train no.12050  loss = 1042.11621 avg_loss = 2.37227\n",
            "epoch no.14 train no.12060  loss = 978.54626 avg_loss = 2.38624\n",
            "epoch no.14 train no.12070  loss = 1319.09326 avg_loss = 2.37190\n",
            "epoch no.14 train no.12080  loss = 1345.34473 avg_loss = 2.36882\n",
            "epoch no.14 train no.12090  loss = 909.96515 avg_loss = 2.36280\n",
            "epoch no.14 train no.12100  loss = 846.90466 avg_loss = 2.36428\n",
            "epoch no.14 train no.12110  loss = 861.71191 avg_loss = 2.36415\n",
            "epoch no.14 train no.12120  loss = 1019.78503 avg_loss = 2.35838\n",
            "epoch no.14 train no.12130  loss = 1496.68774 avg_loss = 2.35313\n",
            "epoch no.14 train no.12140  loss = 1265.50610 avg_loss = 2.35104\n",
            "epoch no.14 train no.12150  loss = 1489.02979 avg_loss = 2.35932\n",
            "epoch no.14 train no.12160  loss = 925.83734 avg_loss = 2.34532\n",
            "epoch no.14 train no.12170  loss = 1812.34155 avg_loss = 2.35075\n",
            "epoch no.14 train no.12180  loss = 919.59241 avg_loss = 2.36076\n",
            "epoch no.14 train no.12190  loss = 1073.18359 avg_loss = 2.35891\n",
            "epoch no.14 train no.12200  loss = 1020.32349 avg_loss = 2.37005\n",
            "epoch no.14 train no.12210  loss = 1463.36328 avg_loss = 2.37466\n",
            "epoch no.14 train no.12220  loss = 982.09521 avg_loss = 2.38885\n",
            "epoch no.14 train no.12230  loss = 945.38611 avg_loss = 2.39243\n",
            "epoch no.14 train no.12240  loss = 1382.57776 avg_loss = 2.38871\n",
            "epoch no.14 train no.12250  loss = 1302.54822 avg_loss = 2.38224\n",
            "epoch no.14 train no.12260  loss = 925.43213 avg_loss = 2.38096\n",
            "epoch no.14 train no.12270  loss = 966.06476 avg_loss = 2.39231\n",
            "epoch no.14 train no.12280  loss = 823.75916 avg_loss = 2.37245\n",
            "epoch no.14 train no.12290  loss = 847.88599 avg_loss = 2.36844\n",
            "epoch no.14 train no.12300  loss = 894.61310 avg_loss = 2.37103\n",
            "epoch no.14 train no.12310  loss = 1293.87085 avg_loss = 2.35669\n",
            "epoch no.14 train no.12320  loss = 1377.11194 avg_loss = 2.37082\n",
            "epoch no.14 train no.12330  loss = 810.40790 avg_loss = 2.36463\n",
            "epoch no.14 train no.12340  loss = 1058.13623 avg_loss = 2.36819\n",
            "epoch no.14 train no.12350  loss = 943.19641 avg_loss = 2.36702\n",
            "epoch no.14 train no.12360  loss = 1403.08069 avg_loss = 2.37538\n",
            "epoch no.14 train no.12370  loss = 806.04285 avg_loss = 2.35939\n",
            "epoch no.14 train no.12380  loss = 1206.22949 avg_loss = 2.35030\n",
            "epoch no.14 train no.12390  loss = 933.49152 avg_loss = 2.34466\n",
            "epoch no.14 train no.12400  loss = 742.47046 avg_loss = 2.33109\n",
            "epoch no.14 train no.12410  loss = 1048.40588 avg_loss = 2.34030\n",
            "epoch no.14 train no.12420  loss = 977.15796 avg_loss = 2.32923\n",
            "epoch no.14 train no.12430  loss = 1641.95605 avg_loss = 2.33033\n",
            "epoch no.14 train no.12440  loss = 1165.14282 avg_loss = 2.34562\n",
            "epoch no.14 train no.12450  loss = 962.26227 avg_loss = 2.35689\n",
            "epoch no.14 train no.12460  loss = 1414.23425 avg_loss = 2.34257\n",
            "epoch no.14 train no.12470  loss = 983.98706 avg_loss = 2.34083\n",
            "epoch no.14 train no.12480  loss = 2549.34937 avg_loss = 2.33904\n",
            "epoch no.14 train no.12490  loss = 1057.66541 avg_loss = 2.35514\n",
            "epoch no.14 train no.12500  loss = 1038.37402 avg_loss = 2.36277\n",
            "276\n",
            "to_tokens: ['▁[', '▁내', '▁', '▁수', '이', '▁', '▁할', '▁힘', '했', '어', '▁너', '안', '하다는', '도', '안', '해', '▁말', '아', '▁없는', '마', '라', '해', '▁', '▁말', '은', '▁못', '하게', '▁너', '▁', '▁말', '도', '야', '▁', '냐', '▁네', '게', '을', '냐', '▁아', '대', '▁아', '요', '도', '한', '도', '▁네', '게', '▁줄', '했', '어', '▁', '냐', '▁마음', '별', '을', '▁', '냐', '▁그', '대', '꺼', '▁', '라', '▁', '럴', '▁줄', '▁몰', '라', '▁', '▁말', '▁못', '▁', '해', '도', '젠', '▁하지', '지', '▁', '▁', '한', '▁', '를', '▁', '도', '한', '도', '▁', '럴', '▁울', '의', '▁', '해', '▁이', '를', '▁마음', '▁', '▁가져', '가', '래', '▁', '가', '▁', '▁', '▁줄', '▁가져', '▁', '어', '▁', '게', '이', '야', '▁', '도', '▁사랑', '해', '단', '▁말', '도', '건', '▁줄', '▁알', '▁있어', '▁네', '를', '▁너무', '가', '줘', '지', '▁않', '게', '▁', '은', '해', '▁그', '대', '한', '▁안', '마', '▁네', '는', '를', '▁사랑', '해', '▁말', '하고', '래', '▁', '를', '▁사랑', '해', '▁나', '▁말', '▁말', '하지', '▁다', '게', '▁나', '▁수', '어', '▁', '▁그', '를', '▁사랑', '해', '▁나', '▁말', '▁말', '가', '▁좋아', '싶', '▁말', '▁어', '▁사랑', '해', '▁나', '를', '▁전', '부', '래', '▁사랑', '해', '▁나', '▁말', '▁아', '▁다', '▁마음', '▁알', '냐', '▁네', '가', '▁좋아', '잖', '니', '▁나', '해', '잖', '▁없어', '▁말', '하지', '래', '▁', '의', '▁사랑', '해', '▁말', '를', '▁', '▁말', '▁하지', '▁못하는', '했', '어', '▁사랑', '▁네', '가', '▁좋아', '▁마음', '이', '▁내', '▁사랑', '해', '▁나', '를', '▁사랑', '해', '▁나', '해', '▁나', '할', '▁싶은', '▁말', '할', '해', '▁말', '할', '래', '▁', '▁사랑', '해', '▁나', '▁내', '해', '▁나', '할', '▁있어', '▁네', '가', '▁좋아', '파', '하는', '</s>', '해', '▁너', '를', '▁사랑', '해', '</s>']\n",
            "너라면 할말을 대신할 못했어\n",
            "\n",
            "미안해 미안해 말은 하지마 사랑한단 말도 못하게한단말이야 아냐 내맘 아냐 그대나봐 사랑해 난 네게 말했어 아픈 이별이 아냐 그럴지 몰라그럴지몰라 왜 말도 안해이 말로는\n",
            "\n",
            "못 다한\n",
            "\n",
            "너의 말 전하지 못해\n",
            "\n",
            "그대 나를 사랑해 나의 마음을 모두 가져갈래 네게 주고모두 다주고 싶었어 내일이야\n",
            "\n",
            "나를 사랑한단 말 그럴 줄 알고 있어 너에게다 말해주지 않을래 아직 사랑해 그말은 하지마 다시 나를 사랑해 말할게너를 사랑해 왜 그런 말도 모르고 살았어 정말 너를 사랑해이젠 네가보고 싶은걸 정말 사랑해 나의전할래 사랑해 그 말로 내맘 아냐 네가 알겠지 다 알수 없는 말할래 나를 사랑해 나보다더 말하지 못됐어 나는 네가 내 마음이 정말 사랑해 나를 사랑해 사랑해 말하고 싶은 말 사랑해 말할게 너무 사랑해 아직 사랑해 말하고 있어 네가 아파해 사랑해 나를 사랑해</s>\n",
            "epoch no.14 train no.12510  loss = 2162.16846 avg_loss = 2.36222\n",
            "epoch no.14 train no.12520  loss = 1238.54138 avg_loss = 2.36285\n",
            "epoch no.14 train no.12530  loss = 1236.09241 avg_loss = 2.35810\n",
            "epoch no.14 train no.12540  loss = 832.64758 avg_loss = 2.34167\n",
            "epoch no.14 train no.12550  loss = 926.85327 avg_loss = 2.35330\n",
            "epoch no.15 train no.12560  loss = 834.39484 avg_loss = 2.34172\n",
            "epoch no.15 train no.12570  loss = 1906.74023 avg_loss = 2.31331\n",
            "epoch no.15 train no.12580  loss = 930.31635 avg_loss = 2.30189\n",
            "epoch no.15 train no.12590  loss = 938.79498 avg_loss = 2.28193\n",
            "epoch no.15 train no.12600  loss = 859.18036 avg_loss = 2.28591\n",
            "epoch no.15 train no.12610  loss = 924.53937 avg_loss = 2.27036\n",
            "epoch no.15 train no.12620  loss = 806.37830 avg_loss = 2.25540\n",
            "epoch no.15 train no.12630  loss = 836.09125 avg_loss = 2.23425\n",
            "epoch no.15 train no.12640  loss = 1182.68872 avg_loss = 2.22018\n",
            "epoch no.15 train no.12650  loss = 859.49219 avg_loss = 2.21166\n",
            "epoch no.15 train no.12660  loss = 1165.24414 avg_loss = 2.20073\n",
            "epoch no.15 train no.12670  loss = 867.79529 avg_loss = 2.20648\n",
            "epoch no.15 train no.12680  loss = 1474.52087 avg_loss = 2.20623\n",
            "epoch no.15 train no.12690  loss = 1233.08545 avg_loss = 2.20175\n",
            "epoch no.15 train no.12700  loss = 658.44696 avg_loss = 2.20869\n",
            "epoch no.15 train no.12710  loss = 932.68567 avg_loss = 2.21675\n",
            "epoch no.15 train no.12720  loss = 859.01611 avg_loss = 2.21967\n",
            "epoch no.15 train no.12730  loss = 791.75537 avg_loss = 2.22465\n",
            "epoch no.15 train no.12740  loss = 914.70874 avg_loss = 2.21927\n",
            "epoch no.15 train no.12750  loss = 1245.09546 avg_loss = 2.20824\n",
            "epoch no.15 train no.12760  loss = 760.77570 avg_loss = 2.20663\n",
            "epoch no.15 train no.12770  loss = 1021.70343 avg_loss = 2.20822\n",
            "epoch no.15 train no.12780  loss = 1030.84717 avg_loss = 2.21153\n",
            "epoch no.15 train no.12790  loss = 1252.76282 avg_loss = 2.20140\n",
            "epoch no.15 train no.12800  loss = 799.19025 avg_loss = 2.19736\n",
            "epoch no.15 train no.12810  loss = 752.82410 avg_loss = 2.20147\n",
            "epoch no.15 train no.12820  loss = 1325.89832 avg_loss = 2.20334\n",
            "epoch no.15 train no.12830  loss = 838.55994 avg_loss = 2.20971\n",
            "epoch no.15 train no.12840  loss = 1282.94910 avg_loss = 2.21169\n",
            "epoch no.15 train no.12850  loss = 820.49139 avg_loss = 2.22800\n",
            "epoch no.15 train no.12860  loss = 1300.31433 avg_loss = 2.22841\n",
            "epoch no.15 train no.12870  loss = 1120.41382 avg_loss = 2.23493\n",
            "epoch no.15 train no.12880  loss = 867.73407 avg_loss = 2.23378\n",
            "epoch no.15 train no.12890  loss = 879.33075 avg_loss = 2.23783\n",
            "epoch no.15 train no.12900  loss = 970.28558 avg_loss = 2.23886\n",
            "epoch no.15 train no.12910  loss = 2374.10400 avg_loss = 2.23540\n",
            "epoch no.15 train no.12920  loss = 931.72711 avg_loss = 2.23514\n",
            "epoch no.15 train no.12930  loss = 887.57898 avg_loss = 2.23330\n",
            "epoch no.15 train no.12940  loss = 1288.28101 avg_loss = 2.22747\n",
            "epoch no.15 train no.12950  loss = 1025.31848 avg_loss = 2.21990\n",
            "epoch no.15 train no.12960  loss = 1173.17529 avg_loss = 2.21574\n",
            "epoch no.15 train no.12970  loss = 1035.89673 avg_loss = 2.22549\n",
            "epoch no.15 train no.12980  loss = 1242.94067 avg_loss = 2.23062\n",
            "epoch no.15 train no.12990  loss = 887.43756 avg_loss = 2.23985\n",
            "epoch no.15 train no.13000  loss = 811.72839 avg_loss = 2.23433\n",
            "278\n",
            "to_tokens: ['▁[', '▁내', '▁난', '▁', '▁사랑', '젠', '보', '야', '▁그', '▁이제', '▁', '▁', '지', '▁못', '했', '나', '▁내', '▁', '▁돌아', '하지', '니', '▁', '딜', '가', '가', '니', '▁어', '떡', '▁수', '▁없는', '데', '대', '▁내가', '▁몰', '는', '▁살', '글', '거', '▁네', '만', '▁모', '른', '채', '척', '▁했', '도', '어', '▁있는', '잖', '아', '요', '정', '젠', '▁다', '▁내가', '까', '▁싫어', '▁이', '럴', '▁나', '▁싫어', '걸', '▁곳', '을', '▁보', '와', '어', '▁', '▁', '젠', '▁어', '를', '▁보', '려', '고', '▁', '줘', '▁그', '잖', '리', '봐', '만', '▁하는', '▁', '의', '는', '▁못', '▁사람', '일', '할', '▁있어', '▁내가', '게', '로', '▁돌아', '와', '▁수', '▁없는', '잖', '아', '▁이', '를', '▁나', '▁있', '니', '아', '▁오', '마', '▁사랑', '▁나', '▁', '를', '▁', '한', '▁걸', '▁오', '▁뿐', '▁알고', '▁수', '아', '▁난', '▁아닌', '▁다른', '▁할', '▁수', '▁없는', '잖', '아', '▁', '어', '도', '대', '여', '게', '로', '와', '▁줄', '▁아', '▁날', '▁사랑', '▁건', '의', '▁', '으로', '▁너', '파', '고', '한', '▁위해', '▁너무', '▁힘들', '다', '릴', '▁', '지', '니', '▁너', '▁', '▁사람', '▁만나', '▁위해서', '▁울', '▁', '▁너', '게', '▁너', '직', '▁너', '▁한번', '도', '▁그', '대', '여', '만', '▁약속', '▁모든', '부', '를', '▁너', '야', '▁너', '▁나', '를', '▁위한', '낼', '▁내가', '다', '고', '▁그', '대', '여', '▁오', '▁나', '게', '▁오', '를', '▁위해서', '라면', '▁나', '대', '여', '한', '요', '▁날', '대', '▁나', '▁내', '게', '▁너', '를', '인', '걸', '▁너', '를', '▁위한', '▁사람', '여', '린', '▁수', '를', '▁세상', '대', '여', '▁내', '대', '▁나', '야', '▁나', '▁줄', '면', '▁그', '녕', '▁내가', '를', '▁모든', '해', '줘', '를', '이', '▁걸', '▁너', '파', '하는', '▁사람', '▁나', '를', '▁사랑', '</s>', '어', '▁내가', '를', '▁모든', '▁걸', '▁아', '파', '할', '를', '▁모든', '부', '를', '▁나', '대', '여', '▁오']\n",
            "너라면 못난 이 바보야 왜 그렇게 날 잡지 못했어 내게 말했어어딜갔어 어쩔 수 없는 그땐 정말 모르고 서성한 표정으로 모른 척 하지 웃고 있잖아 요 이러는 걸 내가 싫어 이젠 내가아닌 다른 곳을 찾아왔어 하지만 이젠 나를 버린다고말해도 되돌아야만 해\n",
            "\n",
            "너 없이는 그대 사랑하고 싶어내게로돌아올 수 없잖아너도 알고있잖아 아픈만큼 내가 너를 사랑하는 건 너도 알잖아 내가 아닌 사랑을 할 수 없잖아 힘들어 그대 내게 돌아와줘요 날 위한 나의 사랑은 아냐 행복하기엔 정말 기다려\n",
            "\n",
            "주겠지 내가 아닌 사람을 위해 내가\n",
            "\n",
            "있는데 내겐 오직 단 한번이라도 그대에게만의 전부였던거야만 나를 보며 떠난다는그대여야 내게 나를 위해서야 그대 사랑해도 그대여 내겐 너뿐인걸 너를 위한 사람이 여잔 너 없는 그대여 그대여야해주면 안아 너의 사랑해 너뿐인걸 아파하는사람이 나를 위해 울면 나의 모든 것을 아파 나의 전부니까 그대여</s>\n",
            "epoch no.15 train no.13010  loss = 924.75299 avg_loss = 2.23892\n",
            "epoch no.15 train no.13020  loss = 870.80469 avg_loss = 2.24566\n",
            "epoch no.15 train no.13030  loss = 1110.42456 avg_loss = 2.24212\n",
            "epoch no.15 train no.13040  loss = 1085.71631 avg_loss = 2.24341\n",
            "epoch no.15 train no.13050  loss = 1496.45837 avg_loss = 2.23668\n",
            "epoch no.15 train no.13060  loss = 1195.15405 avg_loss = 2.24740\n",
            "epoch no.15 train no.13070  loss = 701.44336 avg_loss = 2.23655\n",
            "epoch no.15 train no.13080  loss = 874.21149 avg_loss = 2.24338\n",
            "epoch no.15 train no.13090  loss = 828.70587 avg_loss = 2.25031\n",
            "epoch no.15 train no.13100  loss = 893.19629 avg_loss = 2.25125\n",
            "epoch no.15 train no.13110  loss = 792.86945 avg_loss = 2.24115\n",
            "epoch no.15 train no.13120  loss = 1278.39209 avg_loss = 2.25049\n",
            "epoch no.15 train no.13130  loss = 1515.35583 avg_loss = 2.25391\n",
            "epoch no.15 train no.13140  loss = 833.15356 avg_loss = 2.26033\n",
            "epoch no.15 train no.13150  loss = 814.83899 avg_loss = 2.24727\n",
            "epoch no.15 train no.13160  loss = 2176.79346 avg_loss = 2.24726\n",
            "epoch no.15 train no.13170  loss = 908.84686 avg_loss = 2.25772\n",
            "epoch no.15 train no.13180  loss = 838.87384 avg_loss = 2.26496\n",
            "epoch no.15 train no.13190  loss = 959.94690 avg_loss = 2.26760\n",
            "epoch no.15 train no.13200  loss = 1163.31030 avg_loss = 2.24608\n",
            "epoch no.15 train no.13210  loss = 906.96747 avg_loss = 2.25529\n",
            "epoch no.15 train no.13220  loss = 1412.97742 avg_loss = 2.24136\n",
            "epoch no.15 train no.13230  loss = 728.56445 avg_loss = 2.24327\n",
            "epoch no.15 train no.13240  loss = 796.40295 avg_loss = 2.24745\n",
            "epoch no.15 train no.13250  loss = 810.32306 avg_loss = 2.24234\n",
            "epoch no.15 train no.13260  loss = 1371.18860 avg_loss = 2.23608\n",
            "epoch no.15 train no.13270  loss = 928.41370 avg_loss = 2.21852\n",
            "epoch no.15 train no.13280  loss = 1198.36426 avg_loss = 2.22042\n",
            "epoch no.15 train no.13290  loss = 970.72351 avg_loss = 2.21904\n",
            "epoch no.15 train no.13300  loss = 923.11957 avg_loss = 2.22454\n",
            "epoch no.15 train no.13310  loss = 855.13239 avg_loss = 2.22392\n",
            "epoch no.15 train no.13320  loss = 876.20984 avg_loss = 2.22454\n",
            "epoch no.15 train no.13330  loss = 868.53406 avg_loss = 2.22852\n",
            "epoch no.15 train no.13340  loss = 1011.78131 avg_loss = 2.22246\n",
            "epoch no.15 train no.13350  loss = 1505.29089 avg_loss = 2.24297\n",
            "epoch no.15 train no.13360  loss = 915.68433 avg_loss = 2.26037\n",
            "epoch no.15 train no.13370  loss = 690.22272 avg_loss = 2.25095\n",
            "epoch no.15 train no.13380  loss = 897.34467 avg_loss = 2.25413\n",
            "epoch no.15 train no.13390  loss = 2085.85742 avg_loss = 2.25422\n",
            "epoch no.16 train no.13400  loss = 765.09717 avg_loss = 2.24355\n",
            "epoch no.16 train no.13410  loss = 1121.80457 avg_loss = 2.22289\n",
            "epoch no.16 train no.13420  loss = 878.68298 avg_loss = 2.21351\n",
            "epoch no.16 train no.13430  loss = 814.69507 avg_loss = 2.20278\n",
            "epoch no.16 train no.13440  loss = 719.28894 avg_loss = 2.18093\n",
            "epoch no.16 train no.13450  loss = 1547.91675 avg_loss = 2.17378\n",
            "epoch no.16 train no.13460  loss = 678.37927 avg_loss = 2.16712\n",
            "epoch no.16 train no.13470  loss = 1037.27234 avg_loss = 2.14738\n",
            "epoch no.16 train no.13480  loss = 848.79315 avg_loss = 2.14718\n",
            "epoch no.16 train no.13490  loss = 765.15833 avg_loss = 2.15090\n",
            "epoch no.16 train no.13500  loss = 788.52051 avg_loss = 2.14725\n",
            "268\n",
            "to_tokens: ['▁[', '▁내', '▁', '와', '▁사랑', '는', '고', '▁', '안', '해', '▁나', '마', '▁말', '은', '▁', '마', '▁', '▁생각', '할', '▁울', '▁그냥', '서', '서', '▁울', '▁너', '것', '도', '▁할', '▁', '▁돌아', '의', '▁행복', '해', '해', '▁나', '▁사랑', '해서', '▁너무', '▁있어', '▁우리', '▁더', '▁너', '▁이', '대로', '▁살아', '▁사랑', '해서', '▁너무', '▁너무', '니까', '아', '▁우리', '걸', '만', '만', '▁나', '를', '▁알아', '줄', '▁수', '▁없는', '▁없어', '서', '▁너무', '▁', '파', '서', '마', '▁그냥', '를', '▁', '라면', '서', '▁너', '▁그', '만', '▁나', '를', '▁', '지', '마', '▁너', '▁내', '만', '▁정말', '▁잘', '▁나', '▁수', '가', '데', '를', '▁가슴', '에', '▁너무', '어', '만', '거', '보', '같은', '만', '을', '▁나', '의', '▁손', '별', '이', '▁아닌', '픈', '도', '▁나', '글', '을', '▁난', '▁내가', '▁너무', '와', '▁너무', '해서', '었던', '까', '▁내가', '의', '했', '▁사람', '도', '▁다', '의', '▁사랑', '보', '▁말', '▁나', '▁나', '나', '어', '▁했', '었던', '▁나', '땐', '▁나', '게', '▁주', '었던', '▁너무', '▁너무', '▁나', '대가', '▁수', '▁있는', '거', '▁나', '의', '▁잘못', '이', '니까', '디', '▁너무', '▁수', '▁있는', '▁사랑', '이', '▁너무', '▁나', '▁그', '▁사랑', '이라고', '이', '니까', '▁나', '의', '▁모든', '이', '▁너', '라', '▁', '준', '</s>', '대가', '도', '야', '▁나', '대가', '도', '▁그', '대가', '▁없는', '요', '를', '▁떠나', '보는', '까', '▁있어', '지', '▁못', '했', '었던', '▁그', '대가', '는', '▁미', '▁정말', '서', '별', '을', '니까', '고', '▁말', '▁나', '대가', '▁나', '고', '▁', '이', '별', '을', '▁수', '▁있게', '으니', '까', '대가', '▁떠나', '이', '▁뭐', '요', '▁나', '를', '이', '만', '▁떠나', '도', '▁없어', '요', '▁나', '▁아', '프', '할', '게', '이', '▁뭐', '▁아', '중', '해', '겐', '는', '▁없', '▁내', '만', '▁뭐', '나', '이', '니까', '▁정말', '▁바', '안', '해', '▁또', '요', '▁있어', '▁사랑', '대가', '▁사랑', '▁나']\n",
            "너라면 너를보내주고 미안해 하지 못한 말은 하지마라\n",
            "\n",
            "생각 없이 그냥 돌아서면 난 아무 말도 없이 그냥 너만 행복해야 해 너무 사랑해서 알고 있어 내가 있어 우리 이대로 너무 사랑해서가 되잖아 그대 하나만 나도 해줄 수가 없어서 너무 아파 하지마 나를 위해서라서 이제 그만 너를 놓지 않아서 그대가 더는 할 수 없는 나의 가슴에 묻어버린 바보 하나만이 너의 이별이 아파와 서있으니까 내가 너를 사랑했으니까나 사랑한 죄도 너를 떠나가지마요 너무 힘들게 했었던 그대가 내게 주었던 내가 먼저 그럴 수 있는 그것이 나의 사랑이 부를 줄 수 있는 사랑이니까요 내 마지막 사랑이니까 나의 사랑이 뭐라 해요 그대여서 그대도 그대가 있어 너를 바라볼게 주지 말했으니 그대 정말 난 없어 이별이 울지라도 그대가 울고만 이별할 수 없으니 그대가 사랑이니까요 나만 나를 떠나는 없어서 이렇게 아파 내 사랑이 더 소중에 이제는 없는 눈물이 너무 사랑이기에 정말 미안고 떠나가도 그대가있어서</s>\n",
            "epoch no.16 train no.13510  loss = 967.82092 avg_loss = 2.14166\n",
            "epoch no.16 train no.13520  loss = 783.37073 avg_loss = 2.12654\n",
            "epoch no.16 train no.13530  loss = 1300.97461 avg_loss = 2.11390\n",
            "epoch no.16 train no.13540  loss = 1410.11841 avg_loss = 2.10960\n",
            "epoch no.16 train no.13550  loss = 1959.44958 avg_loss = 2.10967\n",
            "epoch no.16 train no.13560  loss = 881.76489 avg_loss = 2.12090\n",
            "epoch no.16 train no.13570  loss = 758.42358 avg_loss = 2.11106\n",
            "epoch no.16 train no.13580  loss = 863.31757 avg_loss = 2.09914\n",
            "epoch no.16 train no.13590  loss = 906.78503 avg_loss = 2.10048\n",
            "epoch no.16 train no.13600  loss = 757.33197 avg_loss = 2.07703\n",
            "epoch no.16 train no.13610  loss = 1131.40430 avg_loss = 2.08637\n",
            "epoch no.16 train no.13620  loss = 794.85345 avg_loss = 2.08954\n",
            "epoch no.16 train no.13630  loss = 860.43713 avg_loss = 2.09186\n",
            "epoch no.16 train no.13640  loss = 880.52570 avg_loss = 2.08356\n",
            "epoch no.16 train no.13650  loss = 881.29309 avg_loss = 2.08695\n",
            "epoch no.16 train no.13660  loss = 1944.12634 avg_loss = 2.08235\n",
            "epoch no.16 train no.13670  loss = 853.86981 avg_loss = 2.08250\n",
            "epoch no.16 train no.13680  loss = 1236.42236 avg_loss = 2.08333\n",
            "epoch no.16 train no.13690  loss = 1729.09595 avg_loss = 2.08280\n",
            "epoch no.16 train no.13700  loss = 890.74609 avg_loss = 2.08920\n",
            "epoch no.16 train no.13710  loss = 628.04968 avg_loss = 2.08223\n",
            "epoch no.16 train no.13720  loss = 845.25433 avg_loss = 2.08545\n",
            "epoch no.16 train no.13730  loss = 1067.68469 avg_loss = 2.09652\n",
            "epoch no.16 train no.13740  loss = 977.19171 avg_loss = 2.10111\n",
            "epoch no.16 train no.13750  loss = 787.55115 avg_loss = 2.10648\n",
            "epoch no.16 train no.13760  loss = 916.60187 avg_loss = 2.11181\n",
            "epoch no.16 train no.13770  loss = 973.71558 avg_loss = 2.11605\n",
            "epoch no.16 train no.13780  loss = 796.00494 avg_loss = 2.11643\n",
            "epoch no.16 train no.13790  loss = 675.56274 avg_loss = 2.11042\n",
            "epoch no.16 train no.13800  loss = 897.22736 avg_loss = 2.12111\n",
            "epoch no.16 train no.13810  loss = 789.60144 avg_loss = 2.11289\n",
            "epoch no.16 train no.13820  loss = 1386.94019 avg_loss = 2.11726\n",
            "epoch no.16 train no.13830  loss = 776.70447 avg_loss = 2.13208\n",
            "epoch no.16 train no.13840  loss = 783.55225 avg_loss = 2.12342\n",
            "epoch no.16 train no.13850  loss = 1535.00085 avg_loss = 2.11001\n",
            "epoch no.16 train no.13860  loss = 684.13446 avg_loss = 2.09281\n",
            "epoch no.16 train no.13870  loss = 837.22461 avg_loss = 2.09616\n",
            "epoch no.16 train no.13880  loss = 851.73743 avg_loss = 2.10323\n",
            "epoch no.16 train no.13890  loss = 858.16315 avg_loss = 2.10568\n",
            "epoch no.16 train no.13900  loss = 923.61633 avg_loss = 2.11037\n",
            "epoch no.16 train no.13910  loss = 895.22943 avg_loss = 2.11357\n",
            "epoch no.16 train no.13920  loss = 820.89691 avg_loss = 2.11213\n",
            "epoch no.16 train no.13930  loss = 808.77020 avg_loss = 2.11566\n",
            "epoch no.16 train no.13940  loss = 1860.81091 avg_loss = 2.09995\n",
            "epoch no.16 train no.13950  loss = 724.72284 avg_loss = 2.08916\n",
            "epoch no.16 train no.13960  loss = 852.63098 avg_loss = 2.09064\n",
            "epoch no.16 train no.13970  loss = 734.77252 avg_loss = 2.08563\n",
            "epoch no.16 train no.13980  loss = 783.32019 avg_loss = 2.08830\n",
            "epoch no.16 train no.13990  loss = 1000.93030 avg_loss = 2.10280\n",
            "epoch no.16 train no.14000  loss = 593.97113 avg_loss = 2.09397\n",
            "157\n",
            "to_tokens: ['▁[', '▁내', '▁', '▁너', '를', '▁', '며', '▁', '▁아', '▁', '순', '만', '▁못', '켜', '도', '야', '도', '▁눈물', '이', '▁흘러', '지만', '▁않아', '네', '▁', '이', '▁', '▁사람들', '▁', '게', '▁말', '수', '가', '▁없어', '▁살아', '를', '▁', '▁나', '▁네', '고', '▁있는', '어', '▁많은', '의', '▁이런', '▁사람들', '들을', '▁', '▁네', '를', '▁사랑', '했', '어', '▁', '▁너', '를', '▁', '했', '단', '말', '도', '가', '▁나는', '▁수', '▁있어', '▁더', '▁모든', '▁많은', '단', '▁말', '은', '▁이제', '마', '▁언제', '를', '▁위해', '▁사랑', '해서', '어', '▁말', '말', '▁', '말', '이', '▁하지', '▁수', '가', '▁너무', '▁네', '가', '▁너무', '싶', '어', '▁나', '건', '만으로', '▁나는', '▁난', '▁네', '곁', '▁좋은', '▁싶었', '어', '▁나', '게', '▁주고', '싶', '어', '▁오', '원', '히', '▁내', '곁', '▁것을', '▁주고', '▁누구', '만으로', '▁', '▁많은', '▁네', '한', '것', '▁네', '가', '▁주고', '▁수', '▁있어', '▁난', '▁네', '다', '릴', '게', '▁있어', '▁난', '가', '▁내', '▁싶었', '어', '▁나', '를', '▁너무', '해', '에', '▁너무', '를', '▁사랑', '▁사랑', '해', '</s>']\n",
            "너라면\n",
            "\n",
            "나는 너를 기다리는 마음은 한숨을 삼켜 보내고 난 눈물이 나오지않아사랑이 많은 것을 네게 할 수가 있어 너를향한 난 울고있어나에게 많은 날들을 나는 너를 사랑했어 그러나 너를 사랑한단 말 하나만으로 살 수 없어 내게한단 말은 하지마 너를 너무 사랑했단 그말그말은 할 수 있어 나는 네게 주고 싶었어그것만으로도 난 네게 주고 싶었어 내게 주고 싶었어 영원히 내 모든걸 그것을\n",
            "\n",
            "그것이 난 사랑한걸 네게 할 수 있어 난 기다릴 수 있어 네게 주고싶어 너를 사랑하기에 너를 너무 사랑해</s>\n",
            "epoch no.16 train no.14010  loss = 884.28937 avg_loss = 2.09248\n",
            "epoch no.16 train no.14020  loss = 824.15686 avg_loss = 2.08102\n",
            "epoch no.16 train no.14030  loss = 1821.80688 avg_loss = 2.08065\n",
            "epoch no.16 train no.14040  loss = 1028.58337 avg_loss = 2.09027\n",
            "epoch no.16 train no.14050  loss = 828.50592 avg_loss = 2.08466\n",
            "epoch no.16 train no.14060  loss = 898.24274 avg_loss = 2.09119\n",
            "epoch no.16 train no.14070  loss = 832.97931 avg_loss = 2.09120\n",
            "epoch no.16 train no.14080  loss = 2187.95557 avg_loss = 2.09283\n",
            "epoch no.16 train no.14090  loss = 655.99994 avg_loss = 2.08300\n",
            "epoch no.16 train no.14100  loss = 712.24652 avg_loss = 2.08211\n",
            "epoch no.16 train no.14110  loss = 721.19519 avg_loss = 2.09192\n",
            "epoch no.16 train no.14120  loss = 796.65497 avg_loss = 2.10542\n",
            "epoch no.16 train no.14130  loss = 1347.84290 avg_loss = 2.10674\n",
            "epoch no.16 train no.14140  loss = 842.32080 avg_loss = 2.10705\n",
            "epoch no.16 train no.14150  loss = 935.10724 avg_loss = 2.11471\n",
            "epoch no.16 train no.14160  loss = 882.20050 avg_loss = 2.12040\n",
            "epoch no.16 train no.14170  loss = 780.77380 avg_loss = 2.12750\n",
            "epoch no.16 train no.14180  loss = 2396.82764 avg_loss = 2.13786\n",
            "epoch no.16 train no.14190  loss = 881.55310 avg_loss = 2.13735\n",
            "epoch no.16 train no.14200  loss = 1246.29419 avg_loss = 2.12745\n",
            "epoch no.16 train no.14210  loss = 829.75952 avg_loss = 2.13635\n",
            "epoch no.16 train no.14220  loss = 639.00061 avg_loss = 2.14007\n",
            "epoch no.17 train no.14230  loss = 868.38495 avg_loss = 2.13937\n",
            "epoch no.17 train no.14240  loss = 562.90820 avg_loss = 2.11435\n",
            "epoch no.17 train no.14250  loss = 1260.11743 avg_loss = 2.09732\n",
            "epoch no.17 train no.14260  loss = 793.49713 avg_loss = 2.07803\n",
            "epoch no.17 train no.14270  loss = 712.79364 avg_loss = 2.07527\n",
            "epoch no.17 train no.14280  loss = 765.99188 avg_loss = 2.05520\n",
            "epoch no.17 train no.14290  loss = 2195.35596 avg_loss = 2.05127\n",
            "epoch no.17 train no.14300  loss = 857.38574 avg_loss = 2.03768\n",
            "epoch no.17 train no.14310  loss = 815.26385 avg_loss = 2.02632\n",
            "epoch no.17 train no.14320  loss = 966.58527 avg_loss = 2.04491\n",
            "epoch no.17 train no.14330  loss = 659.43811 avg_loss = 2.02082\n",
            "epoch no.17 train no.14340  loss = 703.86523 avg_loss = 2.01726\n",
            "epoch no.17 train no.14350  loss = 1205.64636 avg_loss = 2.01419\n",
            "epoch no.17 train no.14360  loss = 803.32544 avg_loss = 2.00833\n",
            "epoch no.17 train no.14370  loss = 695.03040 avg_loss = 2.00369\n",
            "epoch no.17 train no.14380  loss = 1151.67517 avg_loss = 2.00393\n",
            "epoch no.17 train no.14390  loss = 789.98846 avg_loss = 2.00791\n",
            "epoch no.17 train no.14400  loss = 870.97583 avg_loss = 1.99115\n",
            "epoch no.17 train no.14410  loss = 881.23309 avg_loss = 1.98812\n",
            "epoch no.17 train no.14420  loss = 806.53485 avg_loss = 1.97636\n",
            "epoch no.17 train no.14430  loss = 699.58142 avg_loss = 1.96577\n",
            "epoch no.17 train no.14440  loss = 773.83160 avg_loss = 1.97059\n",
            "epoch no.17 train no.14450  loss = 1034.61292 avg_loss = 1.96910\n",
            "epoch no.17 train no.14460  loss = 835.24152 avg_loss = 1.97155\n",
            "epoch no.17 train no.14470  loss = 1118.08252 avg_loss = 1.98113\n",
            "epoch no.17 train no.14480  loss = 941.94824 avg_loss = 1.98219\n",
            "epoch no.17 train no.14490  loss = 765.36377 avg_loss = 1.98064\n",
            "epoch no.17 train no.14500  loss = 834.74719 avg_loss = 1.97577\n",
            "104\n",
            "to_tokens: ['▁[', '▁내', '▁', '하지', '▁', '▁', '녕', '▁내', '▁것을', '▁말', '▁있지만', '▁그', '는', '▁안', '녕', '▁아무', '리', '도', '▁하지', '▁수', '▁알아', '▁있지만', '잖', '아', '▁나는', '해', '라면', '정', '▁위해', '▁할', '▁기', '별', '▁안', '▁돌아', '할', '▁수', '▁없는', '▁없어', '▁떨', '린', '▁정말', '나', '▁슬', '이', '▁메', '어', '지', '▁슬', '해', '▁사랑', '해', '▁이', '해', '▁이', '해', '▁사랑', '▁이', '대', '▁', '▁이', '▁싶은', '▁말', '대', '▁이', '▁', '▁이', '▁말', '은', '▁말을', '▁있어', '기에', '▁이', '▁나', '▁있는데', '▁이', '▁싫어', '요', '는', '서', '러', '워', '▁눈물', '만', '별', '이란', '▁그', '대', '▁눈물', '▁흘리', '만', '져', '▁', '▁이', '▁사랑', '해', '▁', '는', '▁', '할', '▁수', '가', '▁없', '요', '</s>']\n",
            "너라면 말 못 해 정다할 걸 알고 있지만 떠나면 안돼 아무말도 할 것을 알고 있잖아 사랑이 무얼 위해서 나는 이젠 싫어 말 할 수가 없어 우린 너무나 가슴에 묻어야 할 기억해 사랑해 사랑해 사랑해요 그대에게 하고 싶은 그대 내게 남긴 말 할 말이 없었지만 이미 알고 있는데 정말 싫어 이제와 서러운 눈물이별이란 그대 눈물로 가려져 있는데 우리 사랑은 이제는 말할 수가 없어요</s>\n",
            "epoch no.17 train no.14510  loss = 831.73035 avg_loss = 1.96741\n",
            "epoch no.17 train no.14520  loss = 888.01776 avg_loss = 1.97672\n",
            "epoch no.17 train no.14530  loss = 692.54486 avg_loss = 1.97596\n",
            "epoch no.17 train no.14540  loss = 2069.88672 avg_loss = 1.98696\n",
            "epoch no.17 train no.14550  loss = 722.39398 avg_loss = 1.98023\n",
            "epoch no.17 train no.14560  loss = 1820.20044 avg_loss = 1.98184\n",
            "epoch no.17 train no.14570  loss = 855.96429 avg_loss = 1.98108\n",
            "epoch no.17 train no.14580  loss = 856.93768 avg_loss = 1.97661\n",
            "epoch no.17 train no.14590  loss = 819.78253 avg_loss = 1.97756\n",
            "epoch no.17 train no.14600  loss = 1294.56311 avg_loss = 1.98611\n",
            "epoch no.17 train no.14610  loss = 929.47388 avg_loss = 1.99675\n",
            "epoch no.17 train no.14620  loss = 802.78882 avg_loss = 1.99663\n",
            "epoch no.17 train no.14630  loss = 869.19299 avg_loss = 2.01108\n",
            "epoch no.17 train no.14640  loss = 791.20972 avg_loss = 2.00079\n",
            "epoch no.17 train no.14650  loss = 929.82141 avg_loss = 1.99476\n",
            "epoch no.17 train no.14660  loss = 2374.95312 avg_loss = 2.00016\n",
            "epoch no.17 train no.14670  loss = 862.36011 avg_loss = 2.00386\n",
            "epoch no.17 train no.14680  loss = 1115.82971 avg_loss = 1.99979\n",
            "epoch no.17 train no.14690  loss = 1187.09973 avg_loss = 2.00002\n",
            "epoch no.17 train no.14700  loss = 593.58484 avg_loss = 1.99624\n",
            "epoch no.17 train no.14710  loss = 714.50586 avg_loss = 1.99749\n",
            "epoch no.17 train no.14720  loss = 1272.47498 avg_loss = 1.99607\n",
            "epoch no.17 train no.14730  loss = 768.99060 avg_loss = 1.99428\n",
            "epoch no.17 train no.14740  loss = 902.02045 avg_loss = 1.99202\n",
            "epoch no.17 train no.14750  loss = 869.91150 avg_loss = 2.00695\n",
            "epoch no.17 train no.14760  loss = 711.42102 avg_loss = 1.99151\n",
            "epoch no.17 train no.14770  loss = 858.11816 avg_loss = 1.99210\n",
            "epoch no.17 train no.14780  loss = 2141.62524 avg_loss = 1.99081\n",
            "epoch no.17 train no.14790  loss = 961.82812 avg_loss = 1.99011\n",
            "epoch no.17 train no.14800  loss = 632.66089 avg_loss = 1.98476\n",
            "epoch no.17 train no.14810  loss = 866.13397 avg_loss = 1.97262\n",
            "epoch no.17 train no.14820  loss = 835.01636 avg_loss = 1.98142\n",
            "epoch no.17 train no.14830  loss = 635.21851 avg_loss = 1.97680\n",
            "epoch no.17 train no.14840  loss = 819.41235 avg_loss = 1.98641\n",
            "epoch no.17 train no.14850  loss = 1158.90479 avg_loss = 1.99343\n",
            "epoch no.17 train no.14860  loss = 809.80377 avg_loss = 1.99075\n",
            "epoch no.17 train no.14870  loss = 2019.34692 avg_loss = 1.99136\n",
            "epoch no.17 train no.14880  loss = 1199.89160 avg_loss = 2.00243\n",
            "epoch no.17 train no.14890  loss = 800.31110 avg_loss = 1.99986\n",
            "epoch no.17 train no.14900  loss = 796.04388 avg_loss = 1.99408\n",
            "epoch no.17 train no.14910  loss = 2120.26978 avg_loss = 2.00440\n",
            "epoch no.17 train no.14920  loss = 765.40802 avg_loss = 2.01086\n",
            "epoch no.17 train no.14930  loss = 809.80804 avg_loss = 2.00500\n",
            "epoch no.17 train no.14940  loss = 637.89008 avg_loss = 2.01333\n",
            "epoch no.17 train no.14950  loss = 1140.88550 avg_loss = 2.01913\n",
            "epoch no.17 train no.14960  loss = 707.91553 avg_loss = 2.02459\n",
            "epoch no.17 train no.14970  loss = 936.99152 avg_loss = 2.03322\n",
            "epoch no.17 train no.14980  loss = 925.98859 avg_loss = 2.03910\n",
            "epoch no.17 train no.14990  loss = 654.44519 avg_loss = 2.03541\n",
            "epoch no.17 train no.15000  loss = 869.87286 avg_loss = 2.03546\n",
            "208\n",
            "to_tokens: ['▁[', '▁내', '▁아무', '▁', '나', '의', '▁사랑', '한', '▁말', '했', '었', '▁왜', '▁세상', '▁정말', '둠', '수', '▁몰', '랐', '어', '▁사랑', '한다', '▁말', '하던', '▁너', '▁말이', '은', '▁이렇게', '게', '▁', '쳐', '주', '오', '▁', '다', '▁사랑', '▁', '이', '▁말', '했', '지', '▁사랑', '만', '▁', '은', '▁뛰', '널', '▁', '플', '던', '▁눈물', '▁때', '▁', '게', '▁', '▁순간', '은', '▁', '이', '▁아', '파', '하면', '▁', '를', '▁두', '▁나', '▁아', '프', '게', '만', '지', '▁', '의', '▁두', '▁손', '이', '▁', '지', '▁', '▁너', '를', '▁볼', '▁수', '▁없는', '▁한', '줄', '다', '고', '▁', '▁', '▁', '▁', '의', '▁사랑', '할', '▁이', '원', '히', '▁그', '프', '▁하지', '▁날', '▁내', '대로', '인', '도', '▁후', '▁', '의', '을', '▁사랑', '해', '게', '▁없', '▁모르', '어', '▁', '했', '▁말', '▁나', '▁나', '의', '▁', '한다', '▁말', '줘', '요', '▁이제', '▁울', '돌', '아', '▁', '▁수', '▁한번', '만', '▁너', '를', '을', '▁사랑', '해', '▁', '▁', '와', '서', '▁후', '▁그', '대가', '▁사랑', '▁함께', '▁할', '▁수', '▁있다', '▁나', '의', '▁사랑', '아', '▁이렇게', '▁울', '고', '만', '고', '▁있', '▁있', '면', '▁그', '대', '▁아니면', '▁그', '날', '여', '▁제', '대', '와', '을', '면', '▁나', '대', '▁떠나', '의', '▁사랑', '해', '▁수', '▁있다', '▁다시', '대', '▁나', '▁내', '</s>']\n",
            "너라면 난나\n",
            "\n",
            "나를사랑한다 말했니이건 어쩔 줄 몰랐어 사랑한다 말하던 그\n",
            "\n",
            "말왜 내게 가르쳐주고 떠난걸 난사랑한다 말했지 나의 가슴이 터져 아팠던 그 말 내게 한 번만 가슴아 아파서 너의 기억 속에서 아프게 하는지 나의 두눈물러면\n",
            "\n",
            "다시너를 볼 수 있게해준다고 말해줘요 너를 사랑해 영원히 슬퍼하는건 이별까지도그렇게 나만을 사랑할 수 밖에 없었어 사랑한다던 말 나를사랑한다고 말해줘요 다시 되돌아요 단 한번도 너만을 사랑해요 이제와서야 그대와 함께 할 수 없는 나의 사랑은 이렇게 울고 웃고만 있다면 그대가 마지막 그대여 그대만 있다면 그대가 나를사랑할 수 있도록 그대여야</s>\n",
            "모델을 저장합니다.\n",
            "epoch no.17 train no.15010  loss = 817.40979 avg_loss = 2.03722\n",
            "epoch no.17 train no.15020  loss = 824.08972 avg_loss = 2.02800\n",
            "epoch no.17 train no.15030  loss = 879.61804 avg_loss = 2.02840\n",
            "epoch no.17 train no.15040  loss = 684.62695 avg_loss = 2.02550\n",
            "epoch no.17 train no.15050  loss = 888.04114 avg_loss = 2.03407\n",
            "epoch no.17 train no.15060  loss = 866.74335 avg_loss = 2.03262\n",
            "epoch no.18 train no.15070  loss = 749.15686 avg_loss = 2.02087\n",
            "epoch no.18 train no.15080  loss = 571.72943 avg_loss = 1.98558\n",
            "epoch no.18 train no.15090  loss = 780.08685 avg_loss = 1.98146\n",
            "epoch no.18 train no.15100  loss = 922.82587 avg_loss = 1.96535\n",
            "epoch no.18 train no.15110  loss = 856.49969 avg_loss = 1.95973\n",
            "epoch no.18 train no.15120  loss = 701.35748 avg_loss = 1.94648\n",
            "epoch no.18 train no.15130  loss = 753.99023 avg_loss = 1.92841\n",
            "epoch no.18 train no.15140  loss = 1420.98425 avg_loss = 1.91119\n",
            "epoch no.18 train no.15150  loss = 656.00208 avg_loss = 1.89739\n",
            "epoch no.18 train no.15160  loss = 1091.54346 avg_loss = 1.89091\n",
            "epoch no.18 train no.15170  loss = 697.55322 avg_loss = 1.87755\n",
            "epoch no.18 train no.15180  loss = 537.93848 avg_loss = 1.87654\n",
            "epoch no.18 train no.15190  loss = 1766.40503 avg_loss = 1.85879\n",
            "epoch no.18 train no.15200  loss = 760.15637 avg_loss = 1.85769\n",
            "epoch no.18 train no.15210  loss = 639.87396 avg_loss = 1.86535\n",
            "epoch no.18 train no.15220  loss = 974.32495 avg_loss = 1.85550\n",
            "epoch no.18 train no.15230  loss = 581.68616 avg_loss = 1.83949\n",
            "epoch no.18 train no.15240  loss = 758.66406 avg_loss = 1.84756\n",
            "epoch no.18 train no.15250  loss = 1163.95129 avg_loss = 1.85421\n",
            "epoch no.18 train no.15260  loss = 738.70209 avg_loss = 1.84859\n",
            "epoch no.18 train no.15270  loss = 1107.83240 avg_loss = 1.84231\n",
            "epoch no.18 train no.15280  loss = 1976.32568 avg_loss = 1.84012\n",
            "epoch no.18 train no.15290  loss = 673.31287 avg_loss = 1.84226\n",
            "epoch no.18 train no.15300  loss = 735.47437 avg_loss = 1.85676\n",
            "epoch no.18 train no.15310  loss = 712.02344 avg_loss = 1.86239\n",
            "epoch no.18 train no.15320  loss = 789.09253 avg_loss = 1.87246\n",
            "epoch no.18 train no.15330  loss = 769.04248 avg_loss = 1.86996\n",
            "epoch no.18 train no.15340  loss = 689.53998 avg_loss = 1.86347\n",
            "epoch no.18 train no.15350  loss = 682.65228 avg_loss = 1.85587\n",
            "epoch no.18 train no.15360  loss = 1135.75586 avg_loss = 1.84929\n",
            "epoch no.18 train no.15370  loss = 725.05286 avg_loss = 1.85105\n",
            "epoch no.18 train no.15380  loss = 924.35370 avg_loss = 1.85236\n",
            "epoch no.18 train no.15390  loss = 822.49487 avg_loss = 1.85219\n",
            "epoch no.18 train no.15400  loss = 661.39380 avg_loss = 1.85552\n",
            "epoch no.18 train no.15410  loss = 876.42957 avg_loss = 1.85230\n",
            "epoch no.18 train no.15420  loss = 794.42017 avg_loss = 1.84624\n",
            "epoch no.18 train no.15430  loss = 800.35828 avg_loss = 1.85966\n",
            "epoch no.18 train no.15440  loss = 846.34705 avg_loss = 1.86419\n",
            "epoch no.18 train no.15450  loss = 652.27142 avg_loss = 1.87009\n",
            "epoch no.18 train no.15460  loss = 2204.72754 avg_loss = 1.87239\n",
            "epoch no.18 train no.15470  loss = 807.05530 avg_loss = 1.87376\n",
            "epoch no.18 train no.15480  loss = 931.55487 avg_loss = 1.87273\n",
            "epoch no.18 train no.15490  loss = 881.08563 avg_loss = 1.86605\n",
            "epoch no.18 train no.15500  loss = 1142.15674 avg_loss = 1.86148\n",
            "189\n",
            "to_tokens: ['▁[', '▁내', '▁좋아', '를', '▁', '한', '단', '로', '니', '만', '를', '▁', '했', '▁죄', '로', '를', '▁', '한', '▁죄', '▁사랑', '▁', '를', '▁사랑', '프', '했던', '▁안', '▁너', '아', '▁', '▁무', '에', '▁', '▁난', '▁너', '를', '▁사랑', '한', '▁', '를', '▁수', '하게', '▁죄', '이', '▁너', '를', '▁함께', '▁머물', '▁난', '▁사랑', '쁨', '에', '▁생각', '해', '▁수', '도', '▁', '▁너', '를', '▁', '나', '해', '▁너', '▁무', '▁', '▁삶', '▁너', '꿀', '라', '▁말', '아', '도', '래', '▁', '대', '이', '야', '▁', '와', '이', '야', '▁여', '린', '▁바람', '▁사랑', '이', '▁너', '▁하나', '이', '야', '▁여', '울', '이', '야', '▁', '와', '만', '이', '야', '▁여', '를', '▁나', '라면', '▁부', '러', '▁행복', '를', '이', '야', '▁너', '린', '이', '야', '▁내', '▁사랑', '이', '대', '엇', '이', '도', '▁바', '를', '▁사랑', '해', '니까', '▁너', '도', '▁모르', '는', '▁여', '를', '▁사랑', '하', '▁너', '를', '만', '이', '야', '▁너', '▁사랑', '이', '▁너', '▁하나', '▁나', '▁내', '▁삶', '이', '▁있어', '▁하나', '▁나와', '▁함께', '▁사랑', '데', '지', '를', '도', '▁나', '의', '▁운명', '▁너', '를', '이', '야', '</s>']\n",
            "너라면 너를 사랑한 죄 로 너를 사랑한 죄 너를\n",
            "\n",
            "사랑한 죄로 너를\n",
            "\n",
            "아파도 난 괜찮아 그 뒤에있어 난 너를 사랑해\n",
            "\n",
            "부를 행복한 삶이너와 함께 하자그 기쁨이라생각 할 때도 난 너를 너무 사랑해 그걸 내겐 바랄라 놓아줄래그뿐이라면\n",
            "\n",
            "너 뿐이야여린 내 사랑은 너 뿐이야 여울이야너 하나뿐이야 너와 함께라면 부디 너뿐이야 여인이여 내 사랑 그 무엇과도 너를 사랑하니까 아무도 모르는 너를 사랑해 너 하나뿐이야 내 삶이 너와는 내 삶이 너도 우리를 만난 건너 하나로는 나의 사랑 너뿐이야</s>\n",
            "epoch no.18 train no.15510  loss = 1049.59839 avg_loss = 1.85948\n",
            "epoch no.18 train no.15520  loss = 740.19739 avg_loss = 1.84570\n",
            "epoch no.18 train no.15530  loss = 733.89825 avg_loss = 1.85538\n",
            "epoch no.18 train no.15540  loss = 1201.33325 avg_loss = 1.86990\n",
            "epoch no.18 train no.15550  loss = 1029.60840 avg_loss = 1.88857\n",
            "epoch no.18 train no.15560  loss = 825.84839 avg_loss = 1.90397\n",
            "epoch no.18 train no.15570  loss = 648.76758 avg_loss = 1.90319\n",
            "epoch no.18 train no.15580  loss = 703.25623 avg_loss = 1.89255\n",
            "epoch no.18 train no.15590  loss = 600.16150 avg_loss = 1.89155\n",
            "epoch no.18 train no.15600  loss = 1179.43054 avg_loss = 1.89928\n",
            "epoch no.18 train no.15610  loss = 865.21399 avg_loss = 1.89255\n",
            "epoch no.18 train no.15620  loss = 754.67401 avg_loss = 1.89027\n",
            "epoch no.18 train no.15630  loss = 785.01404 avg_loss = 1.89321\n",
            "epoch no.18 train no.15640  loss = 527.97021 avg_loss = 1.89036\n",
            "epoch no.18 train no.15650  loss = 956.16571 avg_loss = 1.91922\n",
            "epoch no.18 train no.15660  loss = 759.97827 avg_loss = 1.92352\n",
            "epoch no.18 train no.15670  loss = 990.15222 avg_loss = 1.91941\n",
            "epoch no.18 train no.15680  loss = 809.73053 avg_loss = 1.90256\n",
            "epoch no.18 train no.15690  loss = 1706.27039 avg_loss = 1.88953\n",
            "epoch no.18 train no.15700  loss = 842.43726 avg_loss = 1.89626\n",
            "epoch no.18 train no.15710  loss = 604.26794 avg_loss = 1.88452\n",
            "epoch no.18 train no.15720  loss = 682.37445 avg_loss = 1.88338\n",
            "epoch no.18 train no.15730  loss = 881.32294 avg_loss = 1.88973\n",
            "epoch no.18 train no.15740  loss = 876.20422 avg_loss = 1.89290\n",
            "epoch no.18 train no.15750  loss = 701.07837 avg_loss = 1.88609\n",
            "epoch no.18 train no.15760  loss = 1767.96179 avg_loss = 1.90194\n",
            "epoch no.18 train no.15770  loss = 1153.73145 avg_loss = 1.91102\n",
            "epoch no.18 train no.15780  loss = 585.32373 avg_loss = 1.89602\n",
            "epoch no.18 train no.15790  loss = 594.21283 avg_loss = 1.89143\n",
            "epoch no.18 train no.15800  loss = 812.73248 avg_loss = 1.88931\n",
            "epoch no.18 train no.15810  loss = 781.05542 avg_loss = 1.88885\n",
            "epoch no.18 train no.15820  loss = 613.52612 avg_loss = 1.88513\n",
            "epoch no.18 train no.15830  loss = 891.35419 avg_loss = 1.88528\n",
            "epoch no.18 train no.15840  loss = 552.66241 avg_loss = 1.88617\n",
            "epoch no.18 train no.15850  loss = 925.08124 avg_loss = 1.89087\n",
            "epoch no.18 train no.15860  loss = 830.81396 avg_loss = 1.89513\n",
            "epoch no.18 train no.15870  loss = 813.22375 avg_loss = 1.90536\n",
            "epoch no.18 train no.15880  loss = 830.95935 avg_loss = 1.91130\n",
            "epoch no.18 train no.15890  loss = 658.79688 avg_loss = 1.90666\n",
            "epoch no.18 train no.15900  loss = 767.48792 avg_loss = 1.90739\n",
            "epoch no.19 train no.15910  loss = 599.25024 avg_loss = 1.89097\n",
            "epoch no.19 train no.15920  loss = 650.39337 avg_loss = 1.87425\n",
            "epoch no.19 train no.15930  loss = 670.27802 avg_loss = 1.87209\n",
            "epoch no.19 train no.15940  loss = 609.69385 avg_loss = 1.85615\n",
            "epoch no.19 train no.15950  loss = 777.54114 avg_loss = 1.83659\n",
            "epoch no.19 train no.15960  loss = 759.13464 avg_loss = 1.82327\n",
            "epoch no.19 train no.15970  loss = 760.06921 avg_loss = 1.81758\n",
            "epoch no.19 train no.15980  loss = 565.45514 avg_loss = 1.80457\n",
            "epoch no.19 train no.15990  loss = 1187.33020 avg_loss = 1.80901\n",
            "epoch no.19 train no.16000  loss = 656.48053 avg_loss = 1.80769\n",
            "489\n",
            "to_tokens: ['▁[', '▁왜', '▁', '는', '▁나', '길', '에', '파', '▁', '▁', '이', '▁삼', '켜', '내', '지만', '▁', '봐', '도', '▁', '쳐', '▁불러', '도', '▁', '만', '▁이름', '이', '에', '▁', '▁내', '▁이', '▁', '▁눈', '에', '▁', '▁새', '인', '한', '▁', '별', '에', '▁말', '워', '고', '▁불러', '도', '▁그', '▁', '아', '▁그', '가', '▁', '▁', '나', '▁나', '를', '▁사랑', '해', '▁가슴', '아', '▁', '게', '아', '데', '▁봐', '도', '▁', '잖', '▁', '의', '▁', '픈', '▁노래', '▁', '아', '▁', '▁', '워', '서', '▁', '만', '▁', '▁그리', '어', '도', '▁', '해', '▁가슴', '해', '▁가슴', '해', '▁가슴', '▁', '▁못하고', '했', '에', '▁', '하고', '▁말', '▁나', '하', '▁말', '▁못하는', '직', '떡', '해야', '▁가슴', '이', '▁', '속', '에', '▁새', '고', '▁너', '를', '을', '▁바라', '워', '▁했', '속', '에', '▁새', '서', '▁', '를', '▁살아', '고', '▁살아', '▁하루', '를', '▁살아', '아', '도', '▁못하는', '▁가슴', '에', '▁', '는데', '▁있는데', '이', '▁새', '도록', '▁', '워', '서', '서', '이다', '서', '▁울', '게', '로', '도', '워', '▁말', '▁사랑', '해', '▁사랑', '를', '▁못', '나', '▁하루', '나', '는데', '봐', '도', '떡', '해', '▁너', '▁', '▁못하는', '▁그', '대', '▁사랑', '▁', '▁네', '이', '만', '▁', '만', '▁자', '를', '▁못', '▁', '니까', '▁안', '▁가슴', '에', '▁새', '겨', '서', '▁너', '해', '▁가슴', '에', '▁새', '라도', '▁', '어', '▁너무', '▁', '하게', '룰', '▁살아', '도', '▁그', '서', '워', '▁죽', '를', '▁그', '잊', '만', '▁', '한', '▁말', '아', '서', '도', '▁', '대', '라', '서', '▁내', '▁가슴', '에', '▁', '질', '까', '▁못', '▁', '를', '▁못', '나', '룰', '▁살아', '도', '에', '▁새', '는데', '서', '▁너', '를', '▁', '어', '나', '▁사랑', '방', '겨', '▁말', '▁', '에', '▁죽', '▁가슴', '널', '에', '▁가득', '▁', '▁사랑', '에', '▁', '▁', '룰', '▁살아', '서', '▁사랑', '해', '요', '▁그', '견', '고', '▁안', '잊', '▁', '녕', '▁그', '▁가슴', '잊', '에', '▁새', '겨', '도', '</s>', '이', '▁그', '해', '요', '▁그', '는데', '▁그', '만', '▁새', '겨', '▁', '는데', '▁어', '직', '▁그', '▁너무', '▁하루', '대', '만', '▁', '파', '도', '▁사랑', '해', '▁어', '▁아', '대', '▁못', '는데', '▁사랑', '만', '▁가득', '해', '▁숨', '을', '를', '▁사랑', '▁쉬', '운', '▁또', '에', '▁가득', '를', '▁', '내', '도', '▁싶은', '▁', '직', '▁그', '대', '만', '▁', '는데', '▁하루', '▁', '게', '▁못', '나', '널', '▁그', '해', '</s>', '▁그', '꾸', '만', '대', '만', '서', '이', '도', '▁못', '▁숨', '에', '▁', '▁아', '파', '▁말', '▁못', '▁사랑', '움', '에', '▁', '는데', '서', '▁그', '▁', '어', '▁안', '대', '만', '서', '▁사랑', '해', '요', '▁그', '▁가슴', '에', '▁', '도', '▁사랑', '해', '▁어', '이', '▁', '켜', '서', '▁그', '도', '▁사랑', '니까', '▁못', '고', '▁그', '워', '도', '▁못', '해', '요', '▁사랑', '워', '▁그', '아', '를', '▁', '▁', '잊', '고', '▁', '아', '▁', '해', '요', '▁내']\n",
            "너라면너는 이 가슴 아파서\n",
            "\n",
            "눈물도 삼켜보려 해봐도\n",
            "\n",
            "소리쳐 불러도 너의 이름 가슴에 남아서 내 두눈에\n",
            "\n",
            "가득찬란한 이별을 지우고 불러도 내 사랑아 떠나가네 언제라도 너를 사랑해 가슴아 내 게 아닌가봐늘 기다리는 나의 슬픈 말 사랑해 늘\n",
            "\n",
            "그리워서\n",
            "\n",
            "너를\n",
            "\n",
            "또 울어도사랑해 사랑해 사랑해늘 말 못가득말 못하는 말못난 말오 어떡해 눈물로 가슴속에 오직 너만을 그리워 가슴속에\n",
            "\n",
            "담아서하루를안고서 하루를 보아 말 못하고가슴이\n",
            "\n",
            "뛰고 눈물이 나도록\n",
            "\n",
            "그리워 서성러도\n",
            "\n",
            "내 일로태우는 말 사랑해 하루도 못가고 기다리나봐 어떡해 내\n",
            "\n",
            "말은 그 말 못하면 숨소리만 너만하루를 못 꾸는데 내 가슴에 새겨서 사랑해 가슴에 하루를 태워도 못 하룰 불러도 못해 그리는데 하루도 못하나만가득한 사람아 흘러도 그대라서 내 가슴이터질까만하루를 못 하룰살아가에 새겨서 하루를 울어 너무 한 숨이 다가는데 내맘에 가득 해서 가슴이\n",
            "\n",
            "다 하룰 살아요 사랑해요 못\n",
            "\n",
            "쉬는데 못도록 안녕 내 맘에새겨요 숨도사랑해도 오직 하나에 새도록 새는데 오직여에 그대만아파도 사랑해 너무 그댈\n",
            "\n",
            "새는데 하루에 가득 한 번 하루도 못 쉬고 나에하루를 밀어내고 또 오직 그대만보는데못 살고 못 도 사랑해요 자꾸 그대라 숨겨도\n",
            "\n",
            "내 가슴이 너무 아픈 말만 그리움에 새겨서 내\n",
            "\n",
            "품고 그대라서 사랑해요 내 가슴에 하루도 사랑해 눈물이삼켜서 하루도 모르고 안녕 그리워도사랑해요 그리운 사람 나를 못 잊을말만 사랑해요</s>\n",
            "epoch no.19 train no.16010  loss = 795.09698 avg_loss = 1.80264\n",
            "epoch no.19 train no.16020  loss = 757.50885 avg_loss = 1.80000\n",
            "epoch no.19 train no.16030  loss = 714.68866 avg_loss = 1.78605\n",
            "epoch no.19 train no.16040  loss = 765.62329 avg_loss = 1.78294\n",
            "epoch no.19 train no.16050  loss = 861.49261 avg_loss = 1.77854\n",
            "epoch no.19 train no.16060  loss = 1520.33472 avg_loss = 1.77206\n",
            "epoch no.19 train no.16070  loss = 895.65698 avg_loss = 1.75859\n",
            "epoch no.19 train no.16080  loss = 710.03546 avg_loss = 1.75229\n",
            "epoch no.19 train no.16090  loss = 590.73389 avg_loss = 1.74717\n",
            "epoch no.19 train no.16100  loss = 795.11798 avg_loss = 1.75287\n",
            "epoch no.19 train no.16110  loss = 870.61200 avg_loss = 1.76189\n",
            "epoch no.19 train no.16120  loss = 738.21466 avg_loss = 1.76096\n",
            "epoch no.19 train no.16130  loss = 637.46283 avg_loss = 1.75402\n",
            "epoch no.19 train no.16140  loss = 703.39557 avg_loss = 1.75419\n",
            "epoch no.19 train no.16150  loss = 816.69128 avg_loss = 1.75126\n",
            "epoch no.19 train no.16160  loss = 631.28876 avg_loss = 1.74791\n",
            "epoch no.19 train no.16170  loss = 703.78705 avg_loss = 1.75016\n",
            "epoch no.19 train no.16180  loss = 727.66705 avg_loss = 1.74579\n",
            "epoch no.19 train no.16190  loss = 768.67340 avg_loss = 1.73848\n",
            "epoch no.19 train no.16200  loss = 1649.56689 avg_loss = 1.74229\n",
            "epoch no.19 train no.16210  loss = 641.15393 avg_loss = 1.75058\n",
            "epoch no.19 train no.16220  loss = 1163.62341 avg_loss = 1.76265\n",
            "epoch no.19 train no.16230  loss = 736.96307 avg_loss = 1.78093\n",
            "epoch no.19 train no.16240  loss = 736.05579 avg_loss = 1.77975\n",
            "epoch no.19 train no.16250  loss = 957.64734 avg_loss = 1.77182\n",
            "epoch no.19 train no.16260  loss = 803.14130 avg_loss = 1.79234\n",
            "epoch no.19 train no.16270  loss = 548.79004 avg_loss = 1.79728\n",
            "epoch no.19 train no.16280  loss = 683.57465 avg_loss = 1.79340\n",
            "epoch no.19 train no.16290  loss = 1851.46765 avg_loss = 1.80184\n",
            "epoch no.19 train no.16300  loss = 684.52112 avg_loss = 1.79875\n",
            "epoch no.19 train no.16310  loss = 800.27301 avg_loss = 1.80099\n",
            "epoch no.19 train no.16320  loss = 634.76953 avg_loss = 1.80625\n",
            "epoch no.19 train no.16330  loss = 1125.21680 avg_loss = 1.81135\n",
            "epoch no.19 train no.16340  loss = 1217.02576 avg_loss = 1.80502\n",
            "epoch no.19 train no.16350  loss = 983.15515 avg_loss = 1.80147\n",
            "epoch no.19 train no.16360  loss = 903.78680 avg_loss = 1.78906\n",
            "epoch no.19 train no.16370  loss = 752.96509 avg_loss = 1.79317\n",
            "epoch no.19 train no.16380  loss = 547.17920 avg_loss = 1.78751\n",
            "epoch no.19 train no.16390  loss = 612.17310 avg_loss = 1.77379\n",
            "epoch no.19 train no.16400  loss = 662.99445 avg_loss = 1.78651\n",
            "epoch no.19 train no.16410  loss = 995.71698 avg_loss = 1.76900\n",
            "epoch no.19 train no.16420  loss = 926.83643 avg_loss = 1.77859\n",
            "epoch no.19 train no.16430  loss = 845.14606 avg_loss = 1.79180\n",
            "epoch no.19 train no.16440  loss = 672.15161 avg_loss = 1.78948\n",
            "epoch no.19 train no.16450  loss = 659.33514 avg_loss = 1.79330\n",
            "epoch no.19 train no.16460  loss = 1039.71887 avg_loss = 1.79592\n",
            "epoch no.19 train no.16470  loss = 776.81866 avg_loss = 1.80202\n",
            "epoch no.19 train no.16480  loss = 649.83423 avg_loss = 1.79887\n",
            "epoch no.19 train no.16490  loss = 1124.13843 avg_loss = 1.79812\n",
            "epoch no.19 train no.16500  loss = 1850.38086 avg_loss = 1.81065\n",
            "273\n",
            "to_tokens: ['▁[', '▁내', '▁너', '는', '은', '야', '▁', '▁', '게', '▁이', '러', '니', '▁', '▁버', '이', '▁', '▁', '▁내', '를', '▁', '리지', '▁하지', '마', '▁그런', '발', '▁나', '의', '▁알고', '를', '▁버', '▁웃', '나', '▁그렇게', '▁', '▁', '러', '지', '마', '▁그런', '▁거', '라고', '▁나', '의', '▁버', '려', '둬', '▁너', '만', '▁사랑', '를', '▁', '한다', '▁안', '만', '을', '▁위해', '▁난', '▁괜찮', '나', '▁', '▁내', '만', '▁사랑', '봐', '▁', '를', '을', '보', '게', '▁', '나', '▁', '▁', '은', '▁언제', '뿐', '만', '인', '니', '▁그렇게', '▁세상', '▁', '을', '▁', '한다', '▁', '해', '▁', '해', '▁너', '▁', '▁', '[UNK]', '에서', '▁나', '어', '▁있', '잖', '▁', '만', '을', '▁위해', '해', '▁', '이', '▁', '울', '▁', '잖', '아', '▁', '만', '을', '보', '게', '▁', '젠', '▁내가', '▁지켜', '를', '을', '▁', '▁웃', '▁지', '▁울', '▁흘리', '며', '▁', '원', '히', '▁', '퍼', '만', '이', '걸', '▁알아', '도', '해', '▁사랑', '▁좋아', '▁사랑', '젠', '이', '건', '로', '는', '만', '인', '걸', '▁', '해', '▁사랑', '해', '▁', '해', '▁너', '만', '을', '▁사랑', '해', '▁사랑', '사랑', '▁내', '사랑', '▁내', '사랑', '▁그', '는', '▁너', '까지', '▁', '만', '을', '니까', '▁행복', '해', '▁내', '만', '▁약속', '▁너', '만', '▁사랑', '▁', '해', '▁사랑', '해', '▁사랑', '원', '히', '▁사랑', '만', '을', '▁', '사랑', '해', '원', '히', '▁사랑', '해', '▁사랑', '사랑', '</s>', '▁사랑', '해', '▁사랑', '만', '을', '해', '▁사랑']\n",
            "너라면 더 이상 거니 왜 내게 이러니날 사랑이니늘 나를울게 하지마 제발 너도 나를위해 언제나\n",
            "\n",
            "내게\n",
            "\n",
            "이러지마\n",
            "\n",
            "그런 거라면 나를 버려둬 너도 나를사랑하면 너만을 위해서라면 언제나 늘\n",
            "\n",
            "나를 바라봐 너만 바라볼게\n",
            "\n",
            "언제나\n",
            "\n",
            "내 사랑은 너 하나뿐이니 이대로\n",
            "\n",
            "만을 사랑해\n",
            "\n",
            "사랑해\n",
            "\n",
            "사랑해 늘\n",
            "\n",
            "내\n",
            "\n",
            "곁에서웃고있어너만을 사랑해 사랑이\n",
            "\n",
            "지쳐 있잖아너만 바라볼게 이젠 내가 너만을 위해\n",
            "\n",
            "다신 눈물 흘리니영원히슬픔 뿐인걸알아 사랑해도 좋아 이별이란 말로움 뿐인걸 사랑해 사랑해 사랑해 너만을사랑해 내사랑 내사랑 내사랑 이제는 언제나\n",
            "\n",
            "너만이야 사랑해 너만을 너만을사랑해 사랑해 영원히너만을 내사랑 영원토록사랑해 내사랑해 사랑해 너만 약속해</s>\n",
            "epoch no.19 train no.16510  loss = 699.79413 avg_loss = 1.80214\n",
            "epoch no.19 train no.16520  loss = 743.51489 avg_loss = 1.80787\n",
            "epoch no.19 train no.16530  loss = 1762.34570 avg_loss = 1.80267\n",
            "epoch no.19 train no.16540  loss = 1114.10291 avg_loss = 1.79693\n",
            "epoch no.19 train no.16550  loss = 1180.89270 avg_loss = 1.78795\n",
            "epoch no.19 train no.16560  loss = 717.61865 avg_loss = 1.78968\n",
            "epoch no.19 train no.16570  loss = 1116.23840 avg_loss = 1.79087\n",
            "epoch no.19 train no.16580  loss = 932.78387 avg_loss = 1.78317\n",
            "epoch no.19 train no.16590  loss = 674.13708 avg_loss = 1.77947\n",
            "epoch no.19 train no.16600  loss = 735.32538 avg_loss = 1.77066\n",
            "epoch no.19 train no.16610  loss = 713.39105 avg_loss = 1.77961\n",
            "epoch no.19 train no.16620  loss = 808.20819 avg_loss = 1.78023\n",
            "epoch no.19 train no.16630  loss = 936.13300 avg_loss = 1.77511\n",
            "epoch no.19 train no.16640  loss = 805.61407 avg_loss = 1.76414\n",
            "epoch no.19 train no.16650  loss = 734.78955 avg_loss = 1.75966\n",
            "epoch no.19 train no.16660  loss = 858.55072 avg_loss = 1.75711\n",
            "epoch no.19 train no.16670  loss = 483.45538 avg_loss = 1.75777\n",
            "epoch no.19 train no.16680  loss = 667.44092 avg_loss = 1.75971\n",
            "epoch no.19 train no.16690  loss = 917.65607 avg_loss = 1.76563\n",
            "epoch no.19 train no.16700  loss = 1129.43872 avg_loss = 1.77550\n",
            "epoch no.19 train no.16710  loss = 666.39148 avg_loss = 1.78181\n",
            "epoch no.19 train no.16720  loss = 1161.48694 avg_loss = 1.77901\n",
            "epoch no.19 train no.16730  loss = 1219.43591 avg_loss = 1.79685\n",
            "epoch no.20 train no.16740  loss = 609.57178 avg_loss = 1.80486\n",
            "epoch no.20 train no.16750  loss = 1222.67810 avg_loss = 1.78991\n",
            "epoch no.20 train no.16760  loss = 612.13525 avg_loss = 1.76400\n",
            "epoch no.20 train no.16770  loss = 468.61868 avg_loss = 1.74958\n",
            "epoch no.20 train no.16780  loss = 600.31818 avg_loss = 1.74401\n",
            "epoch no.20 train no.16790  loss = 921.19067 avg_loss = 1.72572\n",
            "epoch no.20 train no.16800  loss = 660.53656 avg_loss = 1.71313\n",
            "epoch no.20 train no.16810  loss = 746.32458 avg_loss = 1.72025\n",
            "epoch no.20 train no.16820  loss = 767.29816 avg_loss = 1.70919\n",
            "epoch no.20 train no.16830  loss = 692.60822 avg_loss = 1.71036\n",
            "epoch no.20 train no.16840  loss = 671.75366 avg_loss = 1.70398\n",
            "epoch no.20 train no.16850  loss = 693.84827 avg_loss = 1.69830\n",
            "epoch no.20 train no.16860  loss = 670.09357 avg_loss = 1.69648\n",
            "epoch no.20 train no.16870  loss = 703.34564 avg_loss = 1.69285\n",
            "epoch no.20 train no.16880  loss = 615.61432 avg_loss = 1.69403\n",
            "epoch no.20 train no.16890  loss = 754.00000 avg_loss = 1.69592\n",
            "epoch no.20 train no.16900  loss = 513.46686 avg_loss = 1.68444\n",
            "epoch no.20 train no.16910  loss = 794.60797 avg_loss = 1.68193\n",
            "epoch no.20 train no.16920  loss = 603.59290 avg_loss = 1.67149\n",
            "epoch no.20 train no.16930  loss = 518.78210 avg_loss = 1.66029\n",
            "epoch no.20 train no.16940  loss = 661.13989 avg_loss = 1.66669\n",
            "epoch no.20 train no.16950  loss = 472.91827 avg_loss = 1.66007\n",
            "epoch no.20 train no.16960  loss = 718.57178 avg_loss = 1.66693\n",
            "epoch no.20 train no.16970  loss = 714.28998 avg_loss = 1.66572\n",
            "epoch no.20 train no.16980  loss = 673.00385 avg_loss = 1.66901\n",
            "epoch no.20 train no.16990  loss = 826.83386 avg_loss = 1.67586\n",
            "epoch no.20 train no.17000  loss = 575.78894 avg_loss = 1.67197\n",
            "289\n",
            "to_tokens: ['▁[', '▁지금', '▁할', '는', '▁사', '곁', '▁그런', '별', '▁날', '걸', '▁끝', '냐', '▁날', '▁', '▁', '넌', '▁내', '란', '라면', '월', '이', '▁흘러', '면', '▁', '의', '▁사랑', '이', '잊', '빛', '▁추억', '이', '▁이', '별', '▁나', '프', '▁미소', '은', '도', '리지', '마', '▁슬', '울', '버', '고', '▁', '지도', '만', '소', '는데', '까', '▁기억', '은', '▁너', '를', '▁모르', '의', '▁', '▁', '의', '▁아', '픈', '▁눈물', '도', '▁모두', '다', '▁', '워', '버', '면', '▁', '를', '▁사랑', '해서', '단', '▁그', '▁날', '들', '▁이', '▁떠', '게', '▁했던', '▁기억', '▁마음', '▁아', '날', '던', '▁다시', '럴', '▁남은', '이', '▁걸', '▁너', '▁할', '▁건', '▁이제', '면', '▁그렇게', '질', '게', '도', '▁감', '써', '▁참', '▁난', '이', '▁흘러', '까', '▁너', '를', '▁보내', '했던', '▁너', '를', '▁사랑', '망', '할', '겠', '어', '.', '했', '▁이', '</s>', '도', '▁사랑', '은', '▁', '▁세상', '▁다시', '▁나', '▁볼', '게', '도', '▁사랑', '를', '▁사랑', '하고', '어', '▁사랑', '원', '히', '▁할', '우', '▁수', '니', '▁너', '파', '서', '었던', '▁슬', '를', '▁사랑', '▁보내', '▁', '도', '▁모두', '를', '▁떠나', '가', '도', '▁괜찮', '를', '▁', '해', '▁너', '를', '▁더', '해', '▁너', '를', '▁함께', '▁했던', '만큼', '간', '도', '▁나', '를', '▁사랑', '가', '테', '니', '▁너', '▁날', '▁누구', '▁사랑', '날', '거', '야', '▁너', '줘', '를', '▁사랑', '가', '▁사랑', '▁괜찮', '를', '▁사랑', '했', '</s>', '를', '▁사랑', '가', '는', '▁내', '파', '게', '▁할', '거', '야', '▁너', '을', '볼', '다', '려', '야', '고', '▁정말', '▁', '가', '▁너', '▁사랑', '아', '▁너', '낼', '▁오', '해', '▁시간', '▁마음', '▁할', '와', '▁', '와', '▁사랑', '했', '으니', '▁너', '▁사랑', '해', '으니', '▁나', '겐', '속', '▁없', '▁이상', '와', '▁떠나', '가', '▁나', '해', '▁너', '▁너', '순', '▁없어', '겠', '걸', '▁알', '▁너', '와', '▁', '망', '치', '으니', '▁너', '게', '▁더', '이상', '▁내', '인', '▁걸', '로', '는', '▁영', '원', '해', '▁너']\n",
            "너라면 너는 내게 이젠 모든 게 아냐.. ...달이 세월이 지나면 우리의 사랑 은한 사랑도 이젠 슬픈 추억도 흔들리지 마지워버리고\n",
            "\n",
            "보내야 만드릴 그것은 너도 나의 사랑 나에게는 아픈 상처들 모두다 지워버리고 너를 사랑했었던많은 날들이 날 울게 하지만 내게 떠났지만그게 사랑인가야 하는 걸 알면서도모질게 눈물을 애써도 눈물이 날 만큼 너를 사랑하고 너를 원망하겠어 사랑하고 있어 나의 사랑아 이젠 더 이상 그 누구도 너를 사랑했어 영원히 지울테니 아파 했어 너를 떠나간 사랑마저 나를떠나가도 너를사랑해너를사랑해너와 함께 한순간도 나를 떠나갈테니 그만큼 그를 떠날거야해 너를 떠나도 나는 너를 사랑해 너를 떠나가는 아프게 할거야만 바라본 데려두는 날 떠나가도 괜찮아 끝이사랑했던 내게 돌아와 너를 사랑했어도 사랑했었던 내 마음이 더 너를 떠나갈 사랑해줘 한 적 없인 걸 알아 너를 원망 했었던 내겐 더는없인걸 이제는 영원해</s>\n",
            "epoch no.20 train no.17010  loss = 1067.76697 avg_loss = 1.66866\n",
            "epoch no.20 train no.17020  loss = 1710.76648 avg_loss = 1.66354\n",
            "epoch no.20 train no.17030  loss = 630.18231 avg_loss = 1.66427\n",
            "epoch no.20 train no.17040  loss = 1769.33423 avg_loss = 1.66567\n",
            "epoch no.20 train no.17050  loss = 725.98865 avg_loss = 1.67390\n",
            "epoch no.20 train no.17060  loss = 691.76532 avg_loss = 1.67001\n",
            "epoch no.20 train no.17070  loss = 792.47205 avg_loss = 1.67357\n",
            "epoch no.20 train no.17080  loss = 622.10156 avg_loss = 1.68360\n",
            "epoch no.20 train no.17090  loss = 628.21869 avg_loss = 1.68226\n",
            "epoch no.20 train no.17100  loss = 637.71649 avg_loss = 1.68351\n",
            "epoch no.20 train no.17110  loss = 933.62024 avg_loss = 1.69412\n",
            "epoch no.20 train no.17120  loss = 520.95514 avg_loss = 1.68811\n",
            "epoch no.20 train no.17130  loss = 818.05823 avg_loss = 1.70732\n",
            "epoch no.20 train no.17140  loss = 545.69464 avg_loss = 1.68518\n",
            "epoch no.20 train no.17150  loss = 784.51245 avg_loss = 1.68633\n",
            "epoch no.20 train no.17160  loss = 1110.44629 avg_loss = 1.69301\n",
            "epoch no.20 train no.17170  loss = 532.30573 avg_loss = 1.68453\n",
            "epoch no.20 train no.17180  loss = 627.40784 avg_loss = 1.68062\n",
            "epoch no.20 train no.17190  loss = 592.57660 avg_loss = 1.68672\n",
            "epoch no.20 train no.17200  loss = 814.81598 avg_loss = 1.67995\n",
            "epoch no.20 train no.17210  loss = 769.20947 avg_loss = 1.67713\n",
            "epoch no.20 train no.17220  loss = 782.37897 avg_loss = 1.68003\n",
            "epoch no.20 train no.17230  loss = 537.83655 avg_loss = 1.67127\n",
            "epoch no.20 train no.17240  loss = 1275.26831 avg_loss = 1.67151\n",
            "epoch no.20 train no.17250  loss = 864.73676 avg_loss = 1.67740\n",
            "epoch no.20 train no.17260  loss = 648.31805 avg_loss = 1.68480\n",
            "epoch no.20 train no.17270  loss = 699.71075 avg_loss = 1.69173\n",
            "epoch no.20 train no.17280  loss = 737.46155 avg_loss = 1.68835\n",
            "epoch no.20 train no.17290  loss = 675.62347 avg_loss = 1.69597\n",
            "epoch no.20 train no.17300  loss = 1216.14185 avg_loss = 1.68592\n",
            "epoch no.20 train no.17310  loss = 997.74792 avg_loss = 1.69604\n",
            "epoch no.20 train no.17320  loss = 781.29980 avg_loss = 1.71586\n",
            "epoch no.20 train no.17330  loss = 1232.88293 avg_loss = 1.70217\n",
            "epoch no.20 train no.17340  loss = 1082.98364 avg_loss = 1.70445\n",
            "epoch no.20 train no.17350  loss = 566.27759 avg_loss = 1.71228\n",
            "epoch no.20 train no.17360  loss = 846.40631 avg_loss = 1.70908\n",
            "epoch no.20 train no.17370  loss = 662.93854 avg_loss = 1.70215\n",
            "epoch no.20 train no.17380  loss = 799.95941 avg_loss = 1.69895\n",
            "epoch no.20 train no.17390  loss = 924.20776 avg_loss = 1.68638\n",
            "epoch no.20 train no.17400  loss = 548.90839 avg_loss = 1.67747\n",
            "epoch no.20 train no.17410  loss = 738.03174 avg_loss = 1.67657\n",
            "epoch no.20 train no.17420  loss = 1023.90454 avg_loss = 1.69013\n",
            "epoch no.20 train no.17430  loss = 667.56732 avg_loss = 1.68805\n",
            "epoch no.20 train no.17440  loss = 536.26001 avg_loss = 1.67728\n",
            "epoch no.20 train no.17450  loss = 614.69232 avg_loss = 1.67684\n",
            "epoch no.20 train no.17460  loss = 1124.62488 avg_loss = 1.67141\n",
            "epoch no.20 train no.17470  loss = 641.08612 avg_loss = 1.67536\n",
            "epoch no.20 train no.17480  loss = 966.62842 avg_loss = 1.68032\n",
            "epoch no.20 train no.17490  loss = 453.77008 avg_loss = 1.68006\n",
            "epoch no.20 train no.17500  loss = 658.39734 avg_loss = 1.67737\n",
            "289\n",
            "to_tokens: ['▁[', '▁나', '▁', '를', '▁보내', '했', '▁사랑', '▁비', '▁울', '건', '을', '▁', '별', '▁더', '▁끝', '이', '야', '▁그', '파', '▁사랑', '▁말', '엇', '도', '▁너', '지고', '▁못할', '는', '▁그', '을', '▁너', '▁그', '으려', '▁너', '별', '을', '▁할', '매', '이', '▁있어', '는', '▁잡고', '▁슬', '픔', '에', '▁두', '▁', '야', '▁사랑', '▁무', '인데', '▁그', '▁하나', '▁사랑', '과', '▁너', '▁너', '▁말', '상', '이', '은', '▁아무', '도', '▁모르', '게', '▁사람들', '▁모두', '▁두', '매', '이', '▁나', '엇', '이', '▁진', '▁너', '▁날', '▁사랑', '겨', '놓', '고', '면', '려', '도', '려', '▁다시', '는', '▁그', '녕', '▁안', '수록', '을', '▁아', '▁너', '▁무', '▁해', '▁이', '▁말', '도', '▁할', '마', '▁너', '의', '▁잡', '을', '▁않는', '어', '▁사랑', '는', '▁바람', '▁너', '▁너', '의', '▁이', '도', '▁수', '▁없는', '잖', '아', '▁이', '젠', '이', '▁아', '▁좋은', '프', '잖', '아', '▁이', '별', '이', '▁아', '것', '도', '▁너', '를', '▁위한', '할', '▁누구', '걸', '으로', '▁나', '를', '▁보내', '고', '▁줄', '▁남은', '인데', '▁그', '▁이', '대로', '가', '▁', '짓', '이', '면', '가', '는', '▁날', '▁알아', '▁수', '까지', '▁너', '는', '▁위한', '▁난', '▁할', '▁수', '가', '▁없', '▁이', '별', '▁무', '의', '▁수', '니까', '▁이', '를', '▁위한', '▁이', '별', '이', '면', '▁사랑', '엇', '이', '라면', '▁뿐', '▁날', '이', '면', '-', '▁너', '를', '▁위한', '▁이', '대로', '▁너', '의', '▁마음', '속', '▁슬', '대로', '이', '▁없', '나', '▁너', '가', '는', '잖', '아', '▁', '인', '으니', '▁너', '대로', '이', '▁아', '으니', '아', '▁이', '이', '어', '▁이', '를', '▁위한', '을', '▁수', '▁이', '별', '이', '라면', '▁너', '를', '▁위한', '▁마지막', '한', '에', '겐', '▁너', '를', '▁', '이', '▁끝', '를', '▁위한', '▁수', '▁없', '▁아', '▁나', '▁알고', '별', '이', '라면', '냐', '게', '▁없는', '겐', '▁할', '▁너', '▁가진', '이', '에서', '▁떠나', '▁잡', '을', '▁위한', '▁없', '</s>', '를', '▁나는', '질', '▁않아', '▁이', '일', '마저', '▁더', '</s>']\n",
            "너라면 너를 사랑해 지금도 그 사람을 이젠모두 끝이야 아냐그 무엇도 해지도 모르는 사람을 해잡을 이별을 헤매고 너를 잃은 슬픔도 없는거야 그 사람과 또 다른 사람들처럼만의 속삭임은아무도 모르는 사이가\n",
            "\n",
            "헤매고 무엇이니 정말 날 숨겨두가버려 두번 다시는 안녕 할말이니 그 말을해 아무말도 하지 않는 너를 잡지 않았어 너는 이제는 나에게 말해줄 수 없잖아 이별보다 더 아프잖아 이별이 아닌 누구라도 너를대신 그 어떤 사람처럼 너를 안을 하나 뿐인데 그냥 이대로가 거짓이 떠나가는 걸 느낄때마다너를 위해서 난 할 수가 있어 이젠나일 테니까 너를 위한이별이 없어 무엇이 하나 남은 고통이 오직 너를 위한 이젠 나의 마음과이별은언제까지 가져가 없잖아 끝났어 이별이 없잖아 끝났어 너를 잡을 위해이별이라면 너를 위한 사랑했기에겐 너의 흔적들도 너를 볼 수는 없는 난 이별이 아프게 내겐 없어 내가슴속에서 끝내 잡을 수 있어 너와\n",
            "\n",
            "헤어질 않아 아무것이라면</s>\n",
            "epoch no.20 train no.17510  loss = 1063.99976 avg_loss = 1.67671\n",
            "epoch no.20 train no.17520  loss = 662.74756 avg_loss = 1.67989\n",
            "epoch no.20 train no.17530  loss = 725.20911 avg_loss = 1.67611\n",
            "epoch no.20 train no.17540  loss = 1621.92749 avg_loss = 1.67841\n",
            "epoch no.20 train no.17550  loss = 669.31140 avg_loss = 1.67982\n",
            "epoch no.20 train no.17560  loss = 864.00165 avg_loss = 1.67124\n",
            "epoch no.20 train no.17570  loss = 813.83185 avg_loss = 1.67005\n",
            "epoch no.21 train no.17580  loss = 714.52252 avg_loss = 1.67820\n",
            "epoch no.21 train no.17590  loss = 750.66998 avg_loss = 1.67094\n",
            "epoch no.21 train no.17600  loss = 557.47144 avg_loss = 1.64214\n",
            "epoch no.21 train no.17610  loss = 676.84711 avg_loss = 1.62649\n",
            "epoch no.21 train no.17620  loss = 488.66330 avg_loss = 1.61807\n",
            "epoch no.21 train no.17630  loss = 592.70880 avg_loss = 1.61743\n",
            "epoch no.21 train no.17640  loss = 502.36978 avg_loss = 1.58997\n",
            "epoch no.21 train no.17650  loss = 999.50452 avg_loss = 1.59253\n",
            "epoch no.21 train no.17660  loss = 514.20856 avg_loss = 1.59117\n",
            "epoch no.21 train no.17670  loss = 666.06201 avg_loss = 1.58336\n",
            "epoch no.21 train no.17680  loss = 615.45599 avg_loss = 1.56933\n",
            "epoch no.21 train no.17690  loss = 1089.28748 avg_loss = 1.56769\n",
            "epoch no.21 train no.17700  loss = 521.71497 avg_loss = 1.55313\n",
            "epoch no.21 train no.17710  loss = 2416.42603 avg_loss = 1.56040\n",
            "epoch no.21 train no.17720  loss = 799.89551 avg_loss = 1.56544\n",
            "epoch no.21 train no.17730  loss = 624.40765 avg_loss = 1.55529\n",
            "epoch no.21 train no.17740  loss = 475.00104 avg_loss = 1.54734\n",
            "epoch no.21 train no.17750  loss = 899.53302 avg_loss = 1.54674\n",
            "epoch no.21 train no.17760  loss = 1069.58154 avg_loss = 1.54861\n",
            "epoch no.21 train no.17770  loss = 569.57520 avg_loss = 1.54765\n",
            "epoch no.21 train no.17780  loss = 608.52106 avg_loss = 1.54947\n",
            "epoch no.21 train no.17790  loss = 686.46973 avg_loss = 1.54404\n",
            "epoch no.21 train no.17800  loss = 754.92706 avg_loss = 1.55888\n",
            "epoch no.21 train no.17810  loss = 650.58801 avg_loss = 1.55239\n",
            "epoch no.21 train no.17820  loss = 615.20709 avg_loss = 1.54877\n",
            "epoch no.21 train no.17830  loss = 743.56921 avg_loss = 1.55028\n",
            "epoch no.21 train no.17840  loss = 630.13580 avg_loss = 1.54752\n",
            "epoch no.21 train no.17850  loss = 633.48926 avg_loss = 1.55519\n",
            "epoch no.21 train no.17860  loss = 674.95398 avg_loss = 1.55478\n",
            "epoch no.21 train no.17870  loss = 708.34302 avg_loss = 1.56218\n",
            "epoch no.21 train no.17880  loss = 832.48560 avg_loss = 1.56001\n",
            "epoch no.21 train no.17890  loss = 676.07983 avg_loss = 1.55576\n",
            "epoch no.21 train no.17900  loss = 755.09497 avg_loss = 1.55974\n",
            "epoch no.21 train no.17910  loss = 737.04889 avg_loss = 1.57096\n",
            "epoch no.21 train no.17920  loss = 1223.86011 avg_loss = 1.57740\n",
            "epoch no.21 train no.17930  loss = 929.77643 avg_loss = 1.56756\n",
            "epoch no.21 train no.17940  loss = 578.34204 avg_loss = 1.57156\n",
            "epoch no.21 train no.17950  loss = 557.99408 avg_loss = 1.57384\n",
            "epoch no.21 train no.17960  loss = 904.45459 avg_loss = 1.56834\n",
            "epoch no.21 train no.17970  loss = 755.55670 avg_loss = 1.57390\n",
            "epoch no.21 train no.17980  loss = 588.34485 avg_loss = 1.57463\n",
            "epoch no.21 train no.17990  loss = 725.28217 avg_loss = 1.57883\n",
            "epoch no.21 train no.18000  loss = 785.55835 avg_loss = 1.57580\n",
            "255\n",
            "to_tokens: ['▁[', '▁내', '▁할', '일', '▁너', '는', '▁표정', '을', '▁좋아', '픈', '▁생각', '▁싶어', '▁나는', '의', '▁내', '▁이름', '▁아니', '게', '▁힘', '이', '▁들', '줘', '▁뭐', '의', '▁사랑', '이', '였', '나', '▁', '▁', '쁨', '림', '▁', '다', '▁', '▁나는', '의', '▁위해', '▁마음', '만', '곳', '▁바로', '냐', '지', '▁않아', '▁만큼', '야', '▁', '를', '▁사랑을', '의', '▁', '이', '▁때까지', '▁너', '를', '▁힘들', '▁내가', '쁨', '이', '▁사랑', '주', '고', '니', '▁너', '사랑', '▁사랑', '이', '▁끝', '이', '▁지', '▁기', '▁사랑을', '▁너', '▁너', '를', '▁사랑', '해', '▁만큼', '▁시간', '▁함께', '▁사랑', '은', '기', '▁다시', '▁볼', '수', '야', '▁너', '를', '▁위해', '▁내가', '▁지', '줄', '께', '▁', '의', '▁끝', '로', '▁지', '가', '▁너', '를', '▁위해', '▁울', '지', '▁않을', '께', '▁너', '의', '▁위해', '▁내가', '를', '▁위해', '▁나', '▁울', '가', '를', '▁', '아', '▁너', '를', '▁사랑', '하', '▁수', '▁너', '는', '도', '▁너', '를', '▁이', '이', '▁', '▁너', '▁너', '를', '▁사랑', '줄', '께', '▁너', '의', '▁이', '▁모습을', '▁미소', '하', '어', '▁너', '의', '▁', '▁잡고', '▁', '▁', '▁삶', '의', '▁끝', '가', '▁', '▁너', '▁삶', '이', '▁되어', '▁만큼', '줄', '겠', '▁슬', '픈', '이', '▁언제', '다', '워', '▁날', '▁이제', '▁너', '지', '▁않아', '▁너', '의', '▁삶', '을', '▁', '해', '▁영', '를', '▁삶', '의', '▁삶', '을', '▁', '▁', '어', '▁날', '▁위해', '▁너', '게', '▁', '▁수', '▁있게', '</s>', '줄', '께', '▁너', '의', '▁위해', '▁너', '의', '▁마지막', '부', '이', '▁삶', '로', '▁그', '▁영', '▁사람', '▁지켜', '의', '▁행복', '의', '▁영', '원', '히', '의', '▁삶', '이', '▁때까지', '▁너', '혼', '한', '의', '▁삶', '의', '▁행복', '이', '▁', '▁너', '의', '▁행복', '고', '▁싶어', '를', '▁안', '의', '께', '▁너']\n",
            "너라면 제니 너의 얼굴이 보고 싶어 보고 싶어 너는 그게 내게\n",
            "\n",
            "힘이 되니 우리의 사랑이 언제나 늘 기다려준 시간도 너를 위한 것 그게 아프지 않을 거야 나의 삶이 끝날 때까지 너를 위해 기쁨이\n",
            "\n",
            "되어주겠니 우리의 사랑의 약속을\n",
            "\n",
            "위해 내 사람아 너를 사랑했던 지난 우리의 약속 이젠 다시 만날꺼야 너를 위해 내가 지켜 줄께 삶의 무게이며 살아줘너를 위해 울지는 않을께 너를 위해 너를 위해 내가 살아 너의 사람아 너를 사랑할께 죽어도 너의 삶이\n",
            "\n",
            "살아도 너를지켜줄께너의 그저 사랑했어 너의손을 잡고싶어 내 삶의 무게로 나의 끝이 날 지켜주렴 슬픔은 아름다는걸 난 울지 않아 너의 길을사랑해 너의 삶의 삶을내가 죽는 날 위해 웃게 할 수 있게 해줄께 너를 위해 너의 전 세상의 무게로 인해 소중한 사람 너의 사랑해 영원 너의 끝날 때까지 영원 너의 사랑의 끝날 때까지 너의 길고 너를 사랑할께</s>\n",
            "epoch no.21 train no.18010  loss = 635.16040 avg_loss = 1.57027\n",
            "epoch no.21 train no.18020  loss = 694.52466 avg_loss = 1.57761\n",
            "epoch no.21 train no.18030  loss = 999.11017 avg_loss = 1.57022\n",
            "epoch no.21 train no.18040  loss = 1283.16418 avg_loss = 1.56416\n",
            "epoch no.21 train no.18050  loss = 587.08490 avg_loss = 1.56133\n",
            "epoch no.21 train no.18060  loss = 1507.71472 avg_loss = 1.56453\n",
            "epoch no.21 train no.18070  loss = 569.93213 avg_loss = 1.58309\n",
            "epoch no.21 train no.18080  loss = 1129.83154 avg_loss = 1.58457\n",
            "epoch no.21 train no.18090  loss = 572.96906 avg_loss = 1.58665\n",
            "epoch no.21 train no.18100  loss = 642.86334 avg_loss = 1.59498\n",
            "epoch no.21 train no.18110  loss = 947.42633 avg_loss = 1.58343\n",
            "epoch no.21 train no.18120  loss = 668.01501 avg_loss = 1.59045\n",
            "epoch no.21 train no.18130  loss = 723.02454 avg_loss = 1.58939\n",
            "epoch no.21 train no.18140  loss = 542.10510 avg_loss = 1.59304\n",
            "epoch no.21 train no.18150  loss = 750.10791 avg_loss = 1.61101\n",
            "epoch no.21 train no.18160  loss = 1151.59753 avg_loss = 1.60709\n",
            "epoch no.21 train no.18170  loss = 669.68048 avg_loss = 1.61109\n",
            "epoch no.21 train no.18180  loss = 611.98273 avg_loss = 1.61938\n",
            "epoch no.21 train no.18190  loss = 529.30115 avg_loss = 1.61422\n",
            "epoch no.21 train no.18200  loss = 728.35443 avg_loss = 1.61895\n",
            "epoch no.21 train no.18210  loss = 1746.45459 avg_loss = 1.60901\n",
            "epoch no.21 train no.18220  loss = 760.04681 avg_loss = 1.60007\n",
            "epoch no.21 train no.18230  loss = 563.17267 avg_loss = 1.60240\n",
            "epoch no.21 train no.18240  loss = 1427.24451 avg_loss = 1.59785\n",
            "epoch no.21 train no.18250  loss = 830.95123 avg_loss = 1.58588\n",
            "epoch no.21 train no.18260  loss = 909.30475 avg_loss = 1.58453\n",
            "epoch no.21 train no.18270  loss = 1074.94751 avg_loss = 1.58142\n",
            "epoch no.21 train no.18280  loss = 551.07483 avg_loss = 1.58121\n",
            "epoch no.21 train no.18290  loss = 1773.33081 avg_loss = 1.59998\n",
            "epoch no.21 train no.18300  loss = 520.07739 avg_loss = 1.60155\n",
            "epoch no.21 train no.18310  loss = 621.41211 avg_loss = 1.59796\n",
            "epoch no.21 train no.18320  loss = 682.54810 avg_loss = 1.59515\n",
            "epoch no.21 train no.18330  loss = 1502.12439 avg_loss = 1.60390\n",
            "epoch no.21 train no.18340  loss = 581.70508 avg_loss = 1.60772\n",
            "epoch no.21 train no.18350  loss = 754.59918 avg_loss = 1.60568\n",
            "epoch no.21 train no.18360  loss = 660.92084 avg_loss = 1.59862\n",
            "epoch no.21 train no.18370  loss = 595.28906 avg_loss = 1.59919\n",
            "epoch no.21 train no.18380  loss = 641.02173 avg_loss = 1.59545\n",
            "epoch no.21 train no.18390  loss = 849.06616 avg_loss = 1.59956\n",
            "epoch no.21 train no.18400  loss = 1004.49255 avg_loss = 1.60703\n",
            "epoch no.21 train no.18410  loss = 619.50659 avg_loss = 1.60020\n",
            "epoch no.22 train no.18420  loss = 620.01508 avg_loss = 1.58695\n",
            "epoch no.22 train no.18430  loss = 617.25269 avg_loss = 1.57069\n",
            "epoch no.22 train no.18440  loss = 500.46454 avg_loss = 1.55142\n",
            "epoch no.22 train no.18450  loss = 528.46539 avg_loss = 1.53885\n",
            "epoch no.22 train no.18460  loss = 589.51697 avg_loss = 1.53294\n",
            "epoch no.22 train no.18470  loss = 1052.30237 avg_loss = 1.50935\n",
            "epoch no.22 train no.18480  loss = 1519.44055 avg_loss = 1.50301\n",
            "epoch no.22 train no.18490  loss = 1642.60730 avg_loss = 1.49721\n",
            "epoch no.22 train no.18500  loss = 528.08276 avg_loss = 1.50268\n",
            "187\n",
            "to_tokens: ['▁[', '▁내', '▁난', '▁다', '▁싶은', '은', '▁않은', '다', '니', '하는', '것', '은', '도', '▁', '를', '▁사랑', '쳐', '던', '▁그런', '의', '▁모습', '이', '▁모두', '▁내', '빠', '▁', '리지', '않', '했', '▁', '▁말', '▁너', '도', '▁내', '를', '▁얼굴', '▁', '▁날', '▁', '젠', '면', '▁어', '▁그리', '워', '해', '▁처음', '도', '둘', '픈', '지', '▁내', '를', '▁', '하지', '마', '▁우리', '말', '여', '▁나', '를', '▁', '하지', '마', '도', '▁우리', '▁사람', '봐', '를', '▁말', '앞', '을', '▁서', '러', '워', '서', '▁', '▁너', '게', '▁', '에', '▁나', '▁나', '▁하루', '을', '▁꾸', '며', '▁있어', '서', '면', '않', '아', '▁', '것', '도', '▁너', '▁우리', '을', '▁', '고', '▁잠', '를', '▁', '해', '는', '▁사랑', '▁너', '를', '▁마음', '에', '이', '▁생각해', '볼', '▁우리', '의', '▁바라', '고', '나', '▁그', '것', '보다', '▁사랑', '해', '▁않아', '도', '▁나는', '한', '▁말', '▁말', '▁너', '의', '▁사랑', '해', '▁그렇게', '나', '▁사랑', '▁사랑', '해서', '▁그런', '나', '도', '▁소중한', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁사랑', '해', '▁너', '를', '▁정말', '해', '▁너', '를', '▁사랑', '해', '</s>', '를', '▁사랑', '해', '▁너', '하지', '▁할', '▁수', '▁', '를', '▁정말', '해', '</s>']\n",
            "너라면 꼭 하고싶지않았 사랑한 말투에 너를 넘치던 나의 마음이항상 나를 버리지 못하게 하는 말 너도 너의 모습은 날 이러면 다시 그리워해 이렇게 서글퍼지는 나를\n",
            "\n",
            "생각하지마 그대도 나를사랑하지 않아도 좋은가 너의 집 앞을 서러워서 난네가 생각나나 난 꿈을 꾸고 돌아서지않을 그 누구 보다가눈을감고 너를사랑하지 않게 난 너의 모습만을 바라봐 나를\n",
            "\n",
            "안고서 그 누구도 사랑하지 않아도 사랑이란걸 난 너를사랑했는데 너무나 많이 사랑해서 너무나도 사랑해 너를사랑해 너를 사랑해 너를 사랑해 너를 사랑해 너를 사랑해 말로 할게너를 사랑해</s>\n",
            "epoch no.22 train no.18510  loss = 667.35724 avg_loss = 1.50091\n",
            "epoch no.22 train no.18520  loss = 1077.29468 avg_loss = 1.49711\n",
            "epoch no.22 train no.18530  loss = 609.47748 avg_loss = 1.48679\n",
            "epoch no.22 train no.18540  loss = 571.72314 avg_loss = 1.48271\n",
            "epoch no.22 train no.18550  loss = 652.89716 avg_loss = 1.50034\n",
            "epoch no.22 train no.18560  loss = 779.04602 avg_loss = 1.51320\n",
            "epoch no.22 train no.18570  loss = 575.32666 avg_loss = 1.50751\n",
            "epoch no.22 train no.18580  loss = 721.54291 avg_loss = 1.50166\n",
            "epoch no.22 train no.18590  loss = 743.07312 avg_loss = 1.49432\n",
            "epoch no.22 train no.18600  loss = 539.36169 avg_loss = 1.48132\n",
            "epoch no.22 train no.18610  loss = 413.28699 avg_loss = 1.48378\n",
            "epoch no.22 train no.18620  loss = 509.26251 avg_loss = 1.48165\n",
            "epoch no.22 train no.18630  loss = 545.61285 avg_loss = 1.47437\n",
            "epoch no.22 train no.18640  loss = 471.84467 avg_loss = 1.47647\n",
            "epoch no.22 train no.18650  loss = 623.41882 avg_loss = 1.47426\n",
            "epoch no.22 train no.18660  loss = 495.22534 avg_loss = 1.47985\n",
            "epoch no.22 train no.18670  loss = 561.69519 avg_loss = 1.47059\n",
            "epoch no.22 train no.18680  loss = 607.02893 avg_loss = 1.46599\n",
            "epoch no.22 train no.18690  loss = 872.83789 avg_loss = 1.46676\n",
            "epoch no.22 train no.18700  loss = 827.58191 avg_loss = 1.47051\n",
            "epoch no.22 train no.18710  loss = 572.45380 avg_loss = 1.46443\n",
            "epoch no.22 train no.18720  loss = 528.12671 avg_loss = 1.45889\n",
            "epoch no.22 train no.18730  loss = 633.53802 avg_loss = 1.46468\n",
            "epoch no.22 train no.18740  loss = 682.86621 avg_loss = 1.46967\n",
            "epoch no.22 train no.18750  loss = 761.48071 avg_loss = 1.46820\n",
            "epoch no.22 train no.18760  loss = 682.19183 avg_loss = 1.47334\n",
            "epoch no.22 train no.18770  loss = 937.97430 avg_loss = 1.47319\n",
            "epoch no.22 train no.18780  loss = 1507.16711 avg_loss = 1.47246\n",
            "epoch no.22 train no.18790  loss = 1001.09210 avg_loss = 1.47933\n",
            "epoch no.22 train no.18800  loss = 490.63467 avg_loss = 1.48315\n",
            "epoch no.22 train no.18810  loss = 798.77600 avg_loss = 1.48620\n",
            "epoch no.22 train no.18820  loss = 1194.65198 avg_loss = 1.47874\n",
            "epoch no.22 train no.18830  loss = 925.25287 avg_loss = 1.48310\n",
            "epoch no.22 train no.18840  loss = 554.48657 avg_loss = 1.48350\n",
            "epoch no.22 train no.18850  loss = 780.80518 avg_loss = 1.48656\n",
            "epoch no.22 train no.18860  loss = 928.68652 avg_loss = 1.49273\n",
            "epoch no.22 train no.18870  loss = 557.58191 avg_loss = 1.50173\n",
            "epoch no.22 train no.18880  loss = 548.14508 avg_loss = 1.49138\n",
            "epoch no.22 train no.18890  loss = 601.79999 avg_loss = 1.48262\n",
            "epoch no.22 train no.18900  loss = 634.49677 avg_loss = 1.48141\n",
            "epoch no.22 train no.18910  loss = 530.49805 avg_loss = 1.48048\n",
            "epoch no.22 train no.18920  loss = 690.45685 avg_loss = 1.47471\n",
            "epoch no.22 train no.18930  loss = 647.50543 avg_loss = 1.47574\n",
            "epoch no.22 train no.18940  loss = 555.70624 avg_loss = 1.47971\n",
            "epoch no.22 train no.18950  loss = 782.88629 avg_loss = 1.48009\n",
            "epoch no.22 train no.18960  loss = 975.40570 avg_loss = 1.48406\n",
            "epoch no.22 train no.18970  loss = 488.63129 avg_loss = 1.48945\n",
            "epoch no.22 train no.18980  loss = 580.15320 avg_loss = 1.48470\n",
            "epoch no.22 train no.18990  loss = 592.53448 avg_loss = 1.49618\n",
            "epoch no.22 train no.19000  loss = 638.99744 avg_loss = 1.50864\n",
            "233\n",
            "to_tokens: ['▁[', '▁내', '▁', '라면', '▁보내', '▁만난', '났', '던', '▁때', '▁', '▁이', '눈', '▁눈', '이', '▁', '주', '친', '▁나', '▁그', '▁말', '했', '▁사랑', '부', '▁', '주', '보', '▁때', '도', '▁나', '의', '▁이', '색', '해', '▁보이는', '▁예', '쁜', '▁두', '▁오늘', '▁', '의', '▁그', '색', '▁하', '▁두', '빛', 'E', '▁당', '는', '▁향한', '해', '▁날', '의', '▁모습', '별', '을', '▁아름', '의', '▁마음을', '▁너', '해', '▁', '▁있었', '면', '▁', '▁말', '했', '었', '어', '▁', '의', '▁', '눈', '을', '▁', '픔', '에', '▁잠', '▁있을', '▁때', '도', '대', '▁보여', '▁사람', '의', '▁손', '대', '에', '▁너', '는', '▁너', '의', '▁두', '▁눈', '에', '▁내가', '워', '주', '▁선물', '근', '의', '▁', '냥', '칠', '▁그', '의', '▁그', '결', '▁나', '▁고', '쁜', '▁두', '의', '▁그', '▁두', '▁눈', '▁꼭', '▁잡', '▁', '▁손을', '▁모아', '▁잡', '은', '▁그', '▁순간', '까지', '▁너', '▁', '▁거', '야', '▁', '하는', '▁', '해', '▁사랑', '대가', '와', '▁내가', '의', '▁그', '대', '지', '를', '▁너', '일', '▁말', '했', '어', '▁너무', '대', '여', '의', '▁두', '▁눈에', '▁꼭', '▁내가', '▁', '▁그', '▁걸', '▁주고', '대', '▁아', '▁', '에', '운', '▁때', '엔', '마다', '▁', '원', '에', '▁', '의', '▁두', '▁손을', '▁꼭', '▁잡', '은', '▁그', '의', '▁두', '맞', '에', '▁날', '해']\n",
            "너라면 너를 처음 만났을때 우리 두운 눈이 마주친 느낌으로 말없이 눈을 마주칠 때면너의 어색해 너무 예쁜 선물야 나의 어[UNK] 너를 좋아하던 너의 이별은 나의 마음을 사랑할수 없다면\n",
            "\n",
            "내가 말했었어 너의 두 눈은 슬픔에서 있을 때 그대가 아닌 나의 그 대에로는 너의 두 손에 끼워 주는두 눈이마주친 너의 숨결 너무 예쁜 너의 그\n",
            "\n",
            "두 손을\n",
            "\n",
            "꼭 모아\n",
            "\n",
            "두 손을 꼭 잡던 그날까지 내가될꺼야사랑해 사랑해 그대와나의 그 대가를 보지 못했어 그대 너의 두 손에\n",
            "\n",
            "내가가진 모든 걸 그대가 원하는 힘겨울 때 에\n",
            "\n",
            "영혼에 너의 두 손을 꼭 잡은 나의입술이 좋아</s>\n",
            "epoch no.22 train no.19010  loss = 622.40900 avg_loss = 1.51129\n",
            "epoch no.22 train no.19020  loss = 723.86774 avg_loss = 1.51825\n",
            "epoch no.22 train no.19030  loss = 1618.92456 avg_loss = 1.51873\n",
            "epoch no.22 train no.19040  loss = 492.43387 avg_loss = 1.51903\n",
            "epoch no.22 train no.19050  loss = 833.92126 avg_loss = 1.51417\n",
            "epoch no.22 train no.19060  loss = 868.04279 avg_loss = 1.51379\n",
            "epoch no.22 train no.19070  loss = 561.58478 avg_loss = 1.50308\n",
            "epoch no.22 train no.19080  loss = 663.94598 avg_loss = 1.51547\n",
            "epoch no.22 train no.19090  loss = 665.31360 avg_loss = 1.51055\n",
            "epoch no.22 train no.19100  loss = 638.51147 avg_loss = 1.52174\n",
            "epoch no.22 train no.19110  loss = 660.59583 avg_loss = 1.52589\n",
            "epoch no.22 train no.19120  loss = 518.66626 avg_loss = 1.52953\n",
            "epoch no.22 train no.19130  loss = 659.73132 avg_loss = 1.52554\n",
            "epoch no.22 train no.19140  loss = 819.71210 avg_loss = 1.52553\n",
            "epoch no.22 train no.19150  loss = 1777.92737 avg_loss = 1.53197\n",
            "epoch no.22 train no.19160  loss = 535.30682 avg_loss = 1.52830\n",
            "epoch no.22 train no.19170  loss = 693.04169 avg_loss = 1.54006\n",
            "epoch no.22 train no.19180  loss = 1721.04517 avg_loss = 1.53979\n",
            "epoch no.22 train no.19190  loss = 736.75061 avg_loss = 1.54454\n",
            "epoch no.22 train no.19200  loss = 578.79236 avg_loss = 1.54240\n",
            "epoch no.22 train no.19210  loss = 630.84106 avg_loss = 1.54712\n",
            "epoch no.22 train no.19220  loss = 799.84875 avg_loss = 1.53239\n",
            "epoch no.22 train no.19230  loss = 751.93951 avg_loss = 1.53911\n",
            "epoch no.22 train no.19240  loss = 935.57983 avg_loss = 1.54399\n",
            "epoch no.22 train no.19250  loss = 434.50650 avg_loss = 1.53471\n",
            "epoch no.23 train no.19260  loss = 524.82489 avg_loss = 1.50292\n",
            "epoch no.23 train no.19270  loss = 489.08514 avg_loss = 1.47993\n",
            "epoch no.23 train no.19280  loss = 526.58978 avg_loss = 1.47585\n",
            "epoch no.23 train no.19290  loss = 876.98792 avg_loss = 1.45740\n",
            "epoch no.23 train no.19300  loss = 503.43103 avg_loss = 1.43826\n",
            "epoch no.23 train no.19310  loss = 473.08020 avg_loss = 1.42838\n",
            "epoch no.23 train no.19320  loss = 386.40164 avg_loss = 1.42717\n",
            "epoch no.23 train no.19330  loss = 645.69598 avg_loss = 1.41796\n",
            "epoch no.23 train no.19340  loss = 1177.44568 avg_loss = 1.41597\n",
            "epoch no.23 train no.19350  loss = 568.48090 avg_loss = 1.41536\n",
            "epoch no.23 train no.19360  loss = 586.80255 avg_loss = 1.40700\n",
            "epoch no.23 train no.19370  loss = 559.58380 avg_loss = 1.38910\n",
            "epoch no.23 train no.19380  loss = 623.64484 avg_loss = 1.39278\n",
            "epoch no.23 train no.19390  loss = 416.79510 avg_loss = 1.37981\n",
            "epoch no.23 train no.19400  loss = 591.06891 avg_loss = 1.38717\n",
            "epoch no.23 train no.19410  loss = 878.20532 avg_loss = 1.38344\n",
            "epoch no.23 train no.19420  loss = 811.25708 avg_loss = 1.39061\n",
            "epoch no.23 train no.19430  loss = 535.92822 avg_loss = 1.39229\n",
            "epoch no.23 train no.19440  loss = 834.18701 avg_loss = 1.39614\n",
            "epoch no.23 train no.19450  loss = 553.65863 avg_loss = 1.38679\n",
            "epoch no.23 train no.19460  loss = 579.30554 avg_loss = 1.39331\n",
            "epoch no.23 train no.19470  loss = 513.67175 avg_loss = 1.38346\n",
            "epoch no.23 train no.19480  loss = 745.27295 avg_loss = 1.37615\n",
            "epoch no.23 train no.19490  loss = 617.93860 avg_loss = 1.37881\n",
            "epoch no.23 train no.19500  loss = 420.25095 avg_loss = 1.37352\n",
            "232\n",
            "to_tokens: ['▁[', '▁내', '▁너', '▁', '이', '▁마지막', '▁오늘', '▁내', '▁', '▁사랑', '플', '고', '▁않', '▁', '를', '별', '▁내가', '게', '▁잡아', '줘', '▁오늘', '의', '▁슬', '픈', '▁미소', '만', '▁지', '▁', '는', '▁아', '야', '▁네', '▁', '로', '▁더', '▁깊이', '▁아', '어', '할', '▁', '▁하지만', '도', '▁너', '냥', '야', '▁나는', '▁너', '와', '▁위해', '하는', '지', '같은', '▁아니', '▁', '로', '와', '▁내', '신', '려고', '▁하', '얀', '▁눈', '▁별', '빛', '에', '에', '▁남아', '지는', '▁', '르', '이', '가', '리', '▁', '▁아침', '할', '게', '▁', '의', '▁사랑', '▁뭔가', '를', '▁', '▁', '▁', '▁', '▁너', '▁찾아', '고', '▁', '▁수', '▁있게', '▁것', '의', '▁모습이', '라도', '▁너', '해야', '께', '▁너', '를', '▁사랑', '하는', '▁것', '▁있어', '▁너', '픔', '▁미소', '의', '▁네', '를', '▁울', '▁준비', '▁', '지', '것', '야', '▁', '젠', '▁내가', '▁', '고', '▁수', '▁있게', '니', '▁', '▁행복', '한', '▁이', '▁너', '▁영', '할', '께', '▁있', '▁', '껏', '▁나', '에게', '▁위해', '줄', '마', '▁우리', '▁지켜', '줄', '께', '▁', '는', '만', '▁바로', '야', '▁우리', '▁세상', '▁내가', '하지', '마', '▁내가', '▁언제', '의', '하기', '▁수', '▁', '도', '▁사랑', '다', '한', '단', '▁사랑을', '▁또', '▁사랑을', '▁영', '▁할', '▁그', '▁볼', '▁수', '▁있겠', '지', '▁그', '▁사랑을', '▁할', '꺼', '▁있겠', '▁언제', '게', '▁', '▁너', '고', '▁', '지', '▁', '답', '림', '라도', '▁', '할', '께', '</s>', '를', '▁', '</s>', '이', '▁있어', '돌', '아', '냐', '</s>']\n",
            "너라면 꼭 오늘이라면 마 모두 같이아프지마 나 이젠 내 손을 잡아줘 너의 슬픈 미소를 하지만너는 아니야내게 좀 더 많이 울어야 하고 있어 아직은 마셔봐 나는 너를 사랑하는것은 내게로 다 주려고 하얀 저\n",
            "\n",
            "별빛속에 펼쳐진이밤 차라리간직할께 너를 위해 나의 눈물로 그렇게라도 내가 느끼게 할 수 있는 너의 모습이라면 준비할께\n",
            "\n",
            "너를사랑하는 일이라면 슬픈 우리 사랑을 너를 위해 그냥\n",
            "\n",
            "보내는거야이젠 내가 웃을 수 있니\n",
            "\n",
            "우리 사랑은 이제라도 말할 수 있게 지금껏 너를 보내지마 내가 지켜볼께 이제 그건 아니야\n",
            "\n",
            "이젠 말하지 마세요 우리 사랑할께 아직도 못다한 우리 사랑을 우리 사랑만 이제 다시 만날 수 있겠지\n",
            "\n",
            "우리 함께 할 수 있어 내게 그냥 웃고 떠나는 아름다시는 약속할께 너를 위해 눈물이 되잖아줘</s>\n",
            "epoch no.23 train no.19510  loss = 727.93256 avg_loss = 1.37979\n",
            "epoch no.23 train no.19520  loss = 485.36877 avg_loss = 1.36882\n",
            "epoch no.23 train no.19530  loss = 701.42645 avg_loss = 1.37417\n",
            "epoch no.23 train no.19540  loss = 468.83630 avg_loss = 1.37051\n",
            "epoch no.23 train no.19550  loss = 776.22491 avg_loss = 1.37670\n",
            "epoch no.23 train no.19560  loss = 660.27307 avg_loss = 1.38660\n",
            "epoch no.23 train no.19570  loss = 595.39795 avg_loss = 1.38891\n",
            "epoch no.23 train no.19580  loss = 546.27740 avg_loss = 1.39199\n",
            "epoch no.23 train no.19590  loss = 568.73059 avg_loss = 1.39156\n",
            "epoch no.23 train no.19600  loss = 480.60135 avg_loss = 1.40111\n",
            "epoch no.23 train no.19610  loss = 500.01984 avg_loss = 1.41995\n",
            "epoch no.23 train no.19620  loss = 504.37082 avg_loss = 1.42454\n",
            "epoch no.23 train no.19630  loss = 548.74432 avg_loss = 1.41971\n",
            "epoch no.23 train no.19640  loss = 700.64056 avg_loss = 1.41548\n",
            "epoch no.23 train no.19650  loss = 629.80951 avg_loss = 1.40757\n",
            "epoch no.23 train no.19660  loss = 621.65253 avg_loss = 1.40889\n",
            "epoch no.23 train no.19670  loss = 572.80573 avg_loss = 1.39745\n",
            "epoch no.23 train no.19680  loss = 569.10541 avg_loss = 1.39309\n",
            "epoch no.23 train no.19690  loss = 864.10950 avg_loss = 1.38709\n",
            "epoch no.23 train no.19700  loss = 509.55542 avg_loss = 1.37493\n",
            "epoch no.23 train no.19710  loss = 421.91046 avg_loss = 1.37664\n",
            "epoch no.23 train no.19720  loss = 479.15292 avg_loss = 1.38754\n",
            "epoch no.23 train no.19730  loss = 794.43304 avg_loss = 1.38593\n",
            "epoch no.23 train no.19740  loss = 533.49811 avg_loss = 1.37893\n",
            "epoch no.23 train no.19750  loss = 583.51904 avg_loss = 1.38461\n",
            "epoch no.23 train no.19760  loss = 666.41205 avg_loss = 1.37473\n",
            "epoch no.23 train no.19770  loss = 723.44775 avg_loss = 1.37748\n",
            "epoch no.23 train no.19780  loss = 588.28375 avg_loss = 1.39278\n",
            "epoch no.23 train no.19790  loss = 375.91235 avg_loss = 1.39004\n",
            "epoch no.23 train no.19800  loss = 787.86591 avg_loss = 1.40617\n",
            "epoch no.23 train no.19810  loss = 540.91779 avg_loss = 1.41416\n",
            "epoch no.23 train no.19820  loss = 576.01825 avg_loss = 1.39686\n",
            "epoch no.23 train no.19830  loss = 964.49591 avg_loss = 1.40546\n",
            "epoch no.23 train no.19840  loss = 1521.24194 avg_loss = 1.40523\n",
            "epoch no.23 train no.19850  loss = 822.79974 avg_loss = 1.40459\n",
            "epoch no.23 train no.19860  loss = 599.28253 avg_loss = 1.41714\n",
            "epoch no.23 train no.19870  loss = 1014.78137 avg_loss = 1.42115\n",
            "epoch no.23 train no.19880  loss = 530.31146 avg_loss = 1.41337\n",
            "epoch no.23 train no.19890  loss = 514.92407 avg_loss = 1.41309\n",
            "epoch no.23 train no.19900  loss = 475.94281 avg_loss = 1.41865\n",
            "epoch no.23 train no.19910  loss = 588.17169 avg_loss = 1.41213\n",
            "epoch no.23 train no.19920  loss = 650.08728 avg_loss = 1.41550\n",
            "epoch no.23 train no.19930  loss = 597.59229 avg_loss = 1.40957\n",
            "epoch no.23 train no.19940  loss = 565.37378 avg_loss = 1.41696\n",
            "epoch no.23 train no.19950  loss = 552.79791 avg_loss = 1.40968\n",
            "epoch no.23 train no.19960  loss = 782.62018 avg_loss = 1.41251\n",
            "epoch no.23 train no.19970  loss = 502.21753 avg_loss = 1.41257\n",
            "epoch no.23 train no.19980  loss = 511.79379 avg_loss = 1.42530\n",
            "epoch no.23 train no.19990  loss = 725.00281 avg_loss = 1.41913\n",
            "epoch no.23 train no.20000  loss = 844.48938 avg_loss = 1.41944\n",
            "121\n",
            "to_tokens: ['▁[', '▁왜', '▁너', '▁너', '는', '▁향', '이', '▁모두', '▁이', '워', '버린', '▁슬', '도', '▁이유', '의', '▁마음을', '이', '의', '▁이름', '기가', '▁아직', '▁너', '를', '▁향', '도', '▁같은', '▁너', '▁스', '도', '▁같은', '이', '추', '고', '▁너', '▁봐', '면', '▁오늘', '▁행복', '의', '▁얼굴', '이', '가', '▁돌', '라', '▁그', '▁', '한다', '▁사랑', '런', '▁이유', '이', '도', '없이', '▁없이', '▁너', '도', '▁난', '▁너', '죽', '히', '▁듯', '이', '▁없이', '▁그리', '▁아무', '처럼', '▁남겨', '춰', '이', '▁불', '▁너', '의', '▁향', '기', '로운', '▁조금', '파', '게', '▁해', '▁사랑', '를', '▁지나', '에서', '▁꾸', '며', '▁어제', '▁눈빛', '▁날', '이', '▁꿈꾸', '이', '▁들', '도', '▁나는', '게', '▁오늘', '서', '▁세상', '▁찾아', '했던', '▁', '의', '▁지', '게', '▁하지만', '네', '▁너', '▁난', '▁', '를', '을', '▁사랑', '해', '▁너', '▁아픔', '▁그리', '해', '리', '▁너']\n",
            "너라면 해 너의기억들 모두 지워도 사랑했던 나의 마음 나의 향기 오늘 너의 얼굴과 미소처럼 오늘도 날 비추는 날이면 돼 너의 얼굴을 가리고가 사랑해 아무런 기억해 끝도 없는 오늘도 난 숨막힐 끝도 없는 추억 에 비바람이 되어 너의 향기 그렇게 아프게 해 너를 꿈을 꾸네 그대 만을 잠이 들어도 내게 남아서 날 사랑해 너를 살게 하네매일 난 너만을 사랑해그댈 사랑하니까</s>\n",
            "epoch no.23 train no.20010  loss = 409.19467 avg_loss = 1.43784\n",
            "epoch no.23 train no.20020  loss = 720.78400 avg_loss = 1.44314\n",
            "epoch no.23 train no.20030  loss = 733.56793 avg_loss = 1.44901\n",
            "epoch no.23 train no.20040  loss = 670.93439 avg_loss = 1.45314\n",
            "epoch no.23 train no.20050  loss = 596.73474 avg_loss = 1.44590\n",
            "epoch no.23 train no.20060  loss = 713.67181 avg_loss = 1.43118\n",
            "epoch no.23 train no.20070  loss = 1183.28687 avg_loss = 1.42595\n",
            "epoch no.23 train no.20080  loss = 542.35242 avg_loss = 1.43544\n",
            "epoch no.24 train no.20090  loss = 511.80591 avg_loss = 1.42261\n",
            "epoch no.24 train no.20100  loss = 599.43396 avg_loss = 1.42551\n",
            "epoch no.24 train no.20110  loss = 508.41592 avg_loss = 1.41242\n",
            "epoch no.24 train no.20120  loss = 395.75995 avg_loss = 1.39454\n",
            "epoch no.24 train no.20130  loss = 785.17377 avg_loss = 1.37188\n",
            "epoch no.24 train no.20140  loss = 485.25873 avg_loss = 1.36886\n",
            "epoch no.24 train no.20150  loss = 609.96021 avg_loss = 1.35889\n",
            "epoch no.24 train no.20160  loss = 1253.33118 avg_loss = 1.35212\n",
            "epoch no.24 train no.20170  loss = 537.23083 avg_loss = 1.33582\n",
            "epoch no.24 train no.20180  loss = 852.13196 avg_loss = 1.32473\n",
            "epoch no.24 train no.20190  loss = 475.07056 avg_loss = 1.31785\n",
            "epoch no.24 train no.20200  loss = 702.44751 avg_loss = 1.31887\n",
            "epoch no.24 train no.20210  loss = 568.52814 avg_loss = 1.31794\n",
            "epoch no.24 train no.20220  loss = 425.20743 avg_loss = 1.31353\n",
            "epoch no.24 train no.20230  loss = 559.83551 avg_loss = 1.31354\n",
            "epoch no.24 train no.20240  loss = 534.00677 avg_loss = 1.30252\n",
            "epoch no.24 train no.20250  loss = 491.40283 avg_loss = 1.29728\n",
            "epoch no.24 train no.20260  loss = 601.11334 avg_loss = 1.29830\n",
            "epoch no.24 train no.20270  loss = 528.38354 avg_loss = 1.30578\n",
            "epoch no.24 train no.20280  loss = 385.55466 avg_loss = 1.30625\n",
            "epoch no.24 train no.20290  loss = 442.09308 avg_loss = 1.29893\n",
            "epoch no.24 train no.20300  loss = 550.82440 avg_loss = 1.30043\n",
            "epoch no.24 train no.20310  loss = 342.09192 avg_loss = 1.30520\n",
            "epoch no.24 train no.20320  loss = 514.83557 avg_loss = 1.30468\n",
            "epoch no.24 train no.20330  loss = 439.64218 avg_loss = 1.29590\n",
            "epoch no.24 train no.20340  loss = 438.39331 avg_loss = 1.29139\n",
            "epoch no.24 train no.20350  loss = 637.64679 avg_loss = 1.28611\n",
            "epoch no.24 train no.20360  loss = 401.34448 avg_loss = 1.28642\n",
            "epoch no.24 train no.20370  loss = 415.85040 avg_loss = 1.28317\n",
            "epoch no.24 train no.20380  loss = 565.12000 avg_loss = 1.29344\n",
            "epoch no.24 train no.20390  loss = 528.31213 avg_loss = 1.29804\n",
            "epoch no.24 train no.20400  loss = 1017.49597 avg_loss = 1.29717\n",
            "epoch no.24 train no.20410  loss = 1327.55725 avg_loss = 1.30155\n",
            "epoch no.24 train no.20420  loss = 418.36227 avg_loss = 1.29403\n",
            "epoch no.24 train no.20430  loss = 936.35101 avg_loss = 1.30098\n",
            "epoch no.24 train no.20440  loss = 757.11945 avg_loss = 1.31165\n",
            "epoch no.24 train no.20450  loss = 845.58881 avg_loss = 1.30889\n",
            "epoch no.24 train no.20460  loss = 532.58667 avg_loss = 1.29884\n",
            "epoch no.24 train no.20470  loss = 622.25818 avg_loss = 1.29378\n",
            "epoch no.24 train no.20480  loss = 558.89569 avg_loss = 1.30257\n",
            "epoch no.24 train no.20490  loss = 733.34088 avg_loss = 1.30234\n",
            "epoch no.24 train no.20500  loss = 385.68347 avg_loss = 1.28374\n",
            "212\n",
            "to_tokens: ['▁[', '▁내', '▁해', '를', '를', '▁위해', '냐', '▁하는', '▁괜찮', '▁그', '를', '▁지', '하', '▁않아', '도', '한', '▁', '▁미', '▁너', '뿐', '▁', '▁', '해서', '있', '잖', '아', '▁', '를', '▁또', '보', '니다', '▁매일', '보', '라', '이', '▁난', '고', '가', '도', '▁또', '▁우', '의', '를', '▁바라', '해', '▁정말', '도', '▁순', '▁', '원', '할', '사람', '▁', '▁제', '를', '▁', '가', '도', '서', '은', '▁나는', '를', '▁떠나', '보', '지', '▁', '할', '래', '▁', '▁이', '▁너', '한', '▁너', '별', '도', '▁잘', '를', '▁', '가지', '▁', '▁너', '▁이', '▁', '를', '▁사랑', '▁사랑', '한다고', '▁말', '할', '▁수', '▁있', '나', '요', '▁', '없이', '▁그', '▁나', '가', '면', '▁그', '올', '▁수', '▁없', '▁없', '나', '요', '▁다른', '▁사랑', '▁난', '워', '서', '는', '대', '▁나', '할', '래', '▁다른', '안', '할', '▁너', '나', '▁사랑', '한', '▁말', '▁말해', '▁미', '▁사람', '이', '로', '를', '▁사랑', '할', '▁말해', '를', '▁사랑', '하게', '▁한', '할', '▁수', '▁있', '▁없', '나', '요', '▁그', '대', '▁정말', '인', '▁난', '▁수', '▁있', '나', '요', '▁다른', '▁사람들', '대', '▁', '기에', '를', '▁사랑', '해', '▁말', '요', '▁다른', '▁그', '사람', '도', '▁모르', '▁싶어', '어', '데', '▁어떻게', '를', '▁사랑', '하게', '▁말', '할', '래', '요', '▁그', '를', '▁사랑', '한다고', '▁말', '할', '▁수', '는', '나', '요', '▁그', '▁눈물', '를', '▁사랑', '한다고', '▁말', '할', '▁수', '▁없', '나', '요', '▁나', '대', '요', '▁모르', '나', '면', '▁했', '</s>']\n",
            "너라면 나 너를 아파도 매일 너를 생각하지 못해 사랑해도 난 너를 정말\n",
            "\n",
            "사랑하고있잖아 너를 바라봅니다 바보같이 울다가 다시 한번 나 너를 사랑한다고 말해줄래 영원 한사람이 나를 떠나가 정말 괜찮아 나를 바라보며 말할래 나의\n",
            "\n",
            "행복한 이 순간도나를 떠나가도 좋아 하지만 너를 정말 사랑한다고 말할 수 있나요 한사람이 지나가면 돌아올 수는 없나요 너무도 그리워 우 그대 생각할래 미워서 너무나 사랑한다고 말해요 다른사람 정말 나를 사랑한다고 나를 사랑해서 말할 수는 없나요 그대 없인 살 수 있나요 다른 그대이나를 사랑한다고 말해요 다른 한 순간도 보고싶은데 나를 사랑한다고 말할래요 너를 사랑한다고 말할 수 있나요 이렇게 너를 사랑한다고 말할 수 없나요 그대도 아프게요</s>\n",
            "epoch no.24 train no.20510  loss = 533.32922 avg_loss = 1.29162\n",
            "epoch no.24 train no.20520  loss = 772.67883 avg_loss = 1.30055\n",
            "epoch no.24 train no.20530  loss = 569.86713 avg_loss = 1.30855\n",
            "epoch no.24 train no.20540  loss = 600.59827 avg_loss = 1.30298\n",
            "epoch no.24 train no.20550  loss = 555.25024 avg_loss = 1.32587\n",
            "epoch no.24 train no.20560  loss = 1100.17065 avg_loss = 1.33032\n",
            "epoch no.24 train no.20570  loss = 504.01144 avg_loss = 1.32673\n",
            "epoch no.24 train no.20580  loss = 550.25446 avg_loss = 1.32299\n",
            "epoch no.24 train no.20590  loss = 515.42731 avg_loss = 1.32514\n",
            "epoch no.24 train no.20600  loss = 1160.23010 avg_loss = 1.32010\n",
            "epoch no.24 train no.20610  loss = 538.39178 avg_loss = 1.32053\n",
            "epoch no.24 train no.20620  loss = 632.08398 avg_loss = 1.32934\n",
            "epoch no.24 train no.20630  loss = 563.90942 avg_loss = 1.32520\n",
            "epoch no.24 train no.20640  loss = 497.80164 avg_loss = 1.30869\n",
            "epoch no.24 train no.20650  loss = 572.94843 avg_loss = 1.31234\n",
            "epoch no.24 train no.20660  loss = 539.21069 avg_loss = 1.31276\n",
            "epoch no.24 train no.20670  loss = 494.11157 avg_loss = 1.33305\n",
            "epoch no.24 train no.20680  loss = 454.34851 avg_loss = 1.33771\n",
            "epoch no.24 train no.20690  loss = 744.35284 avg_loss = 1.33223\n",
            "epoch no.24 train no.20700  loss = 427.49387 avg_loss = 1.33532\n",
            "epoch no.24 train no.20710  loss = 532.01959 avg_loss = 1.33069\n",
            "epoch no.24 train no.20720  loss = 753.61145 avg_loss = 1.33489\n",
            "epoch no.24 train no.20730  loss = 485.83060 avg_loss = 1.33813\n",
            "epoch no.24 train no.20740  loss = 532.74414 avg_loss = 1.33228\n",
            "epoch no.24 train no.20750  loss = 415.79565 avg_loss = 1.34127\n",
            "epoch no.24 train no.20760  loss = 388.09726 avg_loss = 1.32605\n",
            "epoch no.24 train no.20770  loss = 517.14880 avg_loss = 1.32653\n",
            "epoch no.24 train no.20780  loss = 652.81201 avg_loss = 1.33848\n",
            "epoch no.24 train no.20790  loss = 561.29706 avg_loss = 1.34230\n",
            "epoch no.24 train no.20800  loss = 559.06079 avg_loss = 1.34269\n",
            "epoch no.24 train no.20810  loss = 570.43195 avg_loss = 1.34317\n",
            "epoch no.24 train no.20820  loss = 326.11353 avg_loss = 1.32937\n",
            "epoch no.24 train no.20830  loss = 678.53845 avg_loss = 1.31704\n",
            "epoch no.24 train no.20840  loss = 830.48682 avg_loss = 1.32721\n",
            "epoch no.24 train no.20850  loss = 685.71222 avg_loss = 1.33534\n",
            "epoch no.24 train no.20860  loss = 699.23749 avg_loss = 1.35022\n",
            "epoch no.24 train no.20870  loss = 748.64459 avg_loss = 1.35375\n",
            "epoch no.24 train no.20880  loss = 609.75507 avg_loss = 1.36124\n",
            "epoch no.24 train no.20890  loss = 520.83118 avg_loss = 1.36412\n",
            "epoch no.24 train no.20900  loss = 399.37048 avg_loss = 1.36540\n",
            "epoch no.24 train no.20910  loss = 471.53925 avg_loss = 1.37528\n",
            "epoch no.24 train no.20920  loss = 417.64145 avg_loss = 1.38364\n",
            "epoch no.25 train no.20930  loss = 458.64926 avg_loss = 1.37757\n",
            "epoch no.25 train no.20940  loss = 501.96323 avg_loss = 1.35904\n",
            "epoch no.25 train no.20950  loss = 516.74292 avg_loss = 1.35222\n",
            "epoch no.25 train no.20960  loss = 496.88998 avg_loss = 1.33518\n",
            "epoch no.25 train no.20970  loss = 425.99683 avg_loss = 1.32604\n",
            "epoch no.25 train no.20980  loss = 353.64645 avg_loss = 1.31618\n",
            "epoch no.25 train no.20990  loss = 697.16919 avg_loss = 1.29483\n",
            "epoch no.25 train no.21000  loss = 448.26669 avg_loss = 1.28794\n",
            "362\n",
            "to_tokens: ['▁[', '▁내', '▁잠시', '의', '▁나', '는', '▁나', '파', '▁그런', '그래', '~', '▁눈에', '에', '▁아', '이', '▁흘러', '▁너무', '▁자', '꾸', '▁자', '마', '도', '는', '▁비', '도', '도', '▁자', '▁흘러', '내', '고', '▁그', '럴', '만', '▁', '▁모르', '냐', '▁', '▁난', '▁아', '워', '해', '도', '▁사랑', '신', '▁울', '를', '이', '야', '▁너', '를', '▁사람', '▁알아', '을', '▁버', '하고', '싶', '어', '▁가슴', '이', '파', '도', '▁미', '▁', '워', '게', '▁', '안', '어', '▁두', '사랑', '이', '▁너', '를', '▁사랑', '하고', '▁나', '▁사랑', '니까', '▁마음을', '▁몰', '라', '서', '▁', '▁미', '워', '하', '▁네', '를', '▁사랑', '한', '▁그', '▁누구', '▁죽', '을', '▁싶은', '어', '▁내', '▁마음', '▁너', '▁뿐', '이', '▁너', '마', '운', '걸', '▁한', '도', '▁못', '▁너', '되', '이라는', '▁또', '어', '▁', '저', '▁', '▁번', '▁너', '를', '을', '▁바라', '보', '▁있는', '았', '어', '▁내', '안', '도', '도', '▁사랑', '하고', '▁내', '게', '은', '▁', '를', '▁사랑', '보', '면서', '▁바', '보', '야', '▁', '▁정말', '쉬', '▁한', '▁사랑', '워', '도', '▁미', '▁너', '가', '▁미', '가', '서', '다', '▁너', '▁내', '를', '를', '▁사랑', '하고', '▁정말', '▁미', '워', '해', '▁정말', '를', '▁사랑', '해', '▁싶었', '서', '▁', '▁사랑', '한', '▁싶어', '고', '▁너', '는', '▁', '를', '▁사랑', '워', '하고', '▁미', '워', '하고', '▁내', '하고', '▁미', '워', '하고', '▁사랑', '는', '▁바', '게', '▁너', '를', '▁사랑', '하고', '▁내', '▁사랑', '처럼', '▁사랑', '하고', '▁정말', '워', '해', '▁내', '▁행복', '하고', '도', '널', '▁너', '해', '를', '▁바라', '▁말', '해', '▁아', '게', '▁너', '를', '▁', '아', '▁내', '난', '▁정말', '워', '도', '▁너', '해', '▁너', '게', '눈', '에', '▁지나', '꾸', '만', '▁미', '를', '▁정말', '해', '▁있어', '▁너', '를', '▁정말', '▁미', '워', '다', '▁너', '질', '는', '▁아', '▁사랑', '워', '도', '▁있어', '▁너', '▁아', '게', '▁정말', '▁사랑', '를', '을', '▁사랑', '하고', '▁너', '▁사랑', '▁내', '▁미', '워', '하고', '▁싶어', '줘', '을', '▁바라', '파', '도', '▁미', '해', '도', '를', '▁사랑', '해', '▁내', '겐', '▁정말', '▁미', '를', '▁정말', '지', '▁사랑', '해', '</s>', '▁전', '▁너', '만', '▁사랑', '▁사랑', '를', '▁정말', '▁사랑', '워', '하고', '▁있어', '▁너', '▁좋아', '해', '▁미', '워', '하고', '▁있어', '</s>', '를', '▁', '해', '▁내', '을', '▁그', '▁번', '▁눈에', '는', '이', '▁우', '▁미', '워', '도', '▁너', '해', '▁내', '▁사랑', '치', '도', '▁내', '를', '▁두', '▁', '▁미', '워', '도', '▁있어', '를', '▁사랑', '워', '서', '▁있어', '▁나']\n",
            "너라면 나랑 너는 아냐 . 두눈에 눈물이 흘러서 자꾸아마너를막아봐도 날 밀어내도 그게 내 마음 아마도정말 미워내도 다신 너뿐이야 너란걸 평생을 말하고 싶었어 가슴 아파도 정말 미치게 미쳤어내 욕심에 너를 사랑한 내 남자의 마음을 몰라서 정말미안해 너를 사랑해 그게만 주고싶어 내겐 너뿐이라고 고마운 단 하루도 정말 안녕하고싶었어그저한동안 너만을 바라보고 말았어 미워져 다시 사랑해 내 마음은 너를 바라보던바보 같은사람아마도 미워하고 있어 네게 다가온다 해도 나 너를 사랑해 정말 미안해 너를 사랑하고 싶어도 많이 사랑하고 싶다고 이제는 너를미워하고 미워도 사랑하고 미워도 모르는 내겐 너를 사랑아도 나를 사랑해미안해도 좋아해 도 좋아 너만을 사랑해 내겐 너를사랑해 하필 미워도 사랑해 내 두눈이 자꾸 정말 너를 사랑하고 있어 너를 정말 미운다가 다시는 정말 미워하고 있어도 그게 다시 너만을 말하고 싶어서 정말 미워하고 있어 죽을 아파도 좋아해너를 사랑해 내겐 정말 너를 떠나도 사랑해 내겐 너를 정말 너를 정말 미워하고 있어도 사랑해 미워하고 있다고 너를 사랑해 죽도록 한 두 눈에 가슴이 정말 미워도 사랑해도 미워해 나의 마음을 정말 미워하고 너를미워하고 있어</s>\n",
            "epoch no.25 train no.21010  loss = 457.87701 avg_loss = 1.27736\n",
            "epoch no.25 train no.21020  loss = 524.93280 avg_loss = 1.27487\n",
            "epoch no.25 train no.21030  loss = 318.67682 avg_loss = 1.26942\n",
            "epoch no.25 train no.21040  loss = 441.90308 avg_loss = 1.26550\n",
            "epoch no.25 train no.21050  loss = 1265.58069 avg_loss = 1.26057\n",
            "epoch no.25 train no.21060  loss = 499.94702 avg_loss = 1.26248\n",
            "epoch no.25 train no.21070  loss = 612.79657 avg_loss = 1.26395\n",
            "epoch no.25 train no.21080  loss = 484.07822 avg_loss = 1.26295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUsSpaBV_Og9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM_RjEXi_Okc"
      },
      "source": [
        "# 생성 실험\n",
        "from jupyter_generator import main"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIHNqig0rfHB",
        "outputId": "30ad39da-0a3f-42af-8d68-011c2b3f9148"
      },
      "source": [
        "main(temperature = 0.7, top_p = 0.9, top_k = 100, tmp_sent = \"\", text_size = 700, loops = -1,load_path = '/content/drive/MyDrive/KoGPT2-FineTuning-master/checkpointweighted_lyrics_1970_80/KoGPT2_checkpoint_15000.pth', ctx= 'cuda', samples=\"/content/drive/MyDrive/KoGPT2-FineTuning-master/samples\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ok :  checkpointweighted_lyrics_1970_80\n",
            "input : 운명이란\n",
            "701\n",
            "to_tokens: ['▁[', '▁[', '▁', '▁내', '▁', '▁아', '닐', '▁거', '라고', '▁믿고', '▁', '던', '▁거', '라고', '▁사랑', '젠', '▁내', '이란', '▁걸', '▁믿고', '기', '▁', '▁', '의', '▁떠', '날', '▁거', '라고', '▁', '▁웃', '고', '▁말', '하던', '어', '▁', '를', '▁떠나', '▁', '대', '▁내', '게', '▁눈물', '이', '▁흘러', '르', '는', '▁눈물', '▁감', '출', '▁수', '▁없', '▁그렇게', '마', '하면', '널', '▁', '출', '▁수', '▁없는', '▁거', '니', '▁그렇게', '로', '▁', '꾸', '▁커', '▁흘러', '▁내', '▁눈물', '이', '▁흘러', '▁', '널', '▁', '도', '▁']\n",
            "운명이란 항상내 게\n",
            "\n",
            "아닐 거라고 믿고\n",
            "\n",
            "싶었던 거야 이젠 사랑이란 걸 허나 봐 너를 떠날 거라고 그렇게 웃고 말았어\n",
            "\n",
            "나를 떠난\n",
            "\n",
            "그대 내 눈에 눈물이 흐르는 눈물 감출 수 없다고 아파도 감출 수도 없는 거라고 눈물로 자꾸만 흘러 내 눈물이 나 는데 아직도\n",
            "\n",
            "\n",
            "good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSF0t1ZF_Om0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}